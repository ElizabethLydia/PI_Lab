#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 4: Integrated PTT-BP Analysis
Uses results from step3 for further analysis: bar charts, integrated views, etc.
åŸºäºæä¾›çš„ç›®å½•ç»“æ„ï¼ˆæ¯ä¸ªå—è¯•è€…å¦‚ /root/autodl-tmp/00003 æœ‰ ptt_bp_analysis/ ç­‰å­ç›®å½•ï¼‰ï¼Œ
è„šæœ¬ä»æ¯ä¸ªå—è¯•è€…çš„ ptt_bp_analysis/ åŠ è½½ step3 æ–‡ä»¶ï¼Œè¿›è¡Œè·¨å—è¯•è€…åˆ†æã€‚
è¾“å‡ºä¿å­˜åˆ° /root/autodl-tmp/integrated_analysis ï¼ˆå…¨å±€ç›®å½•ï¼‰ã€‚
"""

import os
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import StandardScaler

plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.ioff()

class IntegratedPTTBloodPressureAnalyzer:
    def __init__(self, root_path="/root/autodl-tmp/", output_dir="integrated_analysis2"):
        self.root_path = root_path
        self.output_dir = os.path.join(root_path, output_dir)
        self.step3_dir = "ptt_bp_analysis2"  # step3 è¾“å‡ºç›®å½•ï¼ˆæ¯ä¸ªå—è¯•è€…ä¸‹ï¼‰
        os.makedirs(self.output_dir, exist_ok=True)
        
        # åªä¿ç•™è¡€å‹ç›¸å…³æŒ‡æ ‡ï¼ˆä¸step3ä¸€è‡´ï¼‰
        self.physiological_indicators = {
            'systolic_bp': 'Systolic BP (mmHg)',
            'diastolic_bp': 'Diastolic BP (mmHg)', 
            'mean_bp': 'Mean Arterial Pressure (mmHg)'
        }
        
        self.ptt_combinations_en = {
            'sensor2-sensor3': 'Noseâ†’Finger',
            'sensor2-sensor4': 'Noseâ†’Wrist', 
            'sensor2-sensor5': 'Noseâ†’Ear',
            'sensor3-sensor4': 'Fingerâ†’Wrist',
            'sensor3-sensor5': 'Fingerâ†’Ear',
            'sensor4-sensor5': 'Wristâ†’Ear'
        }
        
        print("ğŸ”¬ Integrated PTT-Cardiovascular Parameters Correlation Analyzer")
        print(f"ğŸ“ Results will be saved to: {self.output_dir}")
        print(f"ğŸ“‚ Loading from each subject's {self.step3_dir}/")
    
    def load_subjects(self):
        """åŠ è½½æ‰€æœ‰å—è¯•è€…ï¼ˆç›®å½•ä»¥ '00' å¼€å¤´ï¼‰"""
        return sorted([d for d in os.listdir(self.root_path) 
                       if os.path.isdir(os.path.join(self.root_path, d)) and d.startswith('00')])
    
    def load_step3_correlations(self, subject, exp_id=None):
        """ä»å—è¯•è€…çš„ ptt_bp_analysis2/ åŠ è½½ correlations CSV"""
        print(f"ğŸ“‚ åŠ è½½ {subject} çš„ correlations CSV")
        subject_dir = os.path.join(self.root_path, subject, self.step3_dir)
        if exp_id is not None:
            # ä»exp_Xæ–‡ä»¶å¤¹ä¸­è¯»å–
            corr_file = os.path.join(subject_dir, f'exp_{exp_id}', f'ptt_cardiovascular_correlations_exp_{exp_id}.csv')
        else:
            # æ•´ä½“ç›¸å…³æ€§æ–‡ä»¶åœ¨æ ¹ç›®å½•
            corr_file = os.path.join(subject_dir, 'ptt_cardiovascular_correlations.csv')
        if not os.path.exists(corr_file):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {corr_file}")
            return None
        try:
            df = pd.read_csv(corr_file)
            if df.empty:
                print(f"âš ï¸ ç©ºæ–‡ä»¶: {corr_file}")
                return None
            df['subject'] = subject
            return df
        except pd.errors.EmptyDataError:
            print(f"âš ï¸ ç©ºæ•°æ®é”™è¯¯: {corr_file}")
            return None
        except Exception as e:
            print(f"âŒ åŠ è½½é”™è¯¯ {subject} exp_{exp_id}: {e}")
            return None
    
    def load_step3_sync_data(self, subject, exp_id=None):
        """ä»å—è¯•è€…çš„ ptt_bp_analysis/ åŠ è½½ sync æ•°æ® CSV (always load overall file)"""
        print(f"ğŸ“‚ åŠ è½½ {subject} çš„ sync æ•°æ®")
        subject_dir = os.path.join(self.root_path, subject, self.step3_dir)
        sync_file = os.path.join(subject_dir, 'synchronized_ptt_cardiovascular_data.csv')
        if not os.path.exists(sync_file):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {sync_file}")
            return None
        try:
            df = pd.read_csv(sync_file)
            if df.empty:
                print(f"âš ï¸ ç©ºæ–‡ä»¶: {sync_file}")
                return None
            df['subject'] = subject
            return df
        except pd.errors.EmptyDataError:
            print(f"âš ï¸ ç©ºæ•°æ®é”™è¯¯: {sync_file}")
            return None
        except Exception as e:
            print(f"âŒ åŠ è½½é”™è¯¯ {subject}: {e}")
            return None
    
    def create_correlation_bar_chart(self, corr_df, title_suffix, subjects, subdir, exp_id=None):
        """åˆ›å»ºç›¸å…³æ€§æŸ±çŠ¶å›¾ï¼ˆä¸¤ç§ç‰ˆæœ¬ï¼šmulti-pair ä¸€å¼ å›¾ + per pair å•ç‹¬å›¾ï¼‰"""
        valid_sensors = list(self.ptt_combinations_en.values())
        for physio, physio_label in self.physiological_indicators.items():
            physio_col = f'{physio}_mean'
            data = []
            for subject in subjects:
                subj_df = corr_df[corr_df['subject'] == subject]
                for _, row in subj_df.iterrows():
                    sensor_label = row['sensor_combination']
                    if sensor_label in valid_sensors and row['physiological_parameter'] == physio_col:
                        data.append({
                            'subject': subject,
                            'sensor_pair': sensor_label,
                            'correlation': row['correlation_coefficient'],
                            'p_value': row.get('p_value', 1.0),  # Assume p_value in data
                            'significant': row.get('p_value', 1.0) < 0.05
                        })
            if not data:
                continue
            df = pd.DataFrame(data)
            n_subjects = len(df['subject'].unique())
            if n_subjects == 0:
                continue
            
            os.makedirs(subdir, exist_ok=True)
            
            # ç‰ˆæœ¬1: ä¸€å¼ å›¾æ‰€æœ‰6ä¸ª pair
            fig_width = max(12, n_subjects * 0.5)
            plt.figure(figsize=(fig_width, 8))
            ax = sns.barplot(data=df, x='subject', y='correlation', hue='sensor_pair', palette='tab10')
            lines = [(0.4, 'green'), (-0.4, 'green'), (0.5, 'blue'), (-0.5, 'blue'), (0.7, 'red'), (-0.7, 'red')]
            for val, color in lines:
                plt.axhline(val, color=color, linestyle='--')
            # Add significance asterisks
            for i, bar in enumerate(ax.patches):
                if i < len(df) and df.iloc[i]['significant']:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01 if bar.get_height() > 0 else bar.get_height() - 0.05,
                            '*', ha='center', va='bottom' if bar.get_height() > 0 else 'top')
            plt.title(f'Correlation Bar Chart for {physio_label} (All Pairs) {title_suffix}')
            plt.ylim(-1, 1)
            plt.xlabel('Subject')
            plt.ylabel('Pearson Correlation')
            plt.xticks(rotation=90, ha='right')
            plt.legend(title='Sensor Pair', bbox_to_anchor=(1.05, 1), loc='upper left')
            filename_multi = f'correlation_bar_{physio}_multi{("_exp" + str(exp_id) if exp_id else "")}.png'
            plt.savefig(os.path.join(subdir, filename_multi), bbox_inches='tight')
            plt.close()
            print(f"ğŸ’¾ ä¿å­˜ multi-pair æŸ±çŠ¶å›¾: {os.path.join(subdir, filename_multi)}")
            
            # ç‰ˆæœ¬2: æ¯ä¸ª pair å•ç‹¬ä¸€å¼ å›¾
            for pair_label in valid_sensors:
                pair_data = [d for d in data if d['sensor_pair'] == pair_label]
                if not pair_data:
                    continue
                pair_df = pd.DataFrame(pair_data)
                fig_width = max(12, len(pair_df) * 0.5)
                plt.figure(figsize=(fig_width, 8))
                ax = sns.barplot(data=pair_df, x='subject', y='correlation', color='skyblue')
                for val, color in lines:
                    plt.axhline(val, color=color, linestyle='--')
                # Add significance asterisks
                for i, bar in enumerate(ax.patches):
                    if pair_df.iloc[i]['significant']:
                        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01 if bar.get_height() > 0 else bar.get_height() - 0.05,
                                '*', ha='center', va='bottom' if bar.get_height() > 0 else 'top')
                plt.title(f'Correlation Bar Chart for {physio_label} - {pair_label} {title_suffix}')
                plt.ylim(-1, 1)
                plt.xlabel('Subject')
                plt.ylabel('Pearson Correlation')
                plt.xticks(rotation=90, ha='right')
                safe_pair = pair_label.replace('â†’', '-').replace(' ', '_')
                filename = f'correlation_bar_{physio}_{safe_pair}{("_exp" + str(exp_id) if exp_id else "")}.png'
                plt.savefig(os.path.join(subdir, filename), bbox_inches='tight')
                plt.close()
                print(f"ğŸ’¾ ä¿å­˜ per-pair æŸ±çŠ¶å›¾: {os.path.join(subdir, filename)}")
    
    def create_r_distribution_plot(self, corr_df, title_suffix, subjects, subdir, exp_id=None):
        """ç»˜åˆ¶ r çš„åˆ†å¸ƒå›¾ (violin plot with gradient)"""
        valid_sensors = list(self.ptt_combinations_en.values())
        for physio, physio_label in self.physiological_indicators.items():
            physio_col = f'{physio}_mean'
            data = []
            for subject in subjects:
                subj_df = corr_df[corr_df['subject'] == subject]
                for _, row in subj_df.iterrows():
                    sensor_label = row['sensor_combination']
                    if sensor_label in valid_sensors and row['physiological_parameter'] == physio_col:
                        data.append({
                            'sensor_pair': sensor_label,
                            'correlation': row['correlation_coefficient']
                        })
            if not data:
                continue
            df = pd.DataFrame(data)
            os.makedirs(subdir, exist_ok=True)
            plt.figure(figsize=(12, 8))
            sns.violinplot(data=df, x='sensor_pair', y='correlation', palette='viridis', inner='box')
            
            # æ·»åŠ æ°´å¹³å‚è€ƒçº¿
            lines = [(0, 'black'), (0.4, 'green'), (-0.4, 'green'), (0.7, 'red'), (-0.7, 'red')]
            for val, color in lines:
                plt.axhline(val, color=color, linestyle='--', linewidth=1)
            
            # è®¡ç®—å¹¶æ ‡æ³¨ Q1, median, Q3 å’Œæœ€å®½ç‚¹ (å³°å€¼)
            from scipy.stats import gaussian_kde
            quantiles = df.groupby('sensor_pair')['correlation'].quantile([0.25, 0.5, 0.75]).unstack()
            for i, pair in enumerate(df['sensor_pair'].unique()):
                pair_data = df[df['sensor_pair'] == pair]['correlation']
                if pair in quantiles.index and not pair_data.empty:
                    q1, median, q3 = quantiles.loc[pair, [0.25, 0.5, 0.75]]
                    # æ ‡æ³¨ Q1 å’Œ Q3 (è°ƒæ•´ä½ç½®ä»¥æé«˜æ¸…æ™°åº¦)
                    plt.text(i + 0.2, q1 - 0.05, f'Q1: {q1:.2f}', ha='left', va='top', fontsize=8, color='blue', bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))
                    plt.text(i + 0.2, q3 + 0.05, f'Q3: {q3:.2f}', ha='left', va='bottom', fontsize=8, color='blue', bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))
                    # ä¸­ä½æ•°ç”¨ç™½è‰²æ ‡æ³¨
                    plt.text(i, median + 0.05, f'Med: {median:.2f}', ha='center', va='bottom', fontsize=8, color='white', bbox=dict(facecolor='black', alpha=0.5, edgecolor='none'))
                    # æ ‡æ³¨æœ€å®½ç‚¹ (å¯†åº¦å³°å€¼)
                    if len(pair_data) > 1:
                        pair_data = pair_data.dropna()  # ç§»é™¤ NaN ä»¥é¿å… KDE é”™è¯¯
                        if not pair_data.empty and np.isfinite(pair_data).all():
                            kde = gaussian_kde(pair_data)
                            y_vals = np.linspace(pair_data.min(), pair_data.max(), 100)
                            kde_vals = kde(y_vals)
                            peak_y = y_vals[np.argmax(kde_vals)]
                            plt.text(i - 0.2, peak_y, f'Peak: {peak_y:.2f}', ha='right', va='center', fontsize=8, color='red', bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))
            
            plt.title(f'Distribution of Correlations for {physio_label} {title_suffix}')
            plt.ylim(-1.1, 1.1)  # ç•¥å¾®æ‰©å±• y è½´ä»¥å®¹çº³æ ‡æ³¨
            plt.xlabel('Sensor Pair')
            plt.ylabel('Pearson Correlation')
            plt.xticks(rotation=45, ha='right')
            filename = f'r_distribution_{physio}{("_exp" + str(exp_id) if exp_id else "")}.png'
            plt.savefig(os.path.join(subdir, filename), bbox_inches='tight')
            plt.close()
            print(f"ğŸ’¾ ä¿å­˜ r åˆ†å¸ƒå›¾: {os.path.join(subdir, filename)}")
    
    def remove_outliers_iqr(self, data_series):
        """ä½¿ç”¨IQRæ–¹æ³•å»é™¤æå€¼ (from step3)"""
        q1 = data_series.quantile(0.25)
        q3 = data_series.quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        return data_series[(data_series >= lower_bound) & (data_series <= upper_bound)]

    def create_bland_altman_plots(self, sync_df, exp_id=None, title_suffix=""):
        """åˆ›å»ºBland-Altmanå›¾ - å…­ä¸ªä¼ æ„Ÿå™¨å¯¹çš„SBPã€DBPå’ŒMean BP"""
        try:
            # è¡€å‹æŒ‡æ ‡ - åŒ…æ‹¬Mean BPï¼ˆåªå¤„ç†è¡€å‹ç›¸å…³æŒ‡æ ‡ï¼‰
            bp_indicators = ['systolic_bp_mean', 'diastolic_bp_mean', 'mean_bp_mean']
            bp_labels = ['Systolic BP', 'Diastolic BP', 'Mean BP']
            
            # ä¼ æ„Ÿå™¨å¯¹
            sensor_pairs = list(self.ptt_combinations_en.keys())
            
            # åˆ›å»º6x6çš„å­å›¾å¸ƒå±€ - 6è¡Œï¼ˆä¼ æ„Ÿå™¨å¯¹ï¼‰x 6åˆ—ï¼ˆæ¯ä¸ªç”Ÿç†æŒ‡æ ‡å·¦å³ä¸¤ä¸ªå›¾ï¼‰
            fig, axes = plt.subplots(6, 6, figsize=(24, 20))
            fig.suptitle(f'PTT vs Reference BP Analysis{title_suffix}', 
                        fontsize=16, fontweight='bold', y=1)
            
            # å­˜å‚¨è¯¯å·®å¸¦ç»Ÿè®¡ä¿¡æ¯
            error_band_stats = []
            
            for sensor_idx, sensor_pair in enumerate(sensor_pairs):
                for bp_idx, (bp_indicator, bp_label) in enumerate(zip(bp_indicators, bp_labels)):
                    # è®¡ç®—å­å›¾ä½ç½® - 6è¡Œx6åˆ—å¸ƒå±€
                    row = sensor_idx  # 0-5 for 6 sensor pairs
                    col_left = bp_idx * 2      # 0, 2, 4 for left plots (regression)
                    col_right = bp_idx * 2 + 1 # 1, 3, 5 for right plots (bland-altman)
                    
                    ax_left = axes[row, col_left]   # å·¦ä¾§å›å½’å›¾
                    ax_right = axes[row, col_right] # å³ä¾§Bland-Altmanå›¾
                    
                    # è·å–è¯¥ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
                    pair_data = sync_df[sync_df['sensor_pair'] == sensor_pair].copy()
                    
                    if len(pair_data) < 10:
                        ax_left.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', 
                                   transform=ax_left.transAxes, fontsize=10)
                        ax_right.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', 
                                    transform=ax_right.transAxes, fontsize=10)
                        ax_left.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}')
                        continue
                    
                    # å‡†å¤‡æ•°æ®
                    mask = ~(pair_data['ptt_ms'].isna() | pair_data[bp_indicator].isna())
                    if mask.sum() < 10:
                        ax_left.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', 
                                   transform=ax_left.transAxes, fontsize=10)
                        ax_right.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', 
                                    transform=ax_right.transAxes, fontsize=10)
                        ax_left.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}')
                        continue
                    
                    ptt_vals = pair_data.loc[mask, 'ptt_ms'].values
                    bp_vals = pair_data.loc[mask, bp_indicator].values
                    
                    # æ„å»ºç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹è¿›è¡Œé¢„æµ‹
                    try:
                        # æ ‡å‡†åŒ–æ•°æ®
                        scaler_ptt = StandardScaler()
                        scaler_bp = StandardScaler()
                        ptt_scaled = scaler_ptt.fit_transform(ptt_vals.reshape(-1, 1))
                        bp_scaled = scaler_bp.fit_transform(bp_vals.reshape(-1, 1))
                        
                        # è®­ç»ƒæ¨¡å‹
                        model = LinearRegression()
                        model.fit(ptt_scaled, bp_scaled.flatten())
                        
                        # é¢„æµ‹
                        bp_pred_scaled = model.predict(ptt_scaled)
                        bp_pred = scaler_bp.inverse_transform(bp_pred_scaled.reshape(-1, 1)).flatten()
                        
                    except Exception as e:
                        print(f"âš ï¸ æ¨¡å‹è®­ç»ƒå¤±è´¥ {sensor_pair}-{bp_indicator}: {e}")
                        ax_left.text(0.5, 0.5, 'Model Error', ha='center', va='center', 
                                   transform=ax_left.transAxes, fontsize=10)
                        ax_right.text(0.5, 0.5, 'Model Error', ha='center', va='center', 
                                    transform=ax_right.transAxes, fontsize=10)
                        ax_left.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}')
                        continue
                    
                    # === å·¦ä¾§ï¼šå›å½’æ‹Ÿåˆå›¾ + è¯¯å·®å¸¦ ===
                    # ç»˜åˆ¶è¯¯å·®å¸¦ï¼ˆæ”¹è¿›çš„é¢œè‰²è®¾ç½®ï¼šä¸€å±‚ä¸€å±‚å åŠ ï¼‰
                    bp_range = [min(bp_vals.min(), bp_pred.min()), max(bp_vals.max(), bp_pred.max())]
                    # å…ˆç»˜åˆ¶æœ€å¤§çš„è¯¯å·®å¸¦ï¼ˆ15mmHgï¼‰
                    ax_left.fill_between(bp_range, 
                                       [b - 15 for b in bp_range], [b + 15 for b in bp_range],
                                       alpha=0.3, color='pink', label='Â±15 mmHg')
                    # å†ç»˜åˆ¶ä¸­ç­‰è¯¯å·®å¸¦ï¼ˆ10mmHgï¼‰
                    ax_left.fill_between(bp_range, 
                                       [b - 10 for b in bp_range], [b + 10 for b in bp_range],
                                       alpha=0.4, color=(1.0, 1.0, 0.6), label='Â±10 mmHg')
                    # æœ€åç»˜åˆ¶æœ€å°è¯¯å·®å¸¦ï¼ˆ5mmHgï¼‰
                    ax_left.fill_between(bp_range, 
                                       [b - 5 for b in bp_range], [b + 5 for b in bp_range],
                                       alpha=0.5, color=(0.7, 1.0, 0.7), label='Â±5 mmHg')
                    
                    # ç»˜åˆ¶ç†æƒ³çº¿ï¼ˆy=xï¼‰
                    ax_left.plot(bp_range, bp_range, 'k--', alpha=0.5, linewidth=1, label='Perfect Match')
                    
                    # æœ€åç»˜åˆ¶æ•°æ®ç‚¹ï¼ˆç¡®ä¿åœ¨æœ€ä¸Šå±‚ï¼‰
                    ax_left.scatter(bp_pred, bp_vals, alpha=0.6, s=20, color='blue')
                    
                    ax_left.set_xlabel('Predicted BP (mmHg)', fontsize=9)
                    ax_left.set_ylabel('Reference BP (mmHg)', fontsize=9)
                    ax_left.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}', fontsize=10)
                    ax_left.grid(True, alpha=0.3)
                    ax_left.legend(fontsize=7, loc='upper left')
                    
                    # === å³ä¾§ï¼šBland-Altmanå›¾ ===
                    # Bland-Altmanè®¡ç®—
                    mean_bp = (bp_vals + bp_pred) / 2
                    diff_bp = bp_pred - bp_vals
                    
                    # è®¡ç®—ç»Ÿè®¡é‡
                    mean_diff = np.mean(diff_bp)
                    std_diff = np.std(diff_bp)
                    limits_of_agreement_upper = mean_diff + 1.96 * std_diff
                    limits_of_agreement_lower = mean_diff - 1.96 * std_diff
                    
                    # ç»˜åˆ¶Bland-Altmanå›¾
                    ax_right.scatter(mean_bp, diff_bp, alpha=0.6, s=20, color='blue')
                    
                    # ç»˜åˆ¶å‡å€¼çº¿å’Œä¸€è‡´æ€§ç•Œé™
                    ax_right.axhline(y=mean_diff, color='red', linestyle='-', linewidth=2, 
                                   label=f'Mean: {mean_diff:.2f}')
                    ax_right.axhline(y=limits_of_agreement_upper, color='red', linestyle='--', linewidth=1, 
                                   label=f'Upper LoA: {limits_of_agreement_upper:.2f}')
                    ax_right.axhline(y=limits_of_agreement_lower, color='red', linestyle='--', linewidth=1, 
                                   label=f'Lower LoA: {limits_of_agreement_lower:.2f}')
                    
                    ax_right.set_xlabel('Mean BP (mmHg)', fontsize=9)
                    ax_right.set_ylabel('Difference (Predicted - Reference) (mmHg)', fontsize=9)
                    ax_right.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}', fontsize=10)
                    ax_right.grid(True, alpha=0.3)
                    ax_right.legend(fontsize=7, loc='upper right')
                    
                    # è®¡ç®—è¯¯å·®å¸¦ç»Ÿè®¡
                    abs_diff = np.abs(diff_bp)
                    within_5 = np.sum(abs_diff <= 5) / len(abs_diff) * 100
                    within_10 = np.sum(abs_diff <= 10) / len(abs_diff) * 100
                    within_15 = np.sum(abs_diff <= 15) / len(abs_diff) * 100
                    
                    error_band_stats.append({
                        'exp_id': exp_id,
                        'sensor_pair': sensor_pair,
                        'sensor_label': self.ptt_combinations_en[sensor_pair],
                        'bp_type': bp_label,
                        'n_samples': len(diff_bp),
                        'within_5_mmhg': within_5,
                        'within_10_mmhg': within_10,
                        'within_15_mmhg': within_15,
                        'mean_diff': mean_diff,
                        'std_diff': std_diff,
                        'loa_upper': limits_of_agreement_upper,
                        'loa_lower': limits_of_agreement_lower
                    })
                    
                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯åˆ°å›¾ä¸­
                    stats_text = f'n={len(diff_bp)}\nÂ±5mmHg: {within_5:.1f}%\nÂ±10mmHg: {within_10:.1f}%\nÂ±15mmHg: {within_15:.1f}%'
                    ax_right.text(0.02, 0.98, stats_text, transform=ax_right.transAxes, 
                               verticalalignment='top', fontsize=7, 
                               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            
            # è®¾ç½®åˆ—æ ‡é¢˜
            for i, bp_label in enumerate(bp_labels):
                # å¦‚æœæ˜¯Systolic BPï¼Œä½¿ç”¨æ›´å¤§çš„å­—ä½“å’ŒåŠ ç²—
                if bp_label == 'Systolic BP':
                    fontsize = 14
                    fontweight = 'bold'
                else:
                    fontsize = 12
                    fontweight = 'bold'
                fig.text(0.167 + i * 0.333, 0.97, bp_label, ha='center', va='center', 
                        fontsize=fontsize, fontweight=fontweight)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾åƒåˆ°å½“å‰å·¥ä½œç›®å½•
            if exp_id is not None:
                filename = f"bland_altman_bp_exp_{exp_id}{title_suffix.replace(' ', '_')}.png"
            else:
                filename = f"bland_altman_bp_overall{title_suffix.replace(' ', '_')}.png"
            
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"ğŸ’¾ ä¿å­˜Bland-Altmanå›¾: {filename}")
            
            # ä¿å­˜è¯¯å·®å¸¦ç»Ÿè®¡åˆ°CSV
            if error_band_stats:
                stats_df = pd.DataFrame(error_band_stats)
                if exp_id is not None:
                    stats_filename = f"error_band_stats_exp_{exp_id}{title_suffix.replace(' ', '_')}.csv"
                else:
                    stats_filename = f"error_band_stats_overall{title_suffix.replace(' ', '_')}.csv"
                stats_df.to_csv(stats_filename, index=False)
                print(f"ğŸ’¾ ä¿å­˜è¯¯å·®å¸¦ç»Ÿè®¡: {stats_filename}")
            
            return fig
            
        except Exception as e:
            print(f"âŒ Bland-Altmanå›¾åˆ›å»ºå¤±è´¥: {e}")
            return None

    def run_individual_experiment_analysis(self, subjects):
        print("\n=== å•å®éªŒåˆ†æ ===")
        individual_dir = os.path.join(self.output_dir, 'individual_experiments_correlations')
        os.makedirs(individual_dir, exist_ok=True)
        for exp_id in range(1, 12):
            exp_corrs = pd.DataFrame()
            for subject in subjects:
                df = self.load_step3_correlations(subject, exp_id)
                if df is not None:
                    exp_corrs = pd.concat([exp_corrs, df])
            if not exp_corrs.empty:
                print(f"ğŸ“Š ç”Ÿæˆå®éªŒ {exp_id} çš„æŸ±çŠ¶å›¾")
                subdir = os.path.join(individual_dir, f'exp_{exp_id}')
                os.makedirs(subdir, exist_ok=True)
                if 'subject' in exp_corrs.columns:
                    cols = ['subject'] + [col for col in exp_corrs.columns if col != 'subject']
                    exp_corrs = exp_corrs[cols]
                csv_path = os.path.join(subdir, f'exp_{exp_id}_correlations.csv')
                exp_corrs.to_csv(csv_path, index=False)
                print(f"ğŸ’¾ ä¿å­˜å®éªŒ {exp_id} çš„ correlations CSV: {csv_path}")
                self.create_correlation_bar_chart(exp_corrs, f'(Exp {exp_id})', subjects, subdir, exp_id)
                self.create_r_distribution_plot(exp_corrs, f'(Exp {exp_id})', subjects, subdir, exp_id)
    
    def run_subject_overall_analysis(self, subjects):
        print("\n=== æ¯ä¸ªå—è¯•è€…æ•´ä½“åˆ†æ ===")
        overall_corrs = pd.DataFrame()
        all_sync_df = pd.DataFrame()
        
        # åŠ è½½ç›¸å…³æ€§å’ŒåŒæ­¥æ•°æ®
        for subject in subjects:
            # åŠ è½½ç›¸å…³æ€§æ•°æ®
            df = self.load_step3_correlations(subject)
            if df is not None:
                overall_corrs = pd.concat([overall_corrs, df])
            
            # åŠ è½½åŒæ­¥æ•°æ®
            sync_df = self.load_step3_sync_data(subject)
            if sync_df is not None:
                all_sync_df = pd.concat([all_sync_df, sync_df], ignore_index=True)
        
        if not overall_corrs.empty:
            print("ğŸ“Š ç”Ÿæˆæ¯ä¸ªå—è¯•è€…æ•´ä½“æŸ±çŠ¶å›¾")
            subdir = os.path.join(self.output_dir, 'overall_correlations')
            os.makedirs(subdir, exist_ok=True)
            if 'subject' in overall_corrs.columns:
                cols = ['subject'] + [col for col in overall_corrs.columns if col != 'subject']
                overall_corrs = overall_corrs[cols]
            csv_path = os.path.join(subdir, 'overall_correlations.csv')
            overall_corrs.to_csv(csv_path, index=False)
            print(f"ğŸ’¾ ä¿å­˜æ•´ä½“ correlations CSV: {csv_path}")
            self.create_correlation_bar_chart(overall_corrs, '(Overall per Subject)', subjects, subdir)
            self.create_r_distribution_plot(overall_corrs, '(Overall per Subject)', subjects, subdir)
        
        # ä¸ºæ•´ä½“æ•°æ®åˆ›å»ºBland-Altmanå›¾
        if not all_sync_df.empty:
            print("ğŸ“Š ä¸ºæ•´ä½“æ•°æ®åˆ›å»ºBland-Altmanå›¾")
            # æ¸…ç†æ•°æ®
            cleaned_overall = pd.DataFrame()
            for pair in all_sync_df['sensor_pair'].unique():
                pair_df = all_sync_df[all_sync_df['sensor_pair'] == pair]
                for col in [c for c in pair_df.columns if c.endswith('_mean') or c == 'ptt_ms']:
                    cleaned_series = self.remove_outliers_iqr(pair_df[col])
                    mask = pair_df[col].isin(cleaned_series)
                    pair_df = pair_df[mask]
                cleaned_overall = pd.concat([cleaned_overall, pair_df])
            
            if not cleaned_overall.empty:
                # åˆ‡æ¢åˆ°æ­£ç¡®çš„ç›®å½•
                os.chdir(subdir)
                self.create_bland_altman_plots(cleaned_overall, None, " (Overall per Subject)")
                os.chdir(self.output_dir)  # å›åˆ°è¾“å‡ºç›®å½•
                
                # ä¿å­˜æ¸…ç†åçš„æ•°æ®
                cleaned_path = os.path.join(subdir, 'overall_cleaned.csv')
                cleaned_overall.to_csv(cleaned_path, index=False)
                print(f"ğŸ’¾ ä¿å­˜æ•´ä½“æ¸…ç†æ•°æ®: {cleaned_path}")
    
    def run_non_cross_experiment_fits(self, subjects):
        """ä¸è·¨å®éªŒçš„çº¿æ€§æ‹Ÿåˆï¼šæ¯ä¸ªå®éªŒå•ç‹¬æ‹Ÿåˆ"""
        print("\n=== ä¸è·¨å®éªŒçº¿æ€§æ‹Ÿåˆåˆ†æ ===")
        non_cross_dir = os.path.join(self.output_dir, 'per_experiment_fits')
        os.makedirs(non_cross_dir, exist_ok=True)
        
        all_sync_df = pd.DataFrame()
        for subject in subjects:
            df = self.load_step3_sync_data(subject)
            if df is not None:
                all_sync_df = pd.concat([all_sync_df, df], ignore_index=True)
        
        if all_sync_df.empty:
            print("âš ï¸ æ— å¯ç”¨ sync æ•°æ®")
            return
        
        if 'exp_id' not in all_sync_df.columns:
            print("âš ï¸ sync æ•°æ®ç¼ºå°‘ 'exp_id' åˆ—ï¼Œæ— æ³•è¿›è¡Œ per-exp åˆ†æ")
            return
        
        for exp_id in sorted(all_sync_df['exp_id'].unique()):
            exp_sync = all_sync_df[all_sync_df['exp_id'] == exp_id].reset_index(drop=True)
            if exp_sync.empty:
                continue
            
            # Clean outliers per group
            cleaned_exp = pd.DataFrame()
            for pair in exp_sync['sensor_pair'].unique():
                pair_df = exp_sync[exp_sync['sensor_pair'] == pair]
                for col in [c for c in pair_df.columns if c.endswith('_mean') or c == 'ptt_ms']:
                    cleaned_series = self.remove_outliers_iqr(pair_df[col])
                    mask = pair_df[col].isin(cleaned_series)
                    pair_df = pair_df[mask]
                cleaned_exp = pd.concat([cleaned_exp, pair_df])
            
            cleaned_path = os.path.join(non_cross_dir, f'per_exp_{exp_id}_cleaned.csv')
            cleaned_exp.to_csv(cleaned_path, index=False)
            print(f"ğŸ’¾ ä¿å­˜ per-exp cleaned CSV: {cleaned_path}")
            
            # ç»˜åˆ¶æ•£ç‚¹å›¾ + çº¿æ€§æ‹Ÿåˆ
            for physio, label in self.physiological_indicators.items():
                col = f'{physio}_mean'
                if col in cleaned_exp.columns:
                    for pair in cleaned_exp['sensor_pair'].unique():
                        pair_df = cleaned_exp[cleaned_exp['sensor_pair'] == pair].reset_index(drop=True)
                        if len(pair_df) < 10:
                            continue
                        plt.figure(figsize=(10, 8))
                        sns.scatterplot(data=pair_df, x='ptt_ms', y=col, hue='subject', palette='tab20', alpha=0.6)
                        
                        mask = ~(pair_df['ptt_ms'].isna() | pair_df[col].isna())
                        if mask.sum() >= 10:
                            X = pair_df.loc[mask, 'ptt_ms'].values.reshape(-1, 1)
                            y = pair_df.loc[mask, col].values
                            model = LinearRegression().fit(X, y)
                            pred = model.predict(X)
                            r, _ = stats.pearsonr(pair_df.loc[mask, 'ptt_ms'], y)
                            r2 = model.score(X, y)
                            mae = mean_absolute_error(y, pred)
                            std = np.std(y - pred)
                            x_sort = np.sort(X, axis=0)
                            plt.plot(x_sort, model.predict(x_sort), color='red', linewidth=2, label='Fit')
                            
                            stats_text = f'r = {r:.2f}\nRÂ² = {r2:.2f}\nMAE = {mae:.2f}\nSTD = {std:.2f}'
                            plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes,
                                     bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray', boxstyle='round,pad=0.5'),
                                     verticalalignment='top')
                        
                        plt.title(f'{label} vs PTT ({self.ptt_combinations_en.get(pair, pair)}) - Per Exp {exp_id} (Cleaned)')
                        plt.xlabel('PTT (ms)')
                        plt.ylabel(label)
                        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                        filename = f'scatter_fit_{physio}_{pair}_per_exp{exp_id}_cleaned.png'
                        plt.savefig(os.path.join(non_cross_dir, filename), bbox_inches='tight')
                        plt.close()
                        print(f"ğŸ’¾ ä¿å­˜ per-exp æ•£ç‚¹æ‹Ÿåˆå›¾: {os.path.join(non_cross_dir, filename)}")
            
            # ä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºBland-Altmanå›¾
            if not cleaned_exp.empty:
                print(f"ğŸ“Š ä¸ºå®éªŒ {exp_id} åˆ›å»ºBland-Altmanå›¾")
                # åˆ‡æ¢åˆ°æ­£ç¡®çš„ç›®å½•
                os.chdir(non_cross_dir)
                self.create_bland_altman_plots(cleaned_exp, exp_id, f" (Per Exp {exp_id})")
                os.chdir(self.output_dir)  # å›åˆ°è¾“å‡ºç›®å½•

    def run_cross_experiment_fits(self, subjects):
        """è·¨å®éªŒçš„çº¿æ€§æ‹Ÿåˆï¼šç»¼åˆæ‰€æœ‰å®éªŒ"""
        print("\n=== è·¨å®éªŒçº¿æ€§æ‹Ÿåˆåˆ†æ ===")
        cross_dir = os.path.join(self.output_dir, 'cross_experiment_fits')
        os.makedirs(cross_dir, exist_ok=True)
        
        all_sync_df = pd.DataFrame()
        for subject in subjects:
            df = self.load_step3_sync_data(subject)
            if df is not None:
                all_sync_df = pd.concat([all_sync_df, df], ignore_index=True)
        
        if all_sync_df.empty:
            print("âš ï¸ æ— å¯ç”¨ sync æ•°æ®")
            return
        
        # Clean comprehensive
        cleaned_comp = pd.DataFrame()
        for pair in all_sync_df['sensor_pair'].unique():
            pair_df = all_sync_df[all_sync_df['sensor_pair'] == pair]
            for col in [c for c in pair_df.columns if c.endswith('_mean') or c == 'ptt_ms']:
                cleaned_series = self.remove_outliers_iqr(pair_df[col])
                mask = pair_df[col].isin(cleaned_series)
                pair_df = pair_df[mask]
            cleaned_comp = pd.concat([cleaned_comp, pair_df])
        
        cleaned_comp_path = os.path.join(cross_dir, 'cross_experiments_cleaned.csv')
        cleaned_comp.to_csv(cleaned_comp_path, index=False)
        print(f"ğŸ’¾ ä¿å­˜ cross-exp cleaned CSV: {cleaned_comp_path}")
        
        # ç»¼åˆæ•£ç‚¹ + æ‹Ÿåˆ
        for physio, label in self.physiological_indicators.items():
            col = f'{physio}_mean'
            if col in cleaned_comp.columns:
                for pair in cleaned_comp['sensor_pair'].unique():
                    pair_df = cleaned_comp[cleaned_comp['sensor_pair'] == pair].reset_index(drop=True)
                    if len(pair_df) < 10:
                        continue
                    plt.figure(figsize=(10, 8))
                    sns.scatterplot(data=pair_df, x='ptt_ms', y=col, hue='subject', palette='tab20', alpha=0.6)
                    
                    mask = ~(pair_df['ptt_ms'].isna() | pair_df[col].isna())
                    if mask.sum() >= 10:
                        X = pair_df.loc[mask, 'ptt_ms'].values.reshape(-1, 1)
                        y = pair_df.loc[mask, col].values
                        model = LinearRegression().fit(X, y)
                        pred = model.predict(X)
                        r, _ = stats.pearsonr(pair_df.loc[mask, 'ptt_ms'], y)
                        r2 = model.score(X, y)
                        mae = mean_absolute_error(y, pred)
                        std = np.std(y - pred)
                        x_sort = np.sort(X, axis=0)
                        plt.plot(x_sort, model.predict(x_sort), color='red', linewidth=2, label='Overall Fit')
                        
                        stats_text = f'r = {r:.2f}\nRÂ² = {r2:.2f}\nMAE = {mae:.2f}\nSTD = {std:.2f}'
                        plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes,
                                 bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray', boxstyle='round,pad=0.5'),
                                 verticalalignment='top')
                    
                    plt.title(f'{label} vs PTT ({self.ptt_combinations_en.get(pair, pair)}) - Cross Experiments (Cleaned)')
                    plt.xlabel('PTT (ms)')
                    plt.ylabel(label)
                    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                    filename = f'scatter_fit_{physio}_{pair}_cross_experiments_cleaned.png'
                    plt.savefig(os.path.join(cross_dir, filename), bbox_inches='tight')
                    plt.close()
                    print(f"ğŸ’¾ ä¿å­˜ cross-exp æ•£ç‚¹æ‹Ÿåˆå›¾: {os.path.join(cross_dir, filename)}")
            
            # ä¸ºè·¨å®éªŒæ•°æ®åˆ›å»ºBland-Altmanå›¾
            if not cleaned_comp.empty:
                print(f"ğŸ“Š ä¸ºè·¨å®éªŒæ•°æ®åˆ›å»ºBland-Altmanå›¾")
                # åˆ‡æ¢åˆ°æ­£ç¡®çš„ç›®å½•
                os.chdir(cross_dir)
                self.create_bland_altman_plots(cleaned_comp, None, " (Cross Experiments)")
                os.chdir(self.output_dir)  # å›åˆ°è¾“å‡ºç›®å½•

    def run_integrated_analysis(self, subjects):
        """èåˆåˆ†æï¼šè·¨å—è¯•è€…æ•´åˆ (ç°åœ¨åªä¿å­˜CSVï¼Œä¸ç”Ÿæˆæ‹Ÿåˆå›¾)"""
        print("\n=== èåˆåˆ†æ ===")
        integrated_dir = os.path.join(self.output_dir, 'integrated_experiments')
        os.makedirs(integrated_dir, exist_ok=True)
        
        all_sync_df = pd.DataFrame()
        for subject in subjects:
            df = self.load_step3_sync_data(subject)
            if df is not None:
                all_sync_df = pd.concat([all_sync_df, df], ignore_index=True)
        
        if all_sync_df.empty:
            print("âš ï¸ æ— å¯ç”¨ sync æ•°æ®")
            return
        
        if 'subject' in all_sync_df.columns:
            cols = ['subject'] + [col for col in all_sync_df.columns if col != 'subject']
            all_sync_df = all_sync_df[cols]
        
        if 'exp_id' in all_sync_df.columns:
            for exp_id in sorted(all_sync_df['exp_id'].unique()):
                exp_sync = all_sync_df[all_sync_df['exp_id'] == exp_id].reset_index(drop=True)
                if not exp_sync.empty:
                    csv_path = os.path.join(integrated_dir, f'integrated_exp_{exp_id}.csv')
                    exp_sync.to_csv(csv_path, index=False)
                    print(f"ğŸ’¾ ä¿å­˜æ•´åˆ CSV: {csv_path}")
        else:
            print("âš ï¸ sync æ•°æ®ç¼ºå°‘ 'exp_id' åˆ—ï¼Œæ— æ³• per-exp æ‹†åˆ†")
        
        comprehensive_path = os.path.join(self.output_dir, 'comprehensive_integrated.csv')
        all_sync_df.to_csv(comprehensive_path, index=False)
        print(f"ğŸ’¾ ä¿å­˜ç»¼åˆ CSV: {comprehensive_path}")

def main():
    analyzer = IntegratedPTTBloodPressureAnalyzer()
    subjects = analyzer.load_subjects()
    print(f"ğŸ“‹ å‘ç° {len(subjects)} ä¸ªå—è¯•è€…")
    
    print("\nğŸ“‹ è¯·é€‰æ‹©åˆ†ææ–¹å¼:")
    print("1. ç»¼åˆåˆ†æ (æ‰€æœ‰)")
    print("2. å•å®éªŒç›¸å…³æ€§åˆ†æ (æ¯ä¸ªå®éªŒçš„æŸ±çŠ¶å›¾)")
    print("3. ç»¼åˆå®éªŒç›¸å…³æ€§åˆ†æ (æ‰€æœ‰å®éªŒçš„æŸ±çŠ¶å›¾)")
    print("4. ä¸è·¨å®éªŒçš„çº¿æ€§æ‹Ÿåˆ")
    print("5. è·¨å®éªŒçš„çº¿æ€§æ‹Ÿåˆ")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3/4/5, é»˜è®¤1): ").strip()
    if not choice:
        choice = "1"
    
    if choice == "1":
        analyzer.run_individual_experiment_analysis(subjects)
        analyzer.run_subject_overall_analysis(subjects)
        analyzer.run_integrated_analysis(subjects)
        analyzer.run_non_cross_experiment_fits(subjects)
        analyzer.run_cross_experiment_fits(subjects)
    elif choice == "2":
        analyzer.run_individual_experiment_analysis(subjects)
    elif choice == "3":
        analyzer.run_subject_overall_analysis(subjects)
    elif choice == "4":
        analyzer.run_non_cross_experiment_fits(subjects)
    elif choice == "5":
        analyzer.run_cross_experiment_fits(subjects)
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œç»¼åˆåˆ†æ")
        analyzer.run_individual_experiment_analysis(subjects)
        analyzer.run_subject_overall_analysis(subjects)
        analyzer.run_integrated_analysis(subjects)
        analyzer.run_non_cross_experiment_fits(subjects)
        analyzer.run_cross_experiment_fits(subjects)
    
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")

if __name__ == "__main__":
    main()