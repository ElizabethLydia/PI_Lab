# PI_Labå¤šè®¾å¤‡PTTè¡€å‹é¢„æµ‹é¢„å¤„ç†ä»£ç 
# åŸºäºBiopacå’ŒHUBè®¾å¤‡çš„ç”Ÿç†ä¿¡å·è¿›è¡Œè„‰æä¼ è¾“æ—¶é—´è®¡ç®—å’Œè¡€å‹é¢„æµ‹

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import signal
from scipy.interpolate import interp1d
from scipy.stats import pearsonr
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

class MultiDevicePTTProcessor:
    """å¤šè®¾å¤‡PTTè¡€å‹é¢„æµ‹å¤„ç†å™¨"""
    
    def __init__(self, data_root="/root/PI_Lab/00017", sampling_rate=100):
        self.data_root = data_root
        self.sampling_rate = sampling_rate
        self.static_conditions = ['1', '7']  # é™æ­¢çŠ¶æ€
        self.all_conditions = [str(i) for i in range(1, 12)]
        
    def load_condition_data(self, condition):
        """åŠ è½½æŒ‡å®šæ¡ä»¶çš„æ•°æ®"""
        condition_path = os.path.join(self.data_root, condition)
        if not os.path.exists(condition_path):
            print(f"æ¡ä»¶ {condition} çš„æ•°æ®è·¯å¾„ä¸å­˜åœ¨")
            return None
        
        data = {
            'condition': condition,
            'biopac': {},
            'hub': {},
            'timestamp_range': None
        }
        
        # åŠ è½½Biopacæ•°æ®
        biopac_path = os.path.join(condition_path, 'Biopac')
        if os.path.exists(biopac_path):
            biopac_files = {
                'hr': f'hr-{condition}.csv',
                'bp': f'bp-{condition}.csv',
                'systolic_bp': f'systolic_bp-{condition}.csv',
                'diastolic_bp': f'diastolic_bp-{condition}.csv',
                'mean_bp': f'mean_bp-{condition}.csv',
                'cardiac_output': f'cardiac_output-{condition}.csv',
                'cardiac_index': f'cardiac_index-{condition}.csv',
                'systemic_vascular_resistance': f'systemic_vascular_resistance-{condition}.csv',
                'rsp': f'rsp-{condition}.csv'
            }
            
            for signal_type, filename in biopac_files.items():
                filepath = os.path.join(biopac_path, filename)
                if os.path.exists(filepath):
                    try:
                        df = pd.read_csv(filepath)
                        data['biopac'][signal_type] = df
                        print(f"æˆåŠŸåŠ è½½Biopac {signal_type}: {len(df)}è¡Œ")
                    except Exception as e:
                        print(f"åŠ è½½Biopac {signal_type}å¤±è´¥: {e}")
        
        # åŠ è½½HUBæ•°æ®
        hub_path = os.path.join(condition_path, 'HUB')
        if os.path.exists(hub_path):
            hub_sensors = ['sensor2.csv', 'sensor3.csv', 'sensor4.csv', 'sensor5.csv']
            
            for sensor_file in hub_sensors:
                filepath = os.path.join(hub_path, sensor_file)
                if os.path.exists(filepath):
                    try:
                        df = pd.read_csv(filepath)
                        sensor_name = sensor_file.replace('.csv', '')
                        data['hub'][sensor_name] = df
                        print(f"æˆåŠŸåŠ è½½HUB {sensor_name}: {len(df)}è¡Œ")
                    except Exception as e:
                        print(f"åŠ è½½HUB {sensor_file}å¤±è´¥: {e}")
        
        # ç¡®å®šæ—¶é—´æˆ³èŒƒå›´
        all_timestamps = []
        for device_data in [data['biopac'], data['hub']]:
            for signal_df in device_data.values():
                if 'timestamp' in signal_df.columns:
                    all_timestamps.extend(signal_df['timestamp'].tolist())
        
        if all_timestamps:
            data['timestamp_range'] = (min(all_timestamps), max(all_timestamps))
            print(f"æ¡ä»¶ {condition} æ—¶é—´æˆ³èŒƒå›´: {data['timestamp_range'][1] - data['timestamp_range'][0]:.2f}ç§’")
        
        return data
    
    def detect_ppg_peaks(self, ppg_signal, timestamps, method='green'):
        """ä»HUB PPGä¿¡å·æ£€æµ‹å¿ƒè·³å³°å€¼"""
        if isinstance(ppg_signal, pd.DataFrame):
            if method in ppg_signal.columns:
                ppg_values = ppg_signal[method].values
            else:
                # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—
                numeric_cols = ppg_signal.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 1:  # è·³è¿‡timestampåˆ—
                    ppg_values = ppg_signal[numeric_cols[1]].values
                else:
                    print("æœªæ‰¾åˆ°åˆé€‚çš„PPGä¿¡å·åˆ—")
                    return [], []
        else:
            ppg_values = ppg_signal
        
        # é¢„å¤„ç†ï¼šå»é™¤å¼‚å¸¸å€¼
        ppg_values = np.array(ppg_values)
        q25, q75 = np.percentile(ppg_values, [25, 75])
        iqr = q75 - q25
        lower_bound = q25 - 1.5 * iqr
        upper_bound = q75 + 1.5 * iqr
        ppg_values = np.clip(ppg_values, lower_bound, upper_bound)
        
        # æ»¤æ³¢
        try:
            nyquist = self.sampling_rate / 2
            low_cutoff = 0.5 / nyquist  # 0.5 Hz
            high_cutoff = 8 / nyquist   # 8 Hz
            b, a = signal.butter(4, [low_cutoff, high_cutoff], btype='band')
            filtered_ppg = signal.filtfilt(b, a, ppg_values)
        except:
            filtered_ppg = ppg_values
        
        # å¯»æ‰¾å³°å€¼
        # ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
        height_threshold = np.mean(filtered_ppg) + 0.5 * np.std(filtered_ppg)
        distance = int(0.4 * self.sampling_rate)  # æœ€å°å¿ƒè·³é—´éš”400ms
        
        peaks, properties = signal.find_peaks(filtered_ppg, 
                                            height=height_threshold,
                                            distance=distance,
                                            prominence=np.std(filtered_ppg) * 0.2)
        
        if len(peaks) == 0:
            # é™ä½é˜ˆå€¼é‡è¯•
            height_threshold = np.mean(filtered_ppg) + 0.2 * np.std(filtered_ppg)
            peaks, properties = signal.find_peaks(filtered_ppg, 
                                                height=height_threshold,
                                                distance=distance)
        
        peak_timestamps = timestamps[peaks] if len(peaks) > 0 else []
        
        return peaks, peak_timestamps
    
    def calculate_hr_from_biopac(self, hr_data):
        """ä»Biopacå¿ƒç‡æ•°æ®è®¡ç®—RRé—´æœŸï¼Œæ¨ç®—Ræ³¢æ—¶é—´"""
        if 'hr' not in hr_data.columns or 'timestamp' not in hr_data.columns:
            return [], []
        
        hr_values = hr_data['hr'].values
        timestamps = hr_data['timestamp'].values
        
        # è®¡ç®—RRé—´æœŸ
        rr_intervals = 60.0 / hr_values  # ç§’
        
        # æ¨ç®—Ræ³¢æ—¶é—´æˆ³
        r_timestamps = []
        current_time = timestamps[0]
        
        for i, rr in enumerate(rr_intervals):
            if i < len(timestamps) - 1:
                # ä½¿ç”¨å®é™…æ—¶é—´æˆ³ä¹‹é—´çš„é—´éš”
                time_diff = timestamps[i+1] - timestamps[i]
                num_beats = max(1, int(time_diff / rr))
                
                for j in range(num_beats):
                    r_time = timestamps[i] + j * rr
                    if r_time <= timestamps[i+1]:
                        r_timestamps.append(r_time)
        
        return r_timestamps, rr_intervals
    
    def calculate_ptt_multidevice(self, condition_data):
        """è®¡ç®—å¤šè®¾å¤‡PTT"""
        results = {
            'condition': condition_data['condition'],
            'ptt_values': [],
            'ptt_timestamps': [],
            'r_timestamps': [],
            'ppg_timestamps': [],
            'hr_biopac': [],
            'bp_biopac': {},
            'device_sync_quality': 0
        }
        
        # è·å–å‚è€ƒè¡€å‹æ•°æ®
        bp_data = {}
        if 'biopac' in condition_data:
            for bp_type in ['systolic_bp', 'diastolic_bp', 'mean_bp', 'bp']:
                if bp_type in condition_data['biopac']:
                    bp_df = condition_data['biopac'][bp_type]
                    if not bp_df.empty:
                        bp_data[bp_type] = bp_df
        
        # æ–¹æ³•1ï¼šä½¿ç”¨Biopacå¿ƒç‡æ¨ç®—Ræ³¢ + HUB PPG
        r_timestamps = []
        if 'hr' in condition_data['biopac']:
            hr_df = condition_data['biopac']['hr']
            r_timestamps, rr_intervals = self.calculate_hr_from_biopac(hr_df)
            results['hr_biopac'] = hr_df['hr'].values
        
        # è·å–HUB PPGå³°å€¼
        ppg_timestamps = []
        if condition_data['hub']:
            # å°è¯•ä¸åŒçš„ä¼ æ„Ÿå™¨
            for sensor_name, sensor_data in condition_data['hub'].items():
                if 'green' in sensor_data.columns:  # ä¼˜å…ˆä½¿ç”¨ç»¿å…‰
                    ppg_peaks, ppg_timestamps = self.detect_ppg_peaks(
                        sensor_data, sensor_data['timestamp'].values, 'green')
                    if len(ppg_timestamps) > 10:  # è‡³å°‘10ä¸ªå³°å€¼æ‰è®¤ä¸ºæœ‰æ•ˆ
                        print(f"ä½¿ç”¨{sensor_name}çš„ç»¿å…‰PPGä¿¡å·ï¼Œæ£€æµ‹åˆ°{len(ppg_timestamps)}ä¸ªå³°å€¼")
                        break
                elif 'ir' in sensor_data.columns:  # å¤‡é€‰çº¢å¤–
                    ppg_peaks, ppg_timestamps = self.detect_ppg_peaks(
                        sensor_data, sensor_data['timestamp'].values, 'ir')
                    if len(ppg_timestamps) > 10:
                        print(f"ä½¿ç”¨{sensor_name}çš„çº¢å¤–PPGä¿¡å·ï¼Œæ£€æµ‹åˆ°{len(ppg_timestamps)}ä¸ªå³°å€¼")
                        break
        
        # è®¡ç®—PTT
        if len(r_timestamps) > 0 and len(ppg_timestamps) > 0:
            ptt_values, matched_r_times, matched_ppg_times = self._match_r_ppg_peaks(
                r_timestamps, ppg_timestamps)
            
            results['ptt_values'] = ptt_values
            results['ptt_timestamps'] = matched_r_times
            results['r_timestamps'] = r_timestamps
            results['ppg_timestamps'] = ppg_timestamps
            
            # è®¡ç®—è®¾å¤‡åŒæ­¥è´¨é‡
            if len(ptt_values) > 0:
                results['device_sync_quality'] = len(ptt_values) / min(len(r_timestamps), len(ppg_timestamps))
            
            print(f"æ¡ä»¶{condition_data['condition']}: è®¡ç®—å‡º{len(ptt_values)}ä¸ªPTTå€¼")
            if len(ptt_values) > 0:
                print(f"PTTèŒƒå›´: {np.min(ptt_values)*1000:.1f} - {np.max(ptt_values)*1000:.1f} ms")
        
        # å­˜å‚¨è¡€å‹æ•°æ®
        results['bp_biopac'] = bp_data
        
        return results
    
    def _match_r_ppg_peaks(self, r_timestamps, ppg_timestamps, max_ptt=1.5):
        """åŒ¹é…Ræ³¢å’ŒPPGå³°å€¼ï¼Œè®¡ç®—PTT"""
        ptt_values = []
        matched_r_times = []
        matched_ppg_times = []
        
        r_timestamps = np.array(r_timestamps)
        ppg_timestamps = np.array(ppg_timestamps)
        
        for r_time in r_timestamps:
            # æ‰¾åˆ°Ræ³¢åç¬¬ä¸€ä¸ªPPGå³°å€¼
            future_ppg = ppg_timestamps[ppg_timestamps > r_time]
            
            if len(future_ppg) > 0:
                ppg_time = future_ppg[0]
                ptt = ppg_time - r_time
                
                # è¿‡æ»¤å¼‚å¸¸PTTå€¼
                if 0.05 <= ptt <= max_ptt:  # 50ms - 1500ms
                    ptt_values.append(ptt)
                    matched_r_times.append(r_time)
                    matched_ppg_times.append(ppg_time)
        
        return np.array(ptt_values), np.array(matched_r_times), np.array(matched_ppg_times)
    
    def extract_ptt_features(self, ptt_results):
        """æå–PTTç‰¹å¾ç”¨äºè¡€å‹é¢„æµ‹"""
        if len(ptt_results['ptt_values']) == 0:
            return None
        
        ptt_values = ptt_results['ptt_values']
        
        features = {
            # PTTç»Ÿè®¡ç‰¹å¾
            'ptt_mean': np.mean(ptt_values),
            'ptt_std': np.std(ptt_values),
            'ptt_median': np.median(ptt_values),
            'ptt_min': np.min(ptt_values),
            'ptt_max': np.max(ptt_values),
            'ptt_range': np.max(ptt_values) - np.min(ptt_values),
            'ptt_cv': np.std(ptt_values) / np.mean(ptt_values),  # å˜å¼‚ç³»æ•°
            
            # å¿ƒç‡ç›¸å…³ç‰¹å¾
            'hr_mean': np.mean(ptt_results['hr_biopac']) if len(ptt_results['hr_biopac']) > 0 else np.nan,
            'hr_std': np.std(ptt_results['hr_biopac']) if len(ptt_results['hr_biopac']) > 0 else np.nan,
            
            # ä¿¡å·è´¨é‡ç‰¹å¾
            'num_beats': len(ptt_values),
            'sync_quality': ptt_results['device_sync_quality'],
            
            # æ—¶åŸŸç‰¹å¾
            'ptt_rmssd': None,  # ç›¸é‚»PTTå·®å€¼çš„å‡æ–¹æ ¹
            'ptt_pnn50': None   # ç›¸é‚»PTTå·®å€¼>50msçš„ç™¾åˆ†æ¯”
        }
        
        # è®¡ç®—PTTå˜å¼‚æ€§ç‰¹å¾
        if len(ptt_values) > 1:
            ptt_diff = np.diff(ptt_values)
            features['ptt_rmssd'] = np.sqrt(np.mean(ptt_diff**2))
            features['ptt_pnn50'] = np.sum(np.abs(ptt_diff) > 0.05) / len(ptt_diff) * 100
        
        return features
    
    def align_bp_with_ptt(self, ptt_results, bp_data):
        """å°†è¡€å‹æ•°æ®ä¸PTTæ—¶é—´æˆ³å¯¹é½"""
        aligned_bp = {}
        
        if not ptt_results['ptt_timestamps'].size or not bp_data:
            return aligned_bp
        
        ptt_timestamps = ptt_results['ptt_timestamps']
        time_range = (np.min(ptt_timestamps), np.max(ptt_timestamps))
        
        for bp_type, bp_df in bp_data.items():
            if 'timestamp' in bp_df.columns:
                bp_signal = bp_df[bp_df.columns[1]].values  # ç¬¬äºŒåˆ—æ˜¯æ•°å€¼
                bp_timestamps = bp_df['timestamp'].values
                
                # ç­›é€‰æ—¶é—´èŒƒå›´å†…çš„è¡€å‹æ•°æ®
                mask = (bp_timestamps >= time_range[0]) & (bp_timestamps <= time_range[1])
                if np.sum(mask) > 0:
                    aligned_bp[bp_type] = {
                        'values': bp_signal[mask],
                        'timestamps': bp_timestamps[mask],
                        'mean': np.mean(bp_signal[mask]),
                        'std': np.std(bp_signal[mask])
                    }
        
        return aligned_bp
    
    def build_bp_prediction_models(self, training_data):
        """æ„å»ºè¡€å‹é¢„æµ‹æ¨¡å‹"""
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        features_list = []
        labels = {'systolic': [], 'diastolic': [], 'mean': []}
        subject_conditions = []
        
        for condition, data in training_data.items():
            if 'ptt_features' not in data or 'aligned_bp' not in data:
                continue
            
            ptt_features = data['ptt_features']
            aligned_bp = data['aligned_bp']
            
            # æ„å»ºç‰¹å¾å‘é‡
            feature_vector = [
                ptt_features['ptt_mean'],
                ptt_features['ptt_std'],
                ptt_features['ptt_cv'],
                ptt_features['hr_mean'] if not np.isnan(ptt_features['hr_mean']) else 70,
                ptt_features['hr_std'] if not np.isnan(ptt_features['hr_std']) else 5,
                ptt_features['sync_quality'],
                ptt_features['ptt_rmssd'] if ptt_features['ptt_rmssd'] is not None else 0,
                ptt_features['ptt_pnn50'] if ptt_features['ptt_pnn50'] is not None else 0
            ]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆç‰¹å¾
            if not any(np.isnan(feature_vector[:3])):  # è‡³å°‘å‰3ä¸ªç‰¹å¾æœ‰æ•ˆ
                features_list.append(feature_vector)
                subject_conditions.append(condition)
                
                # æå–è¡€å‹æ ‡ç­¾
                if 'systolic_bp' in aligned_bp:
                    labels['systolic'].append(aligned_bp['systolic_bp']['mean'])
                else:
                    labels['systolic'].append(np.nan)
                
                if 'diastolic_bp' in aligned_bp:
                    labels['diastolic'].append(aligned_bp['diastolic_bp']['mean'])
                else:
                    labels['diastolic'].append(np.nan)
                
                if 'mean_bp' in aligned_bp:
                    labels['mean'].append(aligned_bp['mean_bp']['mean'])
                else:
                    labels['mean'].append(np.nan)
        
        if len(features_list) < 3:
            print(f"è®­ç»ƒæ•°æ®ä¸è¶³: {len(features_list)}ä¸ªæ ·æœ¬")
            return None
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        X = np.array(features_list)
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        models = {}
        performance = {}
        
        # ä¸ºæ¯ç§è¡€å‹ç±»å‹è®­ç»ƒæ¨¡å‹
        for bp_type in ['systolic', 'diastolic', 'mean']:
            y = np.array(labels[bp_type])
            valid_mask = ~np.isnan(y)
            
            if np.sum(valid_mask) < 3:
                print(f"{bp_type}è¡€å‹æ•°æ®ä¸è¶³")
                continue
            
            X_valid = X_scaled[valid_mask]
            y_valid = y[valid_mask]
            
            # çº¿æ€§å›å½’
            lr_model = LinearRegression()
            lr_model.fit(X_valid, y_valid)
            y_pred_lr = lr_model.predict(X_valid)
            
            # éšæœºæ£®æ—
            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
            rf_model.fit(X_valid, y_valid)
            y_pred_rf = rf_model.predict(X_valid)
            
            models[bp_type] = {
                'linear': lr_model,
                'random_forest': rf_model,
                'scaler': scaler
            }
            
            performance[bp_type] = {
                'linear': {
                    'r2': r2_score(y_valid, y_pred_lr),
                    'mae': mean_absolute_error(y_valid, y_pred_lr),
                    'rmse': np.sqrt(mean_squared_error(y_valid, y_pred_lr))
                },
                'random_forest': {
                    'r2': r2_score(y_valid, y_pred_rf),
                    'mae': mean_absolute_error(y_valid, y_pred_rf),
                    'rmse': np.sqrt(mean_squared_error(y_valid, y_pred_rf))
                }
            }
            
            print(f"\n{bp_type}è¡€å‹é¢„æµ‹æ¨¡å‹æ€§èƒ½:")
            print(f"çº¿æ€§å›å½’ - RÂ²: {performance[bp_type]['linear']['r2']:.3f}, MAE: {performance[bp_type]['linear']['mae']:.3f}")
            print(f"éšæœºæ£®æ— - RÂ²: {performance[bp_type]['random_forest']['r2']:.3f}, MAE: {performance[bp_type]['random_forest']['mae']:.3f}")
        
        return models, performance, (X, labels, subject_conditions)
    
    def process_all_conditions(self):
        """å¤„ç†æ‰€æœ‰å®éªŒæ¡ä»¶"""
        all_results = {}
        
        print("å¼€å§‹å¤„ç†æ‰€æœ‰å®éªŒæ¡ä»¶...")
        
        for condition in self.all_conditions:
            print(f"\nå¤„ç†æ¡ä»¶ {condition}...")
            
            # åŠ è½½æ•°æ®
            condition_data = self.load_condition_data(condition)
            if condition_data is None:
                continue
            
            # è®¡ç®—PTT
            ptt_results = self.calculate_ptt_multidevice(condition_data)
            
            # æå–ç‰¹å¾
            ptt_features = self.extract_ptt_features(ptt_results)
            
            # å¯¹é½è¡€å‹æ•°æ®
            aligned_bp = self.align_bp_with_ptt(ptt_results, ptt_results['bp_biopac'])
            
            all_results[condition] = {
                'ptt_results': ptt_results,
                'ptt_features': ptt_features,
                'aligned_bp': aligned_bp,
                'is_static': condition in self.static_conditions
            }
        
        return all_results
    
    def analyze_static_vs_dynamic(self, all_results):
        """åˆ†æé™æ­¢çŠ¶æ€vsåŠ¨æ€çŠ¶æ€çš„PTTå·®å¼‚"""
        static_ptt = []
        dynamic_ptt = []
        
        for condition, results in all_results.items():
            if results['ptt_features'] is not None:
                ptt_mean = results['ptt_features']['ptt_mean']
                if results['is_static']:
                    static_ptt.append(ptt_mean)
                else:
                    dynamic_ptt.append(ptt_mean)
        
        analysis = {
            'static_ptt_mean': np.mean(static_ptt) if static_ptt else np.nan,
            'static_ptt_std': np.std(static_ptt) if static_ptt else np.nan,
            'dynamic_ptt_mean': np.mean(dynamic_ptt) if dynamic_ptt else np.nan,
            'dynamic_ptt_std': np.std(dynamic_ptt) if dynamic_ptt else np.nan,
            'static_conditions': len(static_ptt),
            'dynamic_conditions': len(dynamic_ptt)
        }
        
        return analysis
    
    def visualize_results(self, all_results, output_dir):
        """å¯è§†åŒ–åˆ†æç»“æœ"""
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. PTTå¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # PTTå‡å€¼å¯¹æ¯”
        conditions = []
        ptt_means = []
        is_static = []
        
        for condition, results in all_results.items():
            if results['ptt_features'] is not None:
                conditions.append(condition)
                ptt_means.append(results['ptt_features']['ptt_mean'] * 1000)  # è½¬æ¢ä¸ºms
                is_static.append(results['is_static'])
        
        colors = ['red' if static else 'blue' for static in is_static]
        axes[0, 0].bar(conditions, ptt_means, color=colors, alpha=0.7)
        axes[0, 0].set_title('å„æ¡ä»¶PTTå‡å€¼å¯¹æ¯”')
        axes[0, 0].set_xlabel('å®éªŒæ¡ä»¶')
        axes[0, 0].set_ylabel('PTT (ms)')
        axes[0, 0].legend(['é™æ­¢çŠ¶æ€', 'åŠ¨æ€çŠ¶æ€'])
        
        # PTTå˜å¼‚æ€§å¯¹æ¯”
        ptt_stds = []
        for condition, results in all_results.items():
            if results['ptt_features'] is not None:
                ptt_stds.append(results['ptt_features']['ptt_std'] * 1000)
        
        if len(ptt_stds) == len(conditions):
            axes[0, 1].bar(conditions, ptt_stds, color=colors, alpha=0.7)
            axes[0, 1].set_title('å„æ¡ä»¶PTTå˜å¼‚æ€§å¯¹æ¯”')
            axes[0, 1].set_xlabel('å®éªŒæ¡ä»¶')
            axes[0, 1].set_ylabel('PTTæ ‡å‡†å·® (ms)')
        
        # è¡€å‹åˆ†å¸ƒ
        bp_systolic = []
        bp_diastolic = []
        for condition, results in all_results.items():
            if 'systolic_bp' in results['aligned_bp']:
                bp_systolic.append(results['aligned_bp']['systolic_bp']['mean'])
            if 'diastolic_bp' in results['aligned_bp']:
                bp_diastolic.append(results['aligned_bp']['diastolic_bp']['mean'])
        
        if bp_systolic:
            axes[1, 0].hist(bp_systolic, bins=10, alpha=0.7, label='æ”¶ç¼©å‹')
            axes[1, 0].set_title('è¡€å‹åˆ†å¸ƒ')
            axes[1, 0].set_xlabel('è¡€å‹ (mmHg)')
            axes[1, 0].set_ylabel('é¢‘æ¬¡')
            axes[1, 0].legend()
        
        if bp_diastolic:
            axes[1, 1].hist(bp_diastolic, bins=10, alpha=0.7, label='èˆ’å¼ å‹', color='orange')
            axes[1, 1].set_title('èˆ’å¼ å‹åˆ†å¸ƒ')
            axes[1, 1].set_xlabel('è¡€å‹ (mmHg)')
            axes[1, 1].set_ylabel('é¢‘æ¬¡')
            axes[1, 1].legend()
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'ptt_analysis_overview.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. æ—¶é—´åºåˆ—å›¾ï¼ˆé€‰æ‹©ä¸€ä¸ªæ¡ä»¶ï¼‰
        for condition in ['1', '7']:  # é™æ­¢çŠ¶æ€
            if condition in all_results and all_results[condition]['ptt_features'] is not None:
                self._plot_condition_timeseries(all_results[condition], condition, output_dir)
                break
    
    def _plot_condition_timeseries(self, condition_results, condition, output_dir):
        """ç»˜åˆ¶å•ä¸ªæ¡ä»¶çš„æ—¶é—´åºåˆ—"""
        ptt_results = condition_results['ptt_results']
        
        fig, axes = plt.subplots(3, 1, figsize=(15, 12))
        
        # PTTæ—¶é—´åºåˆ—
        if len(ptt_results['ptt_timestamps']) > 0:
            axes[0].plot(ptt_results['ptt_timestamps'], 
                        np.array(ptt_results['ptt_values']) * 1000, 'b-', alpha=0.7)
            axes[0].set_title(f'æ¡ä»¶{condition} - PTTæ—¶é—´åºåˆ—')
            axes[0].set_ylabel('PTT (ms)')
            axes[0].grid(True)
        
        # å¿ƒç‡æ—¶é—´åºåˆ—
        if len(ptt_results['hr_biopac']) > 0:
            # éœ€è¦å¯¹åº”çš„æ—¶é—´æˆ³ï¼Œè¿™é‡Œç”¨ç´¢å¼•ä»£æ›¿
            axes[1].plot(ptt_results['hr_biopac'], 'r-', alpha=0.7)
            axes[1].set_title(f'æ¡ä»¶{condition} - å¿ƒç‡æ—¶é—´åºåˆ—')
            axes[1].set_ylabel('å¿ƒç‡ (BPM)')
            axes[1].grid(True)
        
        # PTT vs å¿ƒç‡æ•£ç‚¹å›¾
        if len(ptt_results['ptt_values']) > 0 and len(ptt_results['hr_biopac']) > 0:
            min_len = min(len(ptt_results['ptt_values']), len(ptt_results['hr_biopac']))
            axes[2].scatter(np.array(ptt_results['ptt_values'][:min_len]) * 1000,
                          ptt_results['hr_biopac'][:min_len], alpha=0.6)
            axes[2].set_title(f'æ¡ä»¶{condition} - PTT vs å¿ƒç‡å…³ç³»')
            axes[2].set_xlabel('PTT (ms)')
            axes[2].set_ylabel('å¿ƒç‡ (BPM)')
            axes[2].grid(True)
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f'condition_{condition}_timeseries.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    def save_results(self, results, output_path):
        """ä¿å­˜å¤„ç†ç»“æœ"""
        np.save(output_path, results)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    def run_full_pipeline(self, output_dir="./ptt_multidevice_results"):
        """è¿è¡Œå®Œæ•´çš„å¤šè®¾å¤‡PTTè¡€å‹é¢„æµ‹æµæ°´çº¿"""
        print("å¼€å§‹PI_Labå¤šè®¾å¤‡PTTè¡€å‹é¢„æµ‹æµæ°´çº¿...")
        
        # 1. å¤„ç†æ‰€æœ‰æ¡ä»¶
        all_results = self.process_all_conditions()
        
        if not all_results:
            print("æœªèƒ½å¤„ç†ä»»ä½•æ•°æ®")
            return None
        
        # 2. é™æ­¢çŠ¶æ€vsåŠ¨æ€çŠ¶æ€åˆ†æ
        static_dynamic_analysis = self.analyze_static_vs_dynamic(all_results)
        
        # 3. æ„å»ºè¡€å‹é¢„æµ‹æ¨¡å‹ï¼ˆä½¿ç”¨é™æ­¢çŠ¶æ€æ•°æ®ï¼‰
        static_data = {k: v for k, v in all_results.items() if v['is_static']}
        if static_data:
            models_result = self.build_bp_prediction_models(static_data)
            if models_result:
                models, performance, training_data = models_result
            else:
                models, performance = None, None
        else:
            models, performance = None, None
        
        # 4. ä¿å­˜ç»“æœ
        os.makedirs(output_dir, exist_ok=True)
        
        self.save_results(all_results, os.path.join(output_dir, 'all_conditions_results.npy'))
        self.save_results(static_dynamic_analysis, os.path.join(output_dir, 'static_dynamic_analysis.npy'))
        
        if models:
            self.save_results(models, os.path.join(output_dir, 'bp_prediction_models.npy'))
            self.save_results(performance, os.path.join(output_dir, 'model_performance.npy'))
        
        # 5. ç”Ÿæˆå¯è§†åŒ–
        self.visualize_results(all_results, output_dir)
        
        # 6. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self.generate_comprehensive_report(all_results, static_dynamic_analysis, 
                                         performance, output_dir)
        
        print(f"å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
        
        return {
            'all_results': all_results,
            'static_dynamic_analysis': static_dynamic_analysis,
            'models': models,
            'performance': performance
        }
    
    def generate_comprehensive_report(self, all_results, static_dynamic_analysis, 
                                    performance, output_dir):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        report_path = os.path.join(output_dir, 'comprehensive_analysis_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("PI_Labå¤šè®¾å¤‡PTTè¡€å‹é¢„æµ‹åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            # æ•°æ®å¤„ç†æ¦‚å†µ
            f.write("1. æ•°æ®å¤„ç†æ¦‚å†µ\n")
            f.write("-" * 30 + "\n")
            successful_conditions = sum(1 for results in all_results.values() 
                                      if results['ptt_features'] is not None)
            f.write(f"æ€»å®éªŒæ¡ä»¶æ•°: {len(self.all_conditions)}\n")
            f.write(f"æˆåŠŸå¤„ç†æ¡ä»¶æ•°: {successful_conditions}\n")
            f.write(f"é™æ­¢çŠ¶æ€æ¡ä»¶: {len(self.static_conditions)} (æ¡ä»¶1, 7)\n")
            f.write(f"åŠ¨æ€çŠ¶æ€æ¡ä»¶: {len(self.all_conditions) - len(self.static_conditions)}\n\n")
            
            # PTTç‰¹å¾ç»Ÿè®¡
            f.write("2. PTTç‰¹å¾ç»Ÿè®¡\n")
            f.write("-" * 30 + "\n")
            
            all_ptt_means = []
            all_ptt_stds = []
            for condition, results in all_results.items():
                if results['ptt_features'] is not None:
                    ptt_features = results['ptt_features']
                    f.write(f"æ¡ä»¶ {condition} ({'é™æ­¢' if results['is_static'] else 'åŠ¨æ€'}):\n")
                    f.write(f"  PTTå‡å€¼: {ptt_features['ptt_mean']*1000:.1f} ms\n")
                    f.write(f"  PTTæ ‡å‡†å·®: {ptt_features['ptt_std']*1000:.1f} ms\n")
                    f.write(f"  å¿ƒç‡å‡å€¼: {ptt_features['hr_mean']:.1f} BPM\n")
                    f.write(f"  æœ‰æ•ˆå¿ƒè·³æ•°: {ptt_features['num_beats']}\n")
                    f.write(f"  è®¾å¤‡åŒæ­¥è´¨é‡: {ptt_features['sync_quality']:.3f}\n\n")
                    
                    all_ptt_means.append(ptt_features['ptt_mean'] * 1000)
                    all_ptt_stds.append(ptt_features['ptt_std'] * 1000)
            
            # æ€»ä½“PTTç»Ÿè®¡
            f.write("3. æ€»ä½“PTTç»Ÿè®¡\n")
            f.write("-" * 30 + "\n")
            if all_ptt_means:
                f.write(f"PTTå‡å€¼èŒƒå›´: {np.min(all_ptt_means):.1f} - {np.max(all_ptt_means):.1f} ms\n")
                f.write(f"PTTå‡å€¼å¹³å‡: {np.mean(all_ptt_means):.1f} ms\n")
                f.write(f"PTTå˜å¼‚æ€§èŒƒå›´: {np.min(all_ptt_stds):.1f} - {np.max(all_ptt_stds):.1f} ms\n")
                f.write(f"PTTå˜å¼‚æ€§å¹³å‡: {np.mean(all_ptt_stds):.1f} ms\n\n")
            
            # é™æ­¢vsåŠ¨æ€åˆ†æ
            f.write("4. é™æ­¢çŠ¶æ€ vs åŠ¨æ€çŠ¶æ€åˆ†æ\n")
            f.write("-" * 30 + "\n")
            if not np.isnan(static_dynamic_analysis['static_ptt_mean']):
                f.write(f"é™æ­¢çŠ¶æ€PTTå‡å€¼: {static_dynamic_analysis['static_ptt_mean']*1000:.1f} Â± {static_dynamic_analysis['static_ptt_std']*1000:.1f} ms\n")
            if not np.isnan(static_dynamic_analysis['dynamic_ptt_mean']):
                f.write(f"åŠ¨æ€çŠ¶æ€PTTå‡å€¼: {static_dynamic_analysis['dynamic_ptt_mean']*1000:.1f} Â± {static_dynamic_analysis['dynamic_ptt_std']*1000:.1f} ms\n")
            f.write(f"é™æ­¢çŠ¶æ€æ¡ä»¶æ•°: {static_dynamic_analysis['static_conditions']}\n")
            f.write(f"åŠ¨æ€çŠ¶æ€æ¡ä»¶æ•°: {static_dynamic_analysis['dynamic_conditions']}\n\n")
            
            # æ¨¡å‹æ€§èƒ½
            if performance:
                f.write("5. è¡€å‹é¢„æµ‹æ¨¡å‹æ€§èƒ½\n")
                f.write("-" * 30 + "\n")
                for bp_type, perf in performance.items():
                    f.write(f"{bp_type.capitalize()}è¡€å‹é¢„æµ‹:\n")
                    f.write(f"  çº¿æ€§å›å½’ - RÂ²: {perf['linear']['r2']:.3f}, MAE: {perf['linear']['mae']:.1f} mmHg\n")
                    f.write(f"  éšæœºæ£®æ— - RÂ²: {perf['random_forest']['r2']:.3f}, MAE: {perf['random_forest']['mae']:.1f} mmHg\n\n")
            
            # è®¾å¤‡ç‰¹æ€§åˆ†æ
            f.write("6. è®¾å¤‡ç‰¹æ€§åˆ†æ\n")
            f.write("-" * 30 + "\n")
            f.write("Biopacç³»ç»Ÿ - åŒ»ç”¨çº§è¿ç»­è¡€å‹å’Œå¿ƒç‡ç›‘æµ‹\n")
            f.write("  âœ“ æä¾›å‡†ç¡®çš„å‚è€ƒè¡€å‹æ•°æ®\n")
            f.write("  âœ“ è¿ç»­å¿ƒç‡ç›‘æµ‹ç”¨äºRæ³¢æ—¶é—´æ¨ç®—\n")
            f.write("  âœ“ å¤šç§è¡€å‹å‚æ•°(æ”¶ç¼©å‹/èˆ’å¼ å‹/å¹³å‡å‹)\n\n")
            
            f.write("HUBç³»ç»Ÿ - å¤šä¼ æ„Ÿå™¨é›†æˆè®¾å¤‡\n")
            f.write("  âœ“ PPGä¿¡å·(çº¢å…‰/çº¢å¤–/ç»¿å…‰)ç”¨äºå¤–å‘¨è„‰ææ£€æµ‹\n")
            f.write("  âœ“ IMUä¼ æ„Ÿå™¨ç”¨äºè¿åŠ¨çŠ¶æ€æ£€æµ‹\n")
            f.write("  âœ“ æ¸©åº¦ä¼ æ„Ÿå™¨ç”¨äºç¯å¢ƒç›‘æµ‹\n\n")
            
            # ç»“è®ºå’Œå»ºè®®
            f.write("7. ç»“è®ºå’Œå»ºè®®\n")
            f.write("-" * 30 + "\n")
            f.write("âœ“ æˆåŠŸå®ç°å¤šè®¾å¤‡PTTè®¡ç®—å’Œè¡€å‹é¢„æµ‹\n")
            f.write("âœ“ é™æ­¢çŠ¶æ€æ•°æ®è´¨é‡è¾ƒå¥½ï¼Œé€‚åˆè¡€å‹é¢„æµ‹å»ºæ¨¡\n")
            f.write("âœ“ è®¾å¤‡é—´æ—¶é—´åŒæ­¥è´¨é‡å½±å“PTTè®¡ç®—ç²¾åº¦\n")
            f.write("âœ“ å»ºè®®ä¼˜åŒ–ä¿¡å·é¢„å¤„ç†ç®—æ³•æé«˜å³°å€¼æ£€æµ‹å‡†ç¡®æ€§\n")
            f.write("âœ“ å¯è€ƒè™‘å¢åŠ æ›´å¤šç”Ÿç†ç‰¹å¾æé«˜é¢„æµ‹ç²¾åº¦\n")
        
        print(f"ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = MultiDevicePTTProcessor(
        data_root="/root/PI_Lab/00017",
        sampling_rate=100
    )
    
    # è¿è¡Œå®Œæ•´æµæ°´çº¿
    results = processor.run_full_pipeline("./ptt_multidevice_results")
    
    if results:
        print("\nğŸ‰ å¤šè®¾å¤‡PTTè¡€å‹é¢„æµ‹å¤„ç†æˆåŠŸå®Œæˆ!")
        print(f"ğŸ“Š å¤„ç†æ¡ä»¶æ•°: {len(results['all_results'])}")
        
        if results['models']:
            print("ğŸ¤– è¡€å‹é¢„æµ‹æ¨¡å‹å·²è®­ç»ƒå®Œæˆ")
        
        print("ğŸ“ ç»“æœæ–‡ä»¶:")
        print("  - all_conditions_results.npy: æ‰€æœ‰æ¡ä»¶å¤„ç†ç»“æœ")
        print("  - bp_prediction_models.npy: è¡€å‹é¢„æµ‹æ¨¡å‹")
        print("  - ptt_analysis_overview.png: PTTåˆ†ææ¦‚è§ˆå›¾")
        print("  - comprehensive_analysis_report.txt: ç»¼åˆåˆ†ææŠ¥å‘Š")
    else:
        print("âŒ å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ ¼å¼") 