#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ï¿½ï¿½ IRé€šé“ä¸“é—¨çš„PTTå³°å€¼æ£€æµ‹å™¨ - ä¼˜åŒ–è¾“å‡ºä¸PTTå‡†å¤‡

åŸºäºå¸ˆå…„å»ºè®®çš„æ”¹è¿›ï¼š
1. âœ… ä¸“æ³¨IRé€šé“å³°å€¼æ£€æµ‹ï¼ˆä¿¡å·è´¨é‡æœ€ä½³ï¼‰
2. âœ… ä½¿ç”¨neurokit2è®¡ç®—IBIå¹¶éªŒè¯
3. âœ… åŒä¸€å¿ƒè·³åŒºé—´çš„å³°å€¼åŒ¹é…
4. âœ… è¾“å‡ºå³°å€¼ã€IBIå’ŒPTTé¢„è§ˆCSVï¼Œæ–¹ä¾¿åç»­å¤„ç†

æ ¸å¿ƒåŸç†ï¼š
- PTTä½¿ç”¨å³°å€¼æ—¶é—´å·®è®¡ç®—
- IRé€šé“ä¿¡å·æœ€ç¨³å®š
- IBIéªŒè¯ç¡®ä¿å³°å€¼å‡†ç¡®
- 4ä¼ æ„Ÿå™¨ç”Ÿæˆ6ä¸ªPTTç»„åˆ
"""

import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
from scipy.signal import butter, filtfilt, find_peaks
import warnings
warnings.filterwarnings('ignore')

# ç®€åŒ–matplotlibè®¾ç½®ï¼Œé¿å…å­—ä½“è­¦å‘Š
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

class IRBasedPTTPeakDetector:
    """åŸºäºIRé€šé“çš„PTTå³°å€¼æ£€æµ‹å™¨"""
    
    def __init__(self, data_path="/root/PI_Lab/output/csv_output"):
        self.data_path = data_path
        self.output_dir = "/root/PI_Lab/ptt_output"
        self.sensors = ['sensor2', 'sensor3', 'sensor4', 'sensor5']
        self.target_channel = 'ir'
        self.sensor_mapping = {
            'sensor2': 'nose', 'sensor3': 'finger', 
            'sensor4': 'wrist', 'sensor5': 'ear'
        }
        self.fs = 100  # é‡‡æ ·ç‡100Hz
        self.min_hr = 50
        self.max_hr = 200
        self.refractory_period = 0.3
        self.filter_lowcut = 0.5
        self.filter_highcut = 3.0
        self.filter_order = 3
        self.ibi_tolerance = 0.15  # IBIå®¹å·®15%ï¼Œç¨å¾®æ”¾å®½
        os.makedirs(self.output_dir, exist_ok=True)
        
    def bandpass_filter(self, data, lowcut=0.5, highcut=3.0, fs=100, order=3):
        """å¸¦é€šæ»¤æ³¢ - é’ˆå¯¹å¿ƒç‡é¢‘æ®µ"""
        try:
            nyquist = fs / 2
            low = max(lowcut / nyquist, 0.01)
            high = min(highcut / nyquist, 0.99)
            b, a = butter(order, [low, high], btype='band')
            return filtfilt(b, a, data)
        except Exception as e:
            print(f"âš ï¸  æ»¤æ³¢å¤±è´¥: {e}")
            return data
    
    def detect_peaks_robust(self, signal, fs=100):
        """ç¨³å¥çš„å³°å€¼æ£€æµ‹ - ç»“åˆåº“å‡½æ•°å’Œè‡ªå®šä¹‰ç®—æ³•"""
        try:
            # å…ˆè¿›è¡Œæ»¤æ³¢
            filtered_signal = self.bandpass_filter(signal, self.filter_lowcut, self.filter_highcut, fs)
            
            # ä½¿ç”¨scipyè¿›è¡ŒåŸºç¡€å³°å€¼æ£€æµ‹
            min_distance = int(self.refractory_period * fs)  # 0.3ç§’æœ€å°é—´éš”
            
            # è‡ªé€‚åº”é˜ˆå€¼
            signal_std = np.std(filtered_signal)
            signal_mean = np.mean(filtered_signal)
            height_threshold = signal_mean + 0.3 * signal_std
            prominence_threshold = 0.15 * signal_std
            
            peaks, properties = find_peaks(
                filtered_signal,
                height=height_threshold,
                distance=min_distance,
                prominence=prominence_threshold
            )
            
            if len(peaks) < 2:
                return {
                    'peaks': np.array([]),
                    'ibi_ms': np.array([]),
                    'filtered_signal': filtered_signal,
                    'peak_times': np.array([]),
                    'peak_count': 0,
                    'quality': 'poor'
                }
            
            # è®¡ç®—IBIå¹¶è¿›è¡Œè´¨é‡æ§åˆ¶
            peak_times = peaks / fs
            ibi_ms = np.diff(peak_times) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # IBIè´¨é‡æ§åˆ¶ï¼š300-1200ms (50-200 BPM)
            valid_ibi_mask = (ibi_ms >= 300) & (ibi_ms <= 1200)
            valid_ratio = np.sum(valid_ibi_mask) / len(ibi_ms) if len(ibi_ms) > 0 else 0
            
            # å¦‚æœæœ‰æ•ˆIBIæ¯”ä¾‹å¤ªä½ï¼Œå°è¯•è°ƒæ•´é˜ˆå€¼
            if valid_ratio < 0.7 and len(peaks) > 10:
                # æ›´ä¿å®ˆçš„å³°å€¼æ£€æµ‹
                height_threshold = signal_mean + 0.5 * signal_std
                peaks, _ = find_peaks(
                    filtered_signal,
                    height=height_threshold,
                    distance=min_distance,
                    prominence=prominence_threshold * 1.5
                )
                peak_times = peaks / fs
                ibi_ms = np.diff(peak_times) * 1000
                valid_ibi_mask = (ibi_ms >= 300) & (ibi_ms <= 1200)
                valid_ratio = np.sum(valid_ibi_mask) / len(ibi_ms) if len(ibi_ms) > 0 else 0
            
            # è´¨é‡è¯„ä¼°
            if valid_ratio >= 0.8:
                quality = 'excellent'
            elif valid_ratio >= 0.6:
                quality = 'good'
            elif valid_ratio >= 0.4:
                quality = 'fair'
            else:
                quality = 'poor'
            
            return {
                'peaks': peaks,
                'ibi_ms': ibi_ms,
                'filtered_signal': filtered_signal,
                'peak_times': peak_times,
                'peak_count': len(peaks),
                'quality': quality,
                'valid_ibi_ratio': valid_ratio
            }
            
        except Exception as e:
            print(f"âš ï¸  å³°å€¼æ£€æµ‹å¤±è´¥: {e}")
            return {
                'peaks': np.array([]),
                'ibi_ms': np.array([]),
                'filtered_signal': signal,
                'peak_times': np.array([]),
                'peak_count': 0,
                'quality': 'error'
            }
    
    def calculate_heart_rate_stats(self, ibi_ms):
        """è®¡ç®—å¿ƒç‡ç»Ÿè®¡ä¿¡æ¯"""
        if len(ibi_ms) == 0:
            return {
                'hr_mean': 0,
                'hr_std': 0,
                'ibi_mean': 0,
                'ibi_std': 0,
                'rmssd': 0,  # HRVæŒ‡æ ‡
                'pnn50': 0   # HRVæŒ‡æ ‡
            }
        
        # åŸºç¡€ç»Ÿè®¡
        hr_bpm = 60000 / ibi_ms  # è½¬æ¢ä¸ºBPM
        ibi_mean = np.mean(ibi_ms)
        ibi_std = np.std(ibi_ms)
        hr_mean = np.mean(hr_bpm)
        hr_std = np.std(hr_bpm)
        
        # HRVæŒ‡æ ‡
        if len(ibi_ms) > 1:
            # RMSSD: ç›¸é‚»IBIå·®å€¼çš„å‡æ–¹æ ¹
            diff_ibi = np.diff(ibi_ms)
            rmssd = np.sqrt(np.mean(diff_ibi**2))
            
            # pNN50: ç›¸é‚»IBIå·®å€¼>50msçš„ç™¾åˆ†æ¯”
            pnn50 = np.sum(np.abs(diff_ibi) > 50) / len(diff_ibi) * 100
        else:
            rmssd = 0
            pnn50 = 0
        
        return {
            'hr_mean': hr_mean,
            'hr_std': hr_std,
            'ibi_mean': ibi_mean,
            'ibi_std': ibi_std,
            'rmssd': rmssd,
            'pnn50': pnn50
        }
    
    def match_peaks_across_sensors(self, sensor_results):
        """åŒ¹é…ä¸åŒä¼ æ„Ÿå™¨é—´åŒä¸€å¿ƒè·³çš„å³°å€¼"""
        try:
            # åªä½¿ç”¨è´¨é‡goodä»¥ä¸Šçš„ä¼ æ„Ÿå™¨
            valid_sensors = [s for s in self.sensors 
                           if s in sensor_results 
                           and sensor_results[s]['peak_count'] > 5
                           and sensor_results[s]['quality'] in ['excellent', 'good']]
            
            if len(valid_sensors) < 2:
                print("âš ï¸  é«˜è´¨é‡ä¼ æ„Ÿå™¨æ•°é‡ä¸è¶³ï¼Œå°è¯•æ”¾å®½æ ‡å‡†")
                # æ”¾å®½æ ‡å‡†ï¼ŒåŒ…æ‹¬fairè´¨é‡
                valid_sensors = [s for s in self.sensors 
                               if s in sensor_results 
                               and sensor_results[s]['peak_count'] > 3
                               and sensor_results[s]['quality'] != 'error']
            
            if len(valid_sensors) < 2:
                print("âš ï¸  æœ‰æ•ˆä¼ æ„Ÿå™¨æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå³°å€¼åŒ¹é…")
                return {}
            
            print(f"ğŸ“ æœ‰æ•ˆä¼ æ„Ÿå™¨: {valid_sensors}")
            
            # é€‰æ‹©è´¨é‡æœ€å¥½çš„ä½œä¸ºå‚è€ƒ
            reference_sensor = max(valid_sensors, 
                                 key=lambda s: sensor_results[s]['valid_ibi_ratio'])
            reference_peaks = sensor_results[reference_sensor]['peak_times']
            
            print(f"ğŸ“ å‚è€ƒä¼ æ„Ÿå™¨: {reference_sensor} (è´¨é‡: {sensor_results[reference_sensor]['quality']})")
            
            # ä¸ºæ¯ä¸ªå¿ƒè·³åˆ›å»ºæ—¶é—´çª—å£
            heartbeat_windows = []
            for i, ref_time in enumerate(reference_peaks):
                if i == 0:
                    window_start = 0
                    if len(reference_peaks) > 1:
                        window_end = ref_time + (reference_peaks[1] - reference_peaks[0])/2
                    else:
                        window_end = ref_time + 0.5
                elif i == len(reference_peaks) - 1:
                    window_start = ref_time - (reference_peaks[i] - reference_peaks[i-1])/2
                    window_end = float('inf')
                else:
                    window_start = ref_time - (reference_peaks[i] - reference_peaks[i-1])/2
                    window_end = ref_time + (reference_peaks[i+1] - reference_peaks[i])/2
                
                heartbeat_windows.append({
                    'heartbeat_id': i + 1,
                    'reference_time': ref_time,
                    'window_start': window_start,
                    'window_end': window_end,
                    'sensor_peaks': {reference_sensor: ref_time}
                })
            
            # ä¸ºå…¶ä»–ä¼ æ„Ÿå™¨åŒ¹é…å³°å€¼
            for sensor in valid_sensors:
                if sensor == reference_sensor:
                    continue
                    
                sensor_peaks = sensor_results[sensor]['peak_times']
                
                for peak_time in sensor_peaks:
                    # æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„å¿ƒè·³çª—å£
                    best_window = None
                    min_distance = float('inf')
                    
                    for window in heartbeat_windows:
                        if window['window_start'] <= peak_time <= window['window_end']:
                            distance = abs(peak_time - window['reference_time'])
                            if distance < min_distance:
                                min_distance = distance
                                best_window = window
                    
                    # å°†å³°å€¼åˆ†é…åˆ°æœ€ä½³çª—å£
                    if best_window is not None and min_distance < 0.2:  # 200mså®¹å·®
                        best_window['sensor_peaks'][sensor] = peak_time
            
            # è¿‡æ»¤å®Œæ•´çš„å¿ƒè·³ï¼ˆè‡³å°‘æœ‰2ä¸ªä¼ æ„Ÿå™¨ï¼‰
            complete_heartbeats = [hb for hb in heartbeat_windows 
                                 if len(hb['sensor_peaks']) >= 2]
            
            print(f"ğŸ“Š å®Œæ•´å¿ƒè·³æ•°é‡: {len(complete_heartbeats)}/{len(heartbeat_windows)}")
            
            return {
                'heartbeat_windows': heartbeat_windows,
                'complete_heartbeats': complete_heartbeats,
                'valid_sensors': valid_sensors,
                'reference_sensor': reference_sensor
            }
            
        except Exception as e:
            print(f"âš ï¸  å³°å€¼åŒ¹é…å¤±è´¥: {e}")
            return {}
    
    def process_experiment(self, exp_id):
        """å¤„ç†å•ä¸ªå®éªŒçš„IRé€šé“æ•°æ®"""
        print(f"\nğŸ” å¼€å§‹å¤„ç†å®éªŒ {exp_id} - ä¸“æ³¨IRé€šé“")
        
        sensor_results = {}
        all_signals = {}
        
        for sensor in self.sensors:
            try:
                file_path = os.path.join(self.data_path, f"{exp_id}_hub_{sensor}_aligned.csv")
                if not os.path.exists(file_path):
                    print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    continue
                
                df = pd.read_csv(file_path)
                all_signals[sensor] = df
                
                if len(df.columns) >= 3:
                    ir_signal = df.iloc[:, 2].values  # IRé€šé“
                    
                    # ç¨³å¥çš„å³°å€¼æ£€æµ‹
                    peak_result = self.detect_peaks_robust(ir_signal, self.fs)
                    
                    # è®¡ç®—å¿ƒç‡ç»Ÿè®¡
                    hr_stats = self.calculate_heart_rate_stats(peak_result['ibi_ms'])
                    
                    # åˆå¹¶ç»“æœ
                    peak_result.update({
                        'sensor': sensor,
                        'sensor_name': self.sensor_mapping[sensor],
                        **hr_stats
                    })
                    
                    sensor_results[sensor] = peak_result
                    
                    # æ‰“å°ç»“æœ
                    quality_emoji = {
                        'excellent': 'ğŸŸ¢', 'good': 'ğŸŸ¡', 
                        'fair': 'ğŸŸ ', 'poor': 'ğŸ”´', 'error': 'âŒ'
                    }
                    quality_symbol = quality_emoji.get(peak_result['quality'], 'â“')
                    
                    if peak_result['peak_count'] > 0:
                        ibi_range = f"{np.min(peak_result['ibi_ms']):.0f}-{np.max(peak_result['ibi_ms']):.0f}ms" if len(peak_result['ibi_ms']) > 0 else "N/A"
                        print(f"  {quality_symbol} {sensor}({self.sensor_mapping[sensor]}): "
                              f"{peak_result['peak_count']}å³°å€¼, "
                              f"HR={hr_stats['hr_mean']:.1f}Â±{hr_stats['hr_std']:.1f}BPM, "
                              f"IBI={ibi_range}, "
                              f"è´¨é‡={peak_result['quality']}({peak_result.get('valid_ibi_ratio', 0)*100:.0f}%)")
                    else:
                        print(f"  {quality_symbol} {sensor}({self.sensor_mapping[sensor]}): æœªæ£€æµ‹åˆ°æœ‰æ•ˆå³°å€¼")
                        
                else:
                    print(f"âš ï¸  {sensor}: æ•°æ®åˆ—ä¸è¶³")
                    
            except Exception as e:
                print(f"âŒ å¤„ç† {sensor} å¤±è´¥: {e}")
                continue
        
        # åŒ¹é…ä¸åŒä¼ æ„Ÿå™¨é—´çš„å³°å€¼
        matched_results = self.match_peaks_across_sensors(sensor_results)
        
        # ä¿å­˜ç»“æœ
        self.save_results(exp_id, sensor_results, matched_results, all_signals)
        
        return sensor_results, matched_results
    
    def save_results(self, exp_id, sensor_results, matched_results, all_signals):
        """ä¿å­˜æ£€æµ‹ç»“æœ - 5ä¸ªæ ¸å¿ƒCSVæ–‡ä»¶"""
        try:
            # 1. ä¼ æ„Ÿå™¨è´¨é‡æ±‡æ€»
            sensor_summary = []
            for sensor in sensor_results:
                result = sensor_results[sensor]
                signal_duration = len(all_signals[sensor].iloc[:, 2]) / self.fs  # ä¿¡å·æ—¶é•¿(ç§’)
                
                sensor_summary.append({
                    'sensor': sensor,
                    'sensor_name': result['sensor_name'],
                    'peak_count': result['peak_count'],
                    'quality': result['quality'],
                    'valid_ibi_ratio': result.get('valid_ibi_ratio', 0),
                    'hr_mean_bpm': result['hr_mean'],
                    'hr_std_bpm': result['hr_std'],
                    'ibi_mean_ms': result['ibi_mean'],
                    'ibi_std_ms': result['ibi_std'],
                    'rmssd_ms': result['rmssd'],
                    'pnn50_percent': result['pnn50'],
                    'signal_duration_s': signal_duration
                })
            
            if sensor_summary:
                summary_df = pd.DataFrame(sensor_summary)
                summary_file = os.path.join(self.output_dir, f"sensor_summary_exp_{exp_id}.csv")
                summary_df.to_csv(summary_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜ä¼ æ„Ÿå™¨æ±‡æ€»: {summary_file}")
            
            # 2. æ‰€æœ‰å³°å€¼è¯¦ç»†ä¿¡æ¯
            all_peaks = []
            for sensor in sensor_results:
                result = sensor_results[sensor]
                for i, (peak_idx, peak_time) in enumerate(zip(result['peaks'], result['peak_times'])):
                    all_peaks.append({
                        'sensor': sensor,
                        'sensor_name': result['sensor_name'],
                        'peak_number': i + 1,
                        'peak_index': int(peak_idx),
                        'peak_time_s': peak_time,
                        'quality': result['quality']
                    })
            
            if all_peaks:
                peaks_df = pd.DataFrame(all_peaks)
                peaks_file = os.path.join(self.output_dir, f"all_peaks_exp_{exp_id}.csv")
                peaks_df.to_csv(peaks_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜æ‰€æœ‰å³°å€¼: {peaks_file}")
            
            # 3. æ‰€æœ‰IBIè¯¦ç»†ä¿¡æ¯
            all_ibi = []
            for sensor in sensor_results:
                result = sensor_results[sensor]
                for i, ibi_val in enumerate(result['ibi_ms']):
                    all_ibi.append({
                        'sensor': sensor,
                        'sensor_name': result['sensor_name'],
                        'ibi_number': i + 1,
                        'ibi_ms': ibi_val,
                        'hr_bpm': 60000 / ibi_val,
                        'is_valid': 300 <= ibi_val <= 1200,
                        'quality': result['quality']
                    })
            
            if all_ibi:
                ibi_df = pd.DataFrame(all_ibi)
                ibi_file = os.path.join(self.output_dir, f"all_ibi_exp_{exp_id}.csv")
                ibi_df.to_csv(ibi_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜æ‰€æœ‰IBI: {ibi_file}")
            
            # 4. åŒ¹é…çš„å¿ƒè·³å’ŒPTTè®¡ç®—
            if matched_results and 'complete_heartbeats' in matched_results:
                heartbeat_data = []
                for hb in matched_results['complete_heartbeats']:
                    row = {'heartbeat_id': hb['heartbeat_id']}
                    for sensor in matched_results['valid_sensors']:
                        row[f'{sensor}_peak_time_s'] = hb['sensor_peaks'].get(sensor, np.nan)
                    heartbeat_data.append(row)
                
                if heartbeat_data:
                    heartbeat_df = pd.DataFrame(heartbeat_data)
                    heartbeat_file = os.path.join(self.output_dir, f"matched_heartbeats_exp_{exp_id}.csv")
                    heartbeat_df.to_csv(heartbeat_file, index=False)
                    print(f"ğŸ’¾ ä¿å­˜åŒ¹é…å¿ƒè·³: {heartbeat_file}")
                    
                    # è®¡ç®—PTTçŸ©é˜µå’Œæ—¶é—´åºåˆ—
                    self.calculate_ptt_analysis(heartbeat_df, exp_id, matched_results['valid_sensors'])
            
            # ç”Ÿæˆå¯è§†åŒ–
            self.create_visualizations(exp_id, sensor_results, matched_results, all_signals)
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def calculate_ptt_analysis(self, heartbeat_df, exp_id, valid_sensors):
        """è®¡ç®—PTTåˆ†æ - çŸ©é˜µæ±‡æ€» + æ—¶é—´åºåˆ—"""
        try:
            # ç”Ÿæˆæ‰€æœ‰ä¼ æ„Ÿå™¨ç»„åˆ
            sensor_combinations = []
            for i in range(len(valid_sensors)):
                for j in range(i+1, len(valid_sensors)):
                    sensor_combinations.append((valid_sensors[i], valid_sensors[j]))
            
            print(f"\nğŸ“Š PTTåˆ†æ ({len(sensor_combinations)}ä¸ªä¼ æ„Ÿå™¨ç»„åˆ):")
            
            # PTTçŸ©é˜µæ±‡æ€»
            ptt_summary = []
            ptt_timeseries_all = []
            
            for sensor1, sensor2 in sensor_combinations:
                col1 = f'{sensor1}_peak_time_s'
                col2 = f'{sensor2}_peak_time_s'
                
                if col1 in heartbeat_df.columns and col2 in heartbeat_df.columns:
                    valid_data = heartbeat_df.dropna(subset=[col1, col2])
                    
                    if len(valid_data) > 0:
                        ptt_values = (valid_data[col2] - valid_data[col1]) * 1000  # è½¬æ¢ä¸ºms
                        
                        # æ±‡æ€»ç»Ÿè®¡
                        ptt_summary.append({
                            'sensor_pair': f"{sensor1}-{sensor2}",
                            'sensor_names': f"{self.sensor_mapping[sensor1]}â†’{self.sensor_mapping[sensor2]}",
                            'valid_heartbeats': len(valid_data),
                            'mean_ptt_ms': np.mean(ptt_values),
                            'std_ptt_ms': np.std(ptt_values),
                            'min_ptt_ms': np.min(ptt_values),
                            'max_ptt_ms': np.max(ptt_values),
                            'median_ptt_ms': np.median(ptt_values),
                            'q25_ptt_ms': np.percentile(ptt_values, 25),
                            'q75_ptt_ms': np.percentile(ptt_values, 75)
                        })
                        
                        # æ—¶é—´åºåˆ—æ•°æ®
                        for idx, (heartbeat_id, ptt_val) in enumerate(zip(valid_data['heartbeat_id'], ptt_values)):
                            ptt_timeseries_all.append({
                                'heartbeat_id': heartbeat_id,
                                'sensor_pair': f"{sensor1}-{sensor2}",
                                'sensor_names': f"{self.sensor_mapping[sensor1]}â†’{self.sensor_mapping[sensor2]}",
                                'ptt_ms': ptt_val,
                                f'{sensor1}_time_s': valid_data[col1].iloc[idx],
                                f'{sensor2}_time_s': valid_data[col2].iloc[idx]
                            })
                        
                        print(f"  ğŸ“Š {self.sensor_mapping[sensor1]}â†’{self.sensor_mapping[sensor2]}: "
                              f"{np.mean(ptt_values):.1f}Â±{np.std(ptt_values):.1f}ms "
                              f"({len(valid_data)}å¿ƒè·³)")
            
            # 5. ä¿å­˜PTTçŸ©é˜µæ±‡æ€»
            if ptt_summary:
                ptt_matrix_df = pd.DataFrame(ptt_summary)
                ptt_matrix_file = os.path.join(self.output_dir, f"ptt_matrix_exp_{exp_id}.csv")
                ptt_matrix_df.to_csv(ptt_matrix_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜PTTçŸ©é˜µ: {ptt_matrix_file}")
            
            # 6. ä¿å­˜PTTæ—¶é—´åºåˆ—ï¼ˆç”¨äºå»ºæ¨¡ï¼‰
            if ptt_timeseries_all:
                ptt_timeseries_df = pd.DataFrame(ptt_timeseries_all)
                ptt_timeseries_file = os.path.join(self.output_dir, f"ptt_timeseries_exp_{exp_id}.csv")
                ptt_timeseries_df.to_csv(ptt_timeseries_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜PTTæ—¶é—´åºåˆ—: {ptt_timeseries_file}")
                print(f"   ğŸ“ˆ å…±{len(ptt_timeseries_all)}ä¸ªPTTæ•°æ®ç‚¹ï¼Œå¯ç”¨äºè¡€å‹å»ºæ¨¡")
            
        except Exception as e:
            print(f"âš ï¸  PTTåˆ†æå¤±è´¥: {e}")
    
    def create_visualizations(self, exp_id, sensor_results, matched_results, all_signals):
        """åˆ›å»ºç®€åŒ–å¯è§†åŒ–"""
        try:
            fig, axes = plt.subplots(len(self.sensors), 1, figsize=(16, 3*len(self.sensors)), sharex=True)
            if len(self.sensors) == 1:
                axes = [axes]
            
            colors = ['red', 'blue', 'green', 'orange']
            
            for idx, sensor in enumerate(self.sensors):
                ax = axes[idx]
                
                if sensor in all_signals and sensor in sensor_results:
                    df = all_signals[sensor]
                    time = df['timestamp'].values - df['timestamp'].values[0]
                    filtered_signal = sensor_results[sensor]['filtered_signal']
                    peaks = sensor_results[sensor]['peaks']
                    quality = sensor_results[sensor]['quality']
                    
                    # ç»˜åˆ¶æ»¤æ³¢ä¿¡å·
                    ax.plot(time[:len(filtered_signal)], filtered_signal, 
                           color=colors[idx % len(colors)], linewidth=1.5, alpha=0.8,
                           label=f'{self.sensor_mapping[sensor]} IR')
                    
                    # æ ‡è®°å³°å€¼
                    if len(peaks) > 0:
                        peak_times = peaks / self.fs
                        ax.scatter(peak_times, filtered_signal[peaks], 
                                 color='red', s=40, zorder=5, alpha=0.9)
                        
                        # æ¯10ä¸ªå³°å€¼æ˜¾ç¤ºä¸€ä¸ªæ ‡å·
                        for i, (pt, ps) in enumerate(zip(peak_times, filtered_signal[peaks])):
                            if i % 10 == 0:
                                ax.annotate(f'{i+1}', (pt, ps), xytext=(5, 5), 
                                          textcoords='offset points', fontsize=8)
                    
                    # è®¾ç½®æ ‡é¢˜
                    hr_mean = sensor_results[sensor]['hr_mean']
                    ax.set_title(f'{self.sensor_mapping[sensor]} IR - {quality} - HR: {hr_mean:.1f} BPM', 
                                fontsize=12, fontweight='bold')
                    ax.set_ylabel('Signal', fontsize=10)
                    ax.grid(True, alpha=0.3)
                    ax.legend()
                else:
                    ax.text(0.5, 0.5, f'{self.sensor_mapping[sensor]}: No Data', 
                           ha='center', va='center', transform=ax.transAxes)
                    ax.set_title(f'{self.sensor_mapping[sensor]} IR - No Data')
            
            axes[-1].set_xlabel('Time (seconds)', fontsize=12)
            plt.suptitle(f'Experiment {exp_id} - IR Channel Peak Detection', 
                        fontsize=16, fontweight='bold')
            plt.tight_layout()
            
            plot_file = os.path.join(self.output_dir, f"ir_peaks_exp_{exp_id}.png")
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“Š ä¿å­˜å¯è§†åŒ–: {plot_file}")
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {e}")
    
    def run_analysis(self, experiment_list=None):
        """è¿è¡ŒIRé€šé“PTTå³°å€¼æ£€æµ‹åˆ†æ"""
        if experiment_list is None:
            experiment_list = [f.split('_')[0] for f in os.listdir(self.data_path) 
                             if f.endswith('_hub_sensor2_aligned.csv')]
            experiment_list = sorted(list(set(experiment_list)))
        
        print(f"\nğŸ”¬ å¼€å§‹IRé€šé“PTTå³°å€¼æ£€æµ‹åˆ†æ")
        print(f"ğŸ“‹ å®éªŒåˆ—è¡¨: {experiment_list}")
        print(f"ğŸ¯ æ£€æµ‹ç­–ç•¥:")
        print(f"   - ä¸“æ³¨IRé€šé“ï¼ˆä¿¡å·è´¨é‡æœ€ä½³ï¼‰")
        print(f"   - ç¨³å¥å³°å€¼æ£€æµ‹ + IBIè´¨é‡æ§åˆ¶")
        print(f"   - å¿ƒç‡èŒƒå›´: {self.min_hr}-{self.max_hr} BPM")
        print(f"   - æ»¤æ³¢èŒƒå›´: {self.filter_lowcut}-{self.filter_highcut} Hz")
        print(f"   - è¾“å‡º5ä¸ªæ ‡å‡†CSVæ–‡ä»¶")
        
        all_results = {}
        
        for exp_id in tqdm(experiment_list, desc="å¤„ç†å®éªŒ"):
            try:
                sensor_results, matched_results = self.process_experiment(exp_id)
                all_results[exp_id] = {
                    'sensor_results': sensor_results,
                    'matched_results': matched_results
                }
            except Exception as e:
                print(f"âŒ å®éªŒ {exp_id} å¤„ç†å¤±è´¥: {e}")
                continue
        
        print(f"\nâœ… IRé€šé“PTTå³°å€¼æ£€æµ‹å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}")
        print(f"\nğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜:")
        print(f"   1. sensor_summary_exp_X.csv - ä¼ æ„Ÿå™¨è´¨é‡æ±‡æ€»")
        print(f"   2. all_peaks_exp_X.csv - æ‰€æœ‰å³°å€¼è¯¦ç»†ä¿¡æ¯")
        print(f"   3. all_ibi_exp_X.csv - æ‰€æœ‰IBIè¯¦ç»†ä¿¡æ¯")
        print(f"   4. ptt_matrix_exp_X.csv - PTTçŸ©é˜µæ±‡æ€»")
        print(f"   5. ptt_timeseries_exp_X.csv - PTTæ—¶é—´åºåˆ—ï¼ˆç”¨äºå»ºæ¨¡ï¼‰")
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥: ä½¿ç”¨ptt_timeseries_exp_X.csvè¿›è¡Œè¡€å‹å»ºæ¨¡")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ©º IRé€šé“ä¸“é—¨çš„PTTå³°å€¼æ£€æµ‹å™¨")
    print("=" * 60)
    print("ğŸ“– ä¼˜åŒ–ç‰¹æ€§:")
    print("   â€¢ ä¸“æ³¨IRé€šé“å³°å€¼æ£€æµ‹")
    print("   â€¢ ç¨³å¥çš„IBIè®¡ç®—å’Œè´¨é‡æ§åˆ¶")
    print("   â€¢ æ™ºèƒ½å¿ƒè·³åŒ¹é…")
    print("   â€¢ æ ‡å‡†åŒ–CSVè¾“å‡ºä¾¿äºå»ºæ¨¡")
    print("=" * 60)
    
    detector = IRBasedPTTPeakDetector()
    results = detector.run_analysis(['1'])
    
    print("\nğŸ¯ åˆ†æå®Œæˆï¼Œå»ºè®®ä¸‹ä¸€æ­¥:")
    print("1. æ£€æŸ¥sensor_summary_exp_1.csväº†è§£ä¼ æ„Ÿå™¨è´¨é‡")
    print("2. ä½¿ç”¨ptt_timeseries_exp_1.csvè¿›è¡Œè¡€å‹å»ºæ¨¡")
    print("3. éªŒè¯PTTä¸è¡€å‹çš„ç›¸å…³æ€§ (a*PTT + b)")

if __name__ == "__main__":
    main() 