#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PTTä¸è¡€å‹ç›¸å…³æ€§åˆ†æ
åŸºäºå¸ˆå…„å»ºè®®ï¼šä½¿ç”¨åˆç†åŒºé—´çš„PTTæ•°æ®åˆ†æä¸è¡€å‹çš„ç›¸å…³æ€§
"""

import os
import pickle
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®éäº¤äº’æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºå¼¹çª—
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾ç‰‡ä¿å­˜æ¨¡å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.ioff()  # å…³é—­äº¤äº’æ¨¡å¼

class PTTBloodPressureAnalyzer:
    """PTTä¸è¡€å‹ç›¸å…³æ€§åˆ†æå™¨"""
    
    def __init__(self, output_dir="ptt_bp_analysis"):
        self.output_dir = output_dir
        self.ptt_output_dir = "ptt_output"  # çª—å£åŒ–PTTæ•°æ®ç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # è¡€å‹ç›¸å…³ç”Ÿç†æŒ‡æ ‡æ˜ å°„ï¼ˆè‹±æ–‡ä¸“ä¸šæœ¯è¯­ï¼‰
        self.physiological_indicators = {
            'systolic_bp': 'Systolic BP (mmHg)',
            'diastolic_bp': 'Diastolic BP (mmHg)', 
            'mean_bp': 'Mean Arterial Pressure (mmHg)',
        }
        
        # PTTä¼ æ„Ÿå™¨ç»„åˆï¼ˆè‹±æ–‡æ ‡ç­¾ï¼‰
        self.ptt_combinations_en = {
            'sensor2-sensor3': 'Noseâ†’Finger',
            'sensor2-sensor4': 'Noseâ†’Wrist', 
            'sensor2-sensor5': 'Noseâ†’Ear',
            'sensor3-sensor4': 'Fingerâ†’Wrist',
            'sensor3-sensor5': 'Fingerâ†’Ear',
            'sensor4-sensor5': 'Wristâ†’Ear'
        }
        
        print("ğŸ”¬ Enhanced PTT-Cardiovascular Parameters Correlation Analyzer")
        print(f"ğŸ“ Results will be saved to: {self.output_dir}")
        print(f"ğŸ“Š Analyzing {len(self.physiological_indicators)} physiological indicators")
        print(f"ğŸ¯ Using {len(self.ptt_combinations_en)} PTT sensor combinations")
    
    def load_ground_truth_bp(self, exp_id):
        """åŠ è½½ç”Ÿç†æŒ‡æ ‡æ•°æ®ï¼ˆä»CSVæ–‡ä»¶ï¼‰"""
        try:
            # åŠ è½½CSVæ–‡ä»¶ï¼ˆä¿®æ­£æ–‡ä»¶åï¼‰
            csv_file = os.path.join(self.csv_output_dir, f'{self.subject}_{exp_id}_biopac_aligned.csv')
            if not os.path.exists(csv_file):
                print(f"âŒ ç”Ÿç†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            # è¯»å–å®Œæ•´ç”Ÿç†æ•°æ®
            df = pd.read_csv(csv_file)
            print(f"âœ… åŠ è½½ç”Ÿç†æ•°æ®: {len(df)}æ¡è®°å½•")
            
            # æ˜¾ç¤ºå¯ç”¨çš„ç”Ÿç†æŒ‡æ ‡
            available_indicators = [col for col in df.columns if col in self.physiological_indicators.keys()]
            print(f"ğŸ“Š å¯ç”¨ç”Ÿç†æŒ‡æ ‡: {available_indicators}")
            
            return df
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç”Ÿç†æ•°æ®å¤±è´¥: {e}")
            return None
    
    def load_ptt_data(self, exp_id):
        """åŠ è½½æœ‰æ•ˆçª—å£çš„PTTæ•°æ®"""
        try:
            # åŠ è½½çª—å£éªŒè¯æ•°æ®
            window_file = f"{self.ptt_output_dir}/exp_{exp_id}/window_validation_exp_{exp_id}.csv"
            ptt_file = f"{self.ptt_output_dir}/exp_{exp_id}/ptt_windowed_exp_{exp_id}.csv"
            
            if not (os.path.exists(window_file) and os.path.exists(ptt_file)):
                print(f"âŒ PTTæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: exp_{exp_id}")
                return None
            
            # åŠ è½½çª—å£éªŒè¯ä¿¡æ¯
            window_df = pd.read_csv(window_file)
            # ç­›é€‰æœ‰æ•ˆçª—å£ï¼ˆæ—¶é¢‘åŸŸå¿ƒç‡è¯¯å·®åˆç†ï¼‰
            valid_windows = window_df[
                (window_df['is_valid'] == True) & 
                (window_df['hr_diff_bpm'].abs() <= 5)  # å¿ƒç‡è¯¯å·®â‰¤5BPM
            ]
            
            # åŠ è½½PTTæ•°æ®
            ptt_df = pd.read_csv(ptt_file)
            
            # æ–°å¢ï¼šåŸºäºIBIç­›é€‰ abs(PTT) < 0.5 * reference_mean_ibi_ms
            if 'reference_mean_ibi_ms' in ptt_df.columns:
                mask = np.abs(ptt_df['ptt_ms']) < 0.5 * ptt_df['reference_mean_ibi_ms']
                filtered_ptt = ptt_df[mask | ptt_df['reference_mean_ibi_ms'].isna()]  # å¦‚æœIBI NaNåˆ™ä¿ç•™
                print(f"ğŸ†• IBI-basedç­›é€‰: åŸå§‹{len(ptt_df)} â†’ ç­›é€‰å{len(filtered_ptt)}")
                print(f"ç­›é€‰åˆç†æ¯”ä¾‹: {len(filtered_ptt)/len(ptt_df)*100:.1f}%")  # æ–°å¢ï¼šè¾“å‡ºç­›é€‰æ¯”ä¾‹
            else:
                print("âš ï¸ æ— reference_mean_ibi_msåˆ—ï¼Œè·³è¿‡IBIç­›é€‰")
                filtered_ptt = ptt_df
            
            # åªä¿ç•™æœ‰æ•ˆçª—å£çš„PTTæ•°æ®
            valid_ptt = filtered_ptt[filtered_ptt['window_id'].isin(valid_windows['window_id'])]
            
            print(f"ğŸ“Š å®éªŒ{exp_id}: æ€»çª—å£{len(window_df)}, æœ‰æ•ˆçª—å£{len(valid_windows)}, æœ‰æ•ˆPTTæ•°æ®{len(valid_ptt)}")
            
            return {
                'window_info': valid_windows,
                'ptt_data': valid_ptt
            }
            
        except Exception as e:
            print(f"âŒ åŠ è½½PTTæ•°æ®å¤±è´¥: {e}")
            return None
    
    def remove_outliers_iqr(self, data_series):
        """ä½¿ç”¨IQRæ–¹æ³•å»é™¤æå€¼"""
        q1 = data_series.quantile(0.25)
        q3 = data_series.quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        return data_series[(data_series >= lower_bound) & (data_series <= upper_bound)]
    
    def synchronize_data(self, ptt_data, physio_data, exp_id):
        """æ—¶é—´åŒæ­¥PTTå’Œç”Ÿç†æ•°æ®"""
        synchronized_data = []
        
        for _, ptt_row in ptt_data['ptt_data'].iterrows():
            # PTTæ•°æ®çš„æ—¶é—´ä¿¡æ¯ï¼ˆä¿®æ­£åˆ—åï¼‰
            start_time = ptt_row['window_start_s']
            end_time = ptt_row['window_end_s']
            window_center = (start_time + end_time) / 2
            
            # è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆå‡è®¾ç”Ÿç†æ•°æ®çš„timestampæ˜¯ç»å¯¹æ—¶é—´æˆ³ï¼‰
            # éœ€è¦æ‰¾åˆ°ç”Ÿç†æ•°æ®æ—¶é—´æˆ³çš„èµ·å§‹ç‚¹
            physio_start_time = physio_data['timestamp'].iloc[0]
            start_timestamp = physio_start_time + start_time
            end_timestamp = physio_start_time + end_time
            
            # æ‰¾åˆ°æ—¶é—´çª—å£å†…çš„ç”Ÿç†æ•°æ®
            time_mask = (physio_data['timestamp'] >= start_timestamp) & (physio_data['timestamp'] <= end_timestamp)
            window_physio = physio_data[time_mask]
            
            if len(window_physio) == 0:
                continue  # è·³è¿‡æ²¡æœ‰ç”Ÿç†æ•°æ®çš„çª—å£
            
            # è®¡ç®—çª—å£å†…æ‰€æœ‰ç”Ÿç†æŒ‡æ ‡çš„ç»Ÿè®¡é‡ï¼ˆåªè®¡ç®—meanï¼‰
            physio_values = {}
            for indicator in self.physiological_indicators.keys():
                if indicator in physio_data.columns:
                    physio_values[f'{indicator}_mean'] = window_physio[indicator].mean()
                    physio_values[f'{indicator}_count'] = len(window_physio)
            
            # æ„å»ºåŒæ­¥æ•°æ®è¡Œ
            sync_row = {
                'exp_id': exp_id,
                'window_id': ptt_row['window_id'],
                'start_time': start_time,
                'end_time': end_time,
                'window_center': window_center,
                'sensor_pair': ptt_row['sensor_pair'],
                'ptt_ms': ptt_row['ptt_ms'],
                **physio_values
            }
            
            synchronized_data.append(sync_row)
        
        sync_df = pd.DataFrame(synchronized_data)
        print(f"ğŸ“Š åŒæ­¥å®Œæˆ: {len(sync_df)}ä¸ªæœ‰æ•ˆçª—å£")
        
        # æ–°å¢ï¼šIQRå»é™¤æå€¼ï¼ˆçª—å£çº§ï¼Ÿä½†è¿™é‡Œæ˜¯å¿ƒè·³çº§ï¼Œéœ€åˆ†ç»„ï¼‰
        # å‡è®¾åˆ†ç»„è®¡ç®—mean after IQR
        grouped = sync_df.groupby(['window_id', 'sensor_pair'])
        cleaned_data = []
        for name, group in grouped:
            clean_ptt = self.remove_outliers_iqr(group['ptt_ms'])
            if not clean_ptt.empty:
                mean_ptt = clean_ptt.mean()
                row = group.iloc[0].copy()
                row['ptt_ms'] = mean_ptt
                cleaned_data.append(row)
        cleaned_df = pd.DataFrame(cleaned_data)
        
        # ç”Ÿæˆç®±çº¿å›¾
        self.create_ptt_boxplot(cleaned_df, exp_id)  # ä¿®æ”¹ï¼šä¼ å…¥exp_id
        
        return cleaned_df
    
    def create_ptt_boxplot(self, df, exp_id=None):
        """ç”ŸæˆPTTç®±çº¿å›¾"""
        plt.figure(figsize=(10, 6))
        sns.boxplot(x='sensor_pair', y='ptt_ms', data=df)
        title = 'PTT Boxplot per Sensor Pair'
        if exp_id:
            title += f' (Exp {exp_id})'
            # åˆ›å»ºå®éªŒç‰¹å®šçš„æ–‡ä»¶å¤¹
            exp_output_dir = os.path.join(self.output_dir, f'exp_{exp_id}')
            os.makedirs(exp_output_dir, exist_ok=True)
            filename = f'exp_{exp_id}_ptt_boxplot.png'
            filepath = os.path.join(exp_output_dir, filename)
        else:
            title += ' (Overall)'
            filename = 'overall_ptt_boxplot.png'
            filepath = os.path.join(self.output_dir, filename)
        if hasattr(self, 'subject'):
            title += f' (Subject {self.subject})'
        plt.title(title)
        plt.savefig(filepath)
        plt.close()
    
    def calculate_correlations(self, sync_df):
        """è®¡ç®—PTTä¸æ‰€æœ‰ç”Ÿç†æŒ‡æ ‡çš„ç›¸å…³æ€§"""
        correlations = {}
        
        # ç”Ÿç†æŒ‡æ ‡ï¼ˆåªå¤„ç†meanï¼‰
        physio_metrics = []
        for indicator in self.physiological_indicators.keys():
            col_name = f'{indicator}_mean'
            if col_name in sync_df.columns:
                physio_metrics.append(col_name)
        
        # è·å–æ‰€æœ‰ä¼ æ„Ÿå™¨å¯¹
        sensor_pairs = sync_df['sensor_pair'].unique()
        
        print(f"\nğŸ“Š è®¡ç®—ç›¸å…³æ€§ï¼š{len(sensor_pairs)}ä¸ªä¼ æ„Ÿå™¨å¯¹ Ã— {len(physio_metrics)}ä¸ªç”Ÿç†æŒ‡æ ‡")
        
        for sensor_pair in sensor_pairs:
            correlations[sensor_pair] = {}
            
            # æå–è¯¥ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
            pair_data = sync_df[sync_df['sensor_pair'] == sensor_pair]
            
            if len(pair_data) < 10:  # è‡³å°‘10ä¸ªæ•°æ®ç‚¹
                continue
            
            for physio_col in physio_metrics:
                # æå–æœ‰æ•ˆæ•°æ®
                mask = ~(pair_data['ptt_ms'].isna() | pair_data[physio_col].isna())
                if mask.sum() < 10:
                    continue
                
                ptt_vals = pair_data.loc[mask, 'ptt_ms']
                physio_vals = pair_data.loc[mask, physio_col]
                
                # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
                try:
                    corr_coef, p_value = stats.pearsonr(ptt_vals, physio_vals)
                    
                    correlations[sensor_pair][physio_col] = {
                        'correlation': corr_coef,
                        'p_value': p_value,
                        'n_samples': len(ptt_vals),
                        'significant': p_value < 0.05
                    }
                except Exception as e:
                    print(f"âš ï¸ è®¡ç®—ç›¸å…³æ€§å¤±è´¥ {sensor_pair}-{physio_col}: {e}")
                    continue
        
        return correlations
    
    def create_correlation_heatmap(self, correlations, title_suffix=""):
        """åˆ›å»ºç›¸å…³æ€§çƒ­å›¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        # å‡†å¤‡æ•°æ®
        sensor_pairs = list(correlations.keys())
        physio_cols = set()
        for pair_data in correlations.values():
            physio_cols.update(pair_data.keys())
        physio_cols = sorted(list(physio_cols))
        
        if len(sensor_pairs) == 0 or len(physio_cols) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„ç›¸å…³æ€§æ•°æ®æ¥åˆ›å»ºçƒ­å›¾")
            return None
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        p_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        
        for i, sensor_pair in enumerate(sensor_pairs):
            for j, physio_col in enumerate(physio_cols):
                if physio_col in correlations[sensor_pair]:
                    corr_matrix[i, j] = correlations[sensor_pair][physio_col]['correlation']
                    p_matrix[i, j] = correlations[sensor_pair][physio_col]['p_value']
        
        # æ–°å¢ï¼šé¢„æ ¼å¼åŒ–annotå­—ç¬¦ä¸²
        annot_matrix = np.full((len(sensor_pairs), len(physio_cols)), '', dtype=object)
        for i in range(len(sensor_pairs)):
            for j in range(len(physio_cols)):
                if not np.isnan(corr_matrix[i, j]):
                    corr_str = f"{corr_matrix[i, j]:.3f}"
                    if p_matrix[i, j] < 0.05:
                        corr_str += '*'
                    annot_matrix[i, j] = corr_str
        
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(16, 10))
        
        # ç»˜åˆ¶çƒ­å›¾
        mask = np.isnan(corr_matrix)
        im = sns.heatmap(corr_matrix, 
                        xticklabels=[self._format_physio_label_en(col) for col in physio_cols],
                        yticklabels=[self._format_sensor_pair_label_en(pair) for pair in sensor_pairs],
                        annot=annot_matrix, fmt='', cmap='RdBu_r', center=0,
                        mask=mask, square=False, linewidths=0.5,
                        cbar_kws={'label': 'Correlation Coefficient'},
                        annot_kws={'size': 8})
        
        # ç§»é™¤æ—§çš„ax.text
        
        plt.title(f'PTT-Cardiovascular Parameters Correlation Analysis{title_suffix}', 
                 fontsize=16, fontweight='bold', pad=20)
        if hasattr(self, 'subject'):
            plt.suptitle(f'Subject {self.subject}', y=1.02, fontsize=12)
        plt.xlabel('Physiological Parameters', fontsize=12, fontweight='bold')
        plt.ylabel('PTT Sensor Combinations', fontsize=12, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        if title_suffix and title_suffix.startswith("_exp"):
            # æå–å®éªŒID
            exp_id = title_suffix.replace("_exp", "").replace(" ", "_")
            exp_output_dir = os.path.join(self.output_dir, f'exp_{exp_id}')
            os.makedirs(exp_output_dir, exist_ok=True)
            filename = f"{exp_output_dir}/ptt_cardiovascular_correlation_heatmap_{exp_id}.png"
        else:
            filename = f"{self.output_dir}/ptt_cardiovascular_correlation_heatmap{title_suffix.replace(' ', '_')}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜ç›¸å…³æ€§çƒ­å›¾: {filename}")
        
        return fig
    
    def _format_sensor_pair_label(self, sensor_pair):
        """æ ¼å¼åŒ–ä¼ æ„Ÿå™¨å¯¹æ ‡ç­¾"""
        # sensor2-sensor3 -> noseâ†’finger
        sensor_map = {'sensor2': 'nose', 'sensor3': 'finger', 'sensor4': 'wrist', 'sensor5': 'ear'}
        if '-' in sensor_pair:
            parts = sensor_pair.split('-')
            if len(parts) == 2:
                return f"{sensor_map.get(parts[0], parts[0])}â†’{sensor_map.get(parts[1], parts[1])}"
        return sensor_pair
    
    def _format_physio_label_en(self, physio_col):
        """æ ¼å¼åŒ–ç”Ÿç†æŒ‡æ ‡æ ‡ç­¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        # æå–åŸºç¡€æŒ‡æ ‡åç§°å’Œç»Ÿè®¡é‡
        for indicator, label in self.physiological_indicators.items():
            if physio_col.startswith(indicator):
                stat_part = physio_col.replace(indicator, '').replace('_', ' ')
                if stat_part == ' mean':
                    return label
                elif stat_part == ' std':
                    return f"{label} (SD)"
                elif stat_part == ' min':
                    return f"{label} (Min)"
                elif stat_part == ' max':
                    return f"{label} (Max)"
                else:
                    return f"{label}{stat_part}"
        return physio_col
    
    def _format_sensor_pair_label_en(self, sensor_pair):
        """æ ¼å¼åŒ–ä¼ æ„Ÿå™¨å¯¹æ ‡ç­¾ï¼ˆè‹±æ–‡ç‰ˆï¼‰"""
        return self.ptt_combinations_en.get(sensor_pair, sensor_pair)
    
    def build_regression_models(self, sync_df, correlations, exp_id=None):
        """æ„å»ºPTTâ†’ç”Ÿç†æŒ‡æ ‡çš„å›å½’æ¨¡å‹ï¼Œå¹¶è¿”å›æ¨¡å‹å’Œæ•°æ®"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)

        all_corrs = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                if stats_data['significant']:
                    all_corrs.append((abs(stats_data['correlation']), 
                                    self._format_sensor_pair_label_en(sensor_pair),
                                    self._format_physio_label_en(physio_col),
                                    stats_data['correlation'],
                                    stats_data['p_value'],
                                    stats_data['n_samples']))
                
        all_corrs.sort(reverse=True)
        
        # åˆ›å»ºç›¸å…³æ€§æ˜ å°„ï¼Œæ–¹ä¾¿åç»­æŸ¥æ‰¾
        corr_map = {}
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                key = f"{sensor_pair}â†’{physio_col}"
                corr_map[key] = {
                    'correlation': stats_data['correlation'],
                    'p_value': stats_data['p_value']
                }
        
        # ä¸»è¦è¡€å‹æŒ‡æ ‡ï¼ˆå‡å€¼ï¼‰
        main_physio_cols = []
        for indicator in ['systolic_bp', 'diastolic_bp', 'mean_bp']:
            col_name = f'{indicator}_mean'
            if col_name in sync_df.columns:
                main_physio_cols.append(col_name)
        
        # è·å–æ‰€æœ‰ä¼ æ„Ÿå™¨å¯¹
        sensor_pairs = sync_df['sensor_pair'].unique()
        print(f"ğŸ” å‘ç°ä¼ æ„Ÿå™¨å¯¹: {sensor_pairs}")
        
        # åˆ›å»ºç»“æœæ•°æ®ç»“æ„
        all_models = {}
        all_model_data = {}
        metrics_list = []  # ç”¨äºå­˜å‚¨ CSV çš„æŒ‡æ ‡æ•°æ®
        
        # ä¸ºæ¯ä¸ªä¼ æ„Ÿå™¨å¯¹å•ç‹¬å¤„ç†
        for sensor_pair in sensor_pairs:
            print(f"\nğŸ”§ å¤„ç†ä¼ æ„Ÿå™¨å¯¹: {sensor_pair}")
            
            # è¿‡æ»¤å½“å‰ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
            pair_df = sync_df[sync_df['sensor_pair'] == sensor_pair].copy()
            
            # åˆ›å»ºæ•°æ®é€è§†è¡¨ - æ¯ä¸ªçª—å£ä¸€ä¸ªPTTå€¼
            ptt_pivot = pair_df.pivot_table(
                index=['exp_id', 'window_id'], 
                values='ptt_ms',
                aggfunc='mean'
            ).reset_index().rename(columns={'ptt_ms': f'ptt_{sensor_pair}'})
            
            # åˆå¹¶ç”Ÿç†æ•°æ®ï¼ˆå–å¹³å‡å€¼ï¼‰
            physio_agg = pair_df.groupby(['exp_id', 'window_id']).agg({
                col: 'mean' for col in main_physio_cols if col in pair_df.columns
            }).reset_index()
            
            # åˆå¹¶PTTå’Œç”Ÿç†æ•°æ®
            model_data = pd.merge(ptt_pivot, physio_agg, on=['exp_id', 'window_id'], how='inner')
            
            # æ£€æŸ¥æ•°æ®é‡
            if len(model_data) < 10:
                print(f"âš ï¸ æ•°æ®ä¸è¶³: {sensor_pair} åªæœ‰{len(model_data)}ä¸ªæ ·æœ¬")
                continue
                
            # è·å–PTTç‰¹å¾åˆ—
            ptt_col = f'ptt_{sensor_pair}'
            
            # æ£€æŸ¥PTTåˆ—çš„NaNæ¯”ä¾‹
            nan_ratio = model_data[ptt_col].isna().mean()
            print(f"ğŸ“Š PTTåˆ— {ptt_col} NaNæ¯”ä¾‹: {nan_ratio:.2%}")
            
            # ä¸ºæ¯ä¸ªç”Ÿç†æŒ‡æ ‡å•ç‹¬å»ºæ¨¡
            for physio_col in main_physio_cols:
                if physio_col not in model_data.columns:
                    continue
                    
                # å‡†å¤‡æ•°æ® - ç§»é™¤NaN
                mask = ~model_data[physio_col].isna() & ~model_data[ptt_col].isna()
                
                if mask.sum() < 5:  # è‡³å°‘5ä¸ªæ ·æœ¬
                    print(f"âš ï¸ æ•°æ®ä¸è¶³: {sensor_pair}â†’{physio_col} æœ‰æ•ˆæ ·æœ¬={mask.sum()}")
                    continue
                
                X = model_data.loc[mask, ptt_col].values.reshape(-1, 1)
                y = model_data.loc[mask, physio_col].values
                
                # æ•°æ®æ ‡å‡†åŒ–
                scaler_X = StandardScaler()
                scaler_y = StandardScaler()
                X_scaled = scaler_X.fit_transform(X)
                y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
                
                # è®­ç»ƒæ¨¡å‹
                model = LinearRegression()
                model.fit(X_scaled, y_scaled)
                
                # é¢„æµ‹
                y_pred_scaled = model.predict(X_scaled)
                y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
                
                # è¯„ä¼°
                r2 = r2_score(y, y_pred)
                mae = mean_absolute_error(y, y_pred)
                
                # è·å–ç›¸å…³æ€§æ•°æ®
                model_key = f"{sensor_pair}â†’{physio_col}"
                corr_data = corr_map.get(model_key, {'correlation': float('nan'), 'p_value': float('nan')})
                ptt_correlation = corr_data['correlation']
                ptt_p_value = corr_data['p_value']
                
                # å­˜å‚¨æ¨¡å‹
                all_models[model_key] = {
                    'model': model,
                    'scaler_X': scaler_X,
                    'scaler_y': scaler_y,
                    'feature_names': [ptt_col],
                    'r2_score': r2,
                    'mae': mae,
                    'n_samples': len(y),
                    'y_true': y,
                    'y_pred': y_pred,
                    'sensor_pair': sensor_pair,
                    'physio_col': physio_col,
                    'ptt_correlation': ptt_correlation,
                    'ptt_p_value': ptt_p_value
                }
                
                print(f"ğŸ“ˆ {model_key}æ¨¡å‹: RÂ²={r2:.3f}, MAE={mae:.2f}, N={len(y)}")
                print(f"   ğŸ“Š PTTç›¸å…³æ€§: r={ptt_correlation:.3f}, p={ptt_p_value:.2e}")
                
                # åˆ›å»ºå›¾è¡¨
                plt.figure(figsize=(10, 8))  # å¢åŠ å›¾è¡¨é«˜åº¦ä»¥å®¹çº³æ›´å¤šä¿¡æ¯
                
                # 1. ç»˜åˆ¶åŸå§‹æ•°æ®ç‚¹
                plt.scatter(X, y, alpha=0.6, color='blue', label='Data Points')
                
                # 2. ç»˜åˆ¶æ‹Ÿåˆç›´çº¿
                x_min, x_max = np.min(X), np.max(X)
                x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)
                
                x_range_scaled = scaler_X.transform(x_range)
                y_range_scaled = model.predict(x_range_scaled)
                y_range = scaler_y.inverse_transform(y_range_scaled.reshape(-1, 1)).flatten()
                
                plt.plot(x_range, y_range, 'r-', linewidth=2, label='Fitted Line')
                
                # 3. æ·»åŠ å›¾ä¾‹å’Œæ ‡ç­¾
                plt.xlabel(f'PTT ({sensor_pair}) (ms)')
                plt.ylabel(f'{self._format_physio_label_en(physio_col)}')
                
                # è·å–æ–¹ç¨‹ç³»æ•°
                coef = model.coef_[0]
                intercept = model.intercept_
                
                # è®¡ç®—åŸå§‹æ•°æ®ç©ºé—´çš„æ–œç‡å’Œæˆªè·
                coef_original = coef * (scaler_y.scale_[0] / scaler_X.scale_[0])
                intercept_original = scaler_y.mean_[0] - coef * (scaler_X.mean_[0] * scaler_y.scale_[0] / scaler_X.scale_[0]) + intercept * scaler_y.scale_[0]
                
                # 4. æ›´æ–°æ ‡é¢˜ï¼ŒåŒ…å«ç›¸å…³æ€§ä¿¡æ¯
                title = f'{self._format_physio_label_en(physio_col)} vs PTT ({sensor_pair}) (Subject {self.subject})\n'
                title += f'Equation: y = {coef_original:.3f}x + {intercept_original:.3f} | Correlation: r={ptt_correlation:.3f}, p={ptt_p_value:.2e}\n'
                title += f'RÂ²={r2:.3f}, MAE={mae:.2f}, n={len(y)}'
                plt.title(title)
                
                plt.legend()
                plt.grid(alpha=0.3)
                
                # ä¿å­˜å›¾è¡¨
                safe_physio = physio_col.replace(' ', '_').replace('/', '_')
                safe_pair = sensor_pair.replace(' ', '_').replace('/', '_')
                if exp_id is not None:
                    # åˆ›å»ºå®éªŒç‰¹å®šçš„æ–‡ä»¶å¤¹
                    exp_output_dir = os.path.join(self.output_dir, f'exp_{exp_id}')
                    os.makedirs(exp_output_dir, exist_ok=True)
                    plot_path = os.path.join(exp_output_dir, f"exp_{exp_id}_{safe_physio}_vs_{safe_pair}_fit.png")
                else:
                    plot_path = os.path.join(self.output_dir, f"{safe_physio}_vs_{safe_pair}_fit.png")
                plt.savefig(plot_path, bbox_inches='tight', dpi=150)
                plt.close()
                
                print(f"ğŸ’¾ ä¿å­˜ç‰¹å¾æ‹Ÿåˆå›¾: {plot_path}")
                
                # å­˜å‚¨æ¨¡å‹æ•°æ®
                all_model_data[model_key] = model_data.loc[mask, [ptt_col, physio_col]]
                
                # æ”¶é›†æŒ‡æ ‡æ•°æ®ç”¨äº CSV
                if exp_id is not None:
                    metrics_list.append({
                        'exp_id': exp_id,
                        'sensor_pair': sensor_pair,
                        'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                        'physiological_parameter': physio_col,
                        'parameter_label': self._format_physio_label_en(physio_col),
                        'r2_score': r2,
                        'mae': mae,
                        'n_samples': len(y),
                        'slope': coef_original,
                        'intercept': intercept_original,
                        'ptt_correlation': ptt_correlation,
                        'ptt_p_value': ptt_p_value,
                        'correlation_significant': ptt_p_value < 0.05
                    })
                else:
                    metrics_list.append({
                        'sensor_pair': sensor_pair,
                        'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                        'physiological_parameter': physio_col,
                        'parameter_label': self._format_physio_label_en(physio_col),
                        'r2_score': r2,
                        'mae': mae,
                        'n_samples': len(y),
                        'slope': coef_original,
                        'intercept': intercept_original,
                        'ptt_correlation': ptt_correlation,
                        'ptt_p_value': ptt_p_value,
                        'correlation_significant': ptt_p_value < 0.05
                    })
        
        # å¦‚æœæ²¡æœ‰ exp_idï¼Œä¿å­˜æŒ‡æ ‡åˆ° CSV
        if exp_id is None:
            print("ä¿å­˜æ•´ä½“æ¨¡å‹è¯„ä¼°ï¼š")
            csv_path = os.path.join(self.output_dir, "overall_regression_metrics.csv")
            metrics_df = pd.DataFrame(metrics_list)
            metrics_df.to_csv(csv_path, index=False)
        else:
            print("ä¿å­˜å•ä¸ªå®éªŒæ¨¡å‹è¯„ä¼°ï¼š")
            csv_path = os.path.join(self.output_dir, "all_experiments_regression_metrics.csv")
            metrics_df = pd.DataFrame(metrics_list)
            # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®ï¼›å¦åˆ™åˆ›å»ºæ–°æ–‡ä»¶
            if os.path.exists(csv_path):
                existing_df = pd.read_csv(csv_path)
                combined_df = pd.concat([existing_df, metrics_df], ignore_index=True)
                combined_df.to_csv(csv_path, index=False)
            else:
                metrics_df.to_csv(csv_path, index=False)
        
        return all_models, all_model_data

    def analyze_experiment(self, exp_id):
        """åˆ†æå•ä¸ªå®éªŒ"""
        print(f"\nğŸ” åˆ†æå®éªŒ {exp_id}")
        
        # 1. åŠ è½½æ•°æ®
        physio_data = self.load_ground_truth_bp(exp_id)
        ptt_data = self.load_ptt_data(exp_id)
        
        if physio_data is None or ptt_data is None:
            print(f"âŒ å®éªŒ {exp_id} æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        # 2. æ—¶é—´åŒæ­¥
        sync_df = self.synchronize_data(ptt_data, physio_data, exp_id)
        print(f"ğŸ“Š åŒæ­¥æ•°æ®: {len(sync_df)}ä¸ªæ—¶é—´çª—å£")
        
        # 3. ç›¸å…³æ€§åˆ†æ
        correlations = self.calculate_correlations(sync_df)
        
        # 4. å›å½’å»ºæ¨¡
        models, model_data = self.build_regression_models(sync_df, correlations, exp_id=exp_id)
        
        return {
            'sync_data': sync_df,
            'correlations': correlations,
            'models': models
        }
    
    def analyze_experiment_cross(self, exp_id):
        # 1. åŠ è½½æ•°æ®
        physio_data = self.load_ground_truth_bp(exp_id)
        ptt_data = self.load_ptt_data(exp_id)
        
        if physio_data is None or ptt_data is None:
            print(f"âŒ å®éªŒ {exp_id} æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        # 2. æ—¶é—´åŒæ­¥
        sync_df = self.synchronize_data(ptt_data, physio_data, exp_id)
        print(f"ğŸ“Š åŒæ­¥æ•°æ®: {len(sync_df)}ä¸ªæ—¶é—´çª—å£")

        return {
            'sync_data': sync_df,
        }
    
    def run_individual_experiment_analysis(self):
        """è¿è¡Œå•ä¸ªå®éªŒçš„åˆ†æ"""
        print("ğŸ”¬ å¼€å§‹å•ä¸ªå®éªŒåˆ†æ...")
        
        individual_results = {}
        all_experiments = []
        
        for exp_id in range(1, 12):
            print(f"\nğŸ” å•ç‹¬åˆ†æå®éªŒ {exp_id}")
            
            # åˆ†æå•ä¸ªå®éªŒ
            exp_result = self.analyze_experiment(exp_id)
            if exp_result:
                individual_results[exp_id] = exp_result['sync_data']
                
                # è®¡ç®—ç›¸å…³æ€§
                correlations = self.calculate_correlations(exp_result['sync_data'])
                
                # åˆ›å»ºå•ä¸ªå®éªŒçš„çƒ­å›¾
                self.create_focused_correlation_heatmap(correlations, f"_exp{exp_id}")
                
                # åˆ›å»ºå•ä¸ªå®éªŒçš„Bland-Altmanå›¾
                self.create_bland_altman_plots(exp_result['sync_data'], exp_id=exp_id)
                
                # ä¿å­˜å•ä¸ªå®éªŒç»“æœ
                self.save_individual_experiment_results(exp_result['sync_data'], correlations, exp_id)

                # ç”¨äºç»“æœåˆå¹¶
                all_experiments.append(exp_result['sync_data'])
        
        if not all_experiments:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒæ•°æ®")
            return None
        
        # åˆå¹¶æ‰€æœ‰å®éªŒçš„æ•°æ®
        combined_df = pd.concat(all_experiments, ignore_index=True)
        print(combined_df.head())
        print(f"\nğŸ“Š åˆå¹¶æ•°æ®: {len(combined_df)}ä¸ªæ ·æœ¬ï¼Œæ¥è‡ª{len(all_experiments)}ä¸ªå®éªŒ")
        
        return individual_results, combined_df
    
    def create_focused_correlation_heatmap(self, correlations, title_suffix=""):
        """åˆ›å»ºèšç„¦çš„ç›¸å…³æ€§çƒ­å›¾ï¼ˆåªæ˜¾ç¤ºé‡è¦æŒ‡æ ‡ï¼‰"""
        # é€‰æ‹©é‡è¦çš„è¡€å‹æŒ‡æ ‡ï¼ˆå‡å°‘å›¾åƒå¤§å°ï¼‰
        important_indicators = [
            'systolic_bp_mean', 'diastolic_bp_mean', 'mean_bp_mean'
        ]
        
        # å‡†å¤‡æ•°æ®
        sensor_pairs = list(correlations.keys())
        filtered_correlations = {}
        
        for sensor_pair in sensor_pairs:
            filtered_correlations[sensor_pair] = {
                col: correlations[sensor_pair][col] 
                for col in important_indicators 
                if col in correlations[sensor_pair]
            }
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        physio_cols = list(set().union(*[pair_data.keys() for pair_data in filtered_correlations.values()]))
        physio_cols = sorted(physio_cols)
        
        if len(sensor_pairs) == 0 or len(physio_cols) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®åˆ›å»ºèšç„¦çƒ­å›¾")
            return None
        
        corr_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        p_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        
        for i, sensor_pair in enumerate(sensor_pairs):
            for j, physio_col in enumerate(physio_cols):
                if physio_col in filtered_correlations[sensor_pair]:
                    corr_matrix[i, j] = filtered_correlations[sensor_pair][physio_col]['correlation']
                    p_matrix[i, j] = filtered_correlations[sensor_pair][physio_col]['p_value']
        
        # æ–°å¢ï¼šé¢„æ ¼å¼åŒ–annotå­—ç¬¦ä¸²
        annot_matrix = np.full((len(sensor_pairs), len(physio_cols)), '', dtype=object)
        for i in range(len(sensor_pairs)):
            for j in range(len(physio_cols)):
                if not np.isnan(corr_matrix[i, j]):
                    corr_str = f"{corr_matrix[i, j]:.3f}"
                    if p_matrix[i, j] < 0.05:
                        corr_str += '*'
                    annot_matrix[i, j] = corr_str
        
        # åˆ›å»ºå›¾å½¢ï¼ˆæ›´å°æ›´æ¸…æ™°ï¼‰
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ç»˜åˆ¶çƒ­å›¾
        mask = np.isnan(corr_matrix)
        im = sns.heatmap(corr_matrix, 
                        xticklabels=[self._format_physio_label_en(col) for col in physio_cols],
                        yticklabels=[self._format_sensor_pair_label_en(pair) for pair in sensor_pairs],
                        annot=annot_matrix, fmt='', cmap='RdBu_r', center=0,
                        mask=mask, square=False, linewidths=0.5,
                        cbar_kws={'label': 'Correlation Coefficient'},
                        annot_kws={'size': 10})
        
        # ç§»é™¤æ—§çš„ax.text
        
        plt.title(f'PTT-Cardiovascular Correlation Analysis (Key Parameters){title_suffix}', 
                 fontsize=14, fontweight='bold', pad=20)
        if hasattr(self, 'subject'):
            plt.suptitle(f'Subject {self.subject}', y=1.02, fontsize=12)
        plt.xlabel('Physiological Parameters', fontsize=12, fontweight='bold')
        plt.ylabel('PTT Sensor Combinations', fontsize=12, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        if title_suffix and title_suffix.startswith("_exp"):
            # æå–å®éªŒID
            exp_id = title_suffix.replace("_exp", "").replace(" ", "_")
            exp_output_dir = os.path.join(self.output_dir, f'exp_{exp_id}')
            os.makedirs(exp_output_dir, exist_ok=True)
            filename = f"{exp_output_dir}/ptt_cardiovascular_correlation_focused_{exp_id}.png"
        else:
            filename = f"{self.output_dir}/ptt_cardiovascular_correlation_focused{title_suffix.replace(' ', '_')}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜èšç„¦çƒ­å›¾: {filename}")
        
        return fig
    
    def save_individual_experiment_results(self, sync_data, correlations, exp_id):
        """ä¿å­˜å•ä¸ªå®éªŒçš„ç»“æœ"""
        # ä¿å­˜ç›¸å…³æ€§ç»“æœ
        corr_results = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                corr_results.append({
                    'experiment_id': exp_id,
                    'sensor_pair': sensor_pair,
                    'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                    'physiological_parameter': physio_col,
                    'parameter_label': self._format_physio_label_en(physio_col),
                    'correlation_coefficient': stats_data['correlation'],
                    'p_value': stats_data['p_value'],
                    'n_samples': stats_data['n_samples'],
                    'statistically_significant': stats_data['significant']
                })
        
        corr_df = pd.DataFrame(corr_results)
        # åˆ›å»ºå®éªŒç‰¹å®šçš„æ–‡ä»¶å¤¹
        exp_output_dir = os.path.join(self.output_dir, f'exp_{exp_id}')
        os.makedirs(exp_output_dir, exist_ok=True)
        corr_file = f"{exp_output_dir}/ptt_cardiovascular_correlations_exp_{exp_id}.csv"
        corr_df.to_csv(corr_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜å®éªŒ{exp_id}ç›¸å…³æ€§: {corr_file}")
    
    def run_comprehensive_analysis(self):
        """è¿è¡Œç»¼åˆåˆ†æï¼ˆå•ä¸ª+è·¨å®éªŒå®éªŒï¼‰"""
        print("ğŸ”¬ å¼€å§‹PTTä¸ç”Ÿç†å‚æ•°ç»¼åˆåˆ†æ")
        print("ğŸ“‹ åˆ†æå®éªŒåˆ—è¡¨: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]")

        # 1. å•ä¸ªå®éªŒåˆ†æï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬ä¸€éƒ¨åˆ†ï¼šå•ä¸ªå®éªŒåˆ†æ ===")
        individual_results, combined_df = self.run_individual_experiment_analysis()
        
        # 1. æ•´ä½“åˆ†æï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬äºŒéƒ¨åˆ†ï¼šæ•´ä½“åˆ†æ ===")
        overall_results = self.run_overall_analysis(combined_df)
        
        # 3. åˆ›å»ºèšç„¦çƒ­å›¾ï¼ˆä¼˜åŒ–æ˜¾ç¤ºï¼‰
        print("\n=== ç¬¬ä¸‰éƒ¨åˆ†ï¼šåˆ›å»ºèšç„¦çƒ­å›¾ï¼ˆåªæ˜¾ç¤ºé‡è¦æŒ‡æ ‡ï¼‰===")
        if overall_results:
            self.create_focused_correlation_heatmap(overall_results['correlations'], "_overall_focus")
        
        # 4. åˆ›å»ºæ•´ä½“Bland-Altmanå›¾
        print("\n=== ç¬¬å››éƒ¨åˆ†ï¼šåˆ›å»ºæ•´ä½“Bland-Altmanå›¾ ===")
        if overall_results:
            self.create_bland_altman_plots(overall_results['combined_data'], exp_id=None)
        
        return {
            'overall': overall_results,
            'individual': individual_results
        }
    
    def run_overall_analysis(self, combined_df):
        """è¿è¡Œæ•´ä½“åˆ†æï¼ˆåŸæœ‰åŠŸèƒ½é‡å‘½åï¼‰"""
        # è®¡ç®—æ•´ä½“ç›¸å…³æ€§
        print("\nğŸ“ˆ è®¡ç®—æ•´ä½“ç›¸å…³æ€§...")
        correlations = self.calculate_correlations(combined_df)
        
        # åˆ›å»ºç›¸å…³æ€§çƒ­å›¾
        self.create_correlation_heatmap(correlations, "_overall")
        
        # æ„å»ºå›å½’æ¨¡å‹
        print("\nğŸ¯ æ„å»ºæ•´ä½“å›å½’æ¨¡å‹...")
        models = self.build_regression_models(combined_df, correlations, exp_id=None)
        
        # ä¿å­˜ç»“æœ
        self.save_analysis_results(combined_df, correlations, models)
        
        # æ–°å¢ï¼šæ•´ä½“ç®±çº¿å›¾
        self.create_ptt_boxplot(combined_df, None)
        
        return {
            'combined_data': combined_df,
            'correlations': correlations,
            'models': models
        }
    
    def run_cross_experiments_analysis(self):
        """è·¨å®éªŒæ„å»ºå›å½’æ¨¡å‹"""
        print("\nğŸ¯ å¼€å§‹è·¨å®éªŒæ‹Ÿåˆåˆ†æ...")
        # ä¸ºæ¯ä¸ªå®éªŒå•ç‹¬å»ºæ¨¡
        all_experiments = []
        
        for exp_id in range(1, 12):
            # åˆ†æå•ä¸ªå®éªŒ
            exp_result = self.analyze_experiment_cross(exp_id)
            if exp_result:
                # ç”¨äºç»“æœåˆå¹¶
                all_experiments.append(exp_result['sync_data'])
        
        if not all_experiments:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒæ•°æ®")
            return None
        
        # åˆå¹¶æ‰€æœ‰å®éªŒçš„æ•°æ®
        combined_df = pd.concat(all_experiments, ignore_index=True)
        print(combined_df.head())
        print(f"\nğŸ“Š åˆå¹¶æ•°æ®: {len(combined_df)}ä¸ªæ ·æœ¬ï¼Œæ¥è‡ª{len(all_experiments)}ä¸ªå®éªŒ")
            
        overall_results = self.run_overall_analysis(combined_df)

        if overall_results:
            self.create_focused_correlation_heatmap(overall_results['correlations'], "_overall_focus")
        
        return {
            'overall': overall_results,
        }
    
    def run_individual_regression_analysis(self):
        """ä¸ºæ¯ä¸ªå®éªŒå•ç‹¬æ„å»ºå›å½’æ¨¡å‹å¹¶ç»˜åˆ¶æ‹Ÿåˆç›´çº¿"""
        print("\nğŸ¯ å¼€å§‹å•ç‹¬å®éªŒå›å½’åˆ†æ...")
        individual_models = {}
        model_summary = []
        
        for exp_id in range(1, 12):  # å®éªŒ1-11
            print(f"\nğŸ“Š æ„å»ºå®éªŒ{exp_id}çš„å›å½’æ¨¡å‹")
            exp_data = self.analyze_experiment(exp_id)
            
            if not exp_data or len(exp_data['sync_data']) < 20:
                print(f"âŒ å®éªŒ{exp_id}æ•°æ®ä¸è¶³ï¼ˆ<20æ ·æœ¬ï¼‰")
                continue
            
            # ç›´æ¥ä»analyze_experimentçš„ç»“æœä¸­è·å–æ¨¡å‹
            if 'models' in exp_data and exp_data['models']:
                exp_models = exp_data['models']
                individual_models[f'exp_{exp_id}'] = exp_models
                
                # æ”¶é›†æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
                for model_key, model_info in exp_models.items():
                    # ä»model_keyä¸­æå–ç”Ÿç†æŒ‡æ ‡åç§°
                    # model_keyæ ¼å¼: "sensor_pairâ†’physio_col"
                    physio_param = model_key.split('â†’')[1] if 'â†’' in model_key else model_key
                    
                    model_summary.append({
                        'experiment': exp_id,
                        'physiological_parameter': physio_param,
                        'parameter_label': self._format_physio_label_en(physio_param),
                        'r2_score': model_info['r2_score'],
                        'mae': model_info['mae'],
                        'n_samples': model_info['n_samples'],
                        'sensor_pair': model_info.get('sensor_pair', ''),
                        'sensor_label': self._format_sensor_pair_label_en(model_info.get('sensor_pair', ''))
                    })
        
        # ä¿å­˜å•ç‹¬å®éªŒçš„æ¨¡å‹è¯„ä¼°
        if model_summary:
            model_df = pd.DataFrame(model_summary)
            model_file = f"{self.output_dir}/individual_experiment_models.csv"
            model_df.to_csv(model_file, index=False)
            print(f"ğŸ’¾ ä¿å­˜å•ç‹¬å®éªŒæ¨¡å‹è¯„ä¼°: {model_file}")

            # å¯¹æ¯ä¸ªå®éªŒçš„æ¯ä¸ªç”Ÿç†å‚æ•°ï¼Œé€‰æ‹©æœ€ä½³æ¨¡å‹ï¼ˆæŒ‰RÂ²ï¼‰
            # é¦–å…ˆæŒ‰å®éªŒå’Œç”Ÿç†å‚æ•°åˆ†ç»„ï¼Œç„¶ååœ¨æ¯ä¸ªç»„å†…å–RÂ²æœ€å¤§çš„è¡Œ
            best_model_df = model_df.loc[model_df.groupby(['experiment', 'physiological_parameter'])['r2_score'].idxmax()]
            
            # åˆ›å»ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”å¯è§†åŒ–
            self.create_individual_model_comparison(best_model_df)
        
        return individual_models

    def create_individual_model_comparison(self, model_df):
        """åˆ›å»ºå•ç‹¬å®éªŒæ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾"""
        if model_df.empty:
            return
        
        # åˆ›å»ºMAEå’ŒRÂ²å¯¹æ¯”å›¾
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))
        
        # MAEå¯¹æ¯”
        pivot_mae = model_df.pivot(index='experiment', columns='parameter_label', values='mae')
        im1 = ax1.imshow(pivot_mae.values.T, cmap='Reds', aspect='auto')
        ax1.set_title('MAE Comparison Across Experiments (Lower is Better)', fontsize=14, fontweight='bold')
        if hasattr(self, 'subject'):
            ax1.set_suptitle(f'Subject {self.subject}', y=1.02, fontsize=12)
        ax1.set_xlabel('Experiment Number')
        ax1.set_ylabel('Physiological Parameter')
        ax1.set_xticks(range(len(pivot_mae.index)))
        ax1.set_xticklabels(pivot_mae.index)
        ax1.set_yticks(range(len(pivot_mae.columns)))
        ax1.set_yticklabels(pivot_mae.columns, fontsize=10)
        
        # æ·»åŠ MAEæ•°å€¼æ ‡æ³¨
        for i in range(len(pivot_mae.columns)):
            for j in range(len(pivot_mae.index)):
                if not np.isnan(pivot_mae.iloc[j, i]):
                    ax1.text(j, i, f'{pivot_mae.iloc[j, i]:.1f}', 
                            ha='center', va='center', fontweight='bold')
        
        plt.colorbar(im1, ax=ax1, label='MAE')
        
        # RÂ²å¯¹æ¯”
        pivot_r2 = model_df.pivot(index='experiment', columns='parameter_label', values='r2_score')
        im2 = ax2.imshow(pivot_r2.values.T, cmap='Blues', aspect='auto')
        ax2.set_title('RÂ² Comparison Across Experiments (Higher is Better)', fontsize=14, fontweight='bold')
        if hasattr(self, 'subject'):
            ax2.set_suptitle(f'Subject {self.subject}', y=1.02, fontsize=12)
        ax2.set_xlabel('Experiment Number')
        ax2.set_ylabel('Physiological Parameter')
        ax2.set_xticks(range(len(pivot_r2.index)))
        ax2.set_xticklabels(pivot_r2.index)
        ax2.set_yticks(range(len(pivot_r2.columns)))
        ax2.set_yticklabels(pivot_r2.columns, fontsize=10)
        
        # æ·»åŠ RÂ²æ•°å€¼æ ‡æ³¨
        for i in range(len(pivot_r2.columns)):
            for j in range(len(pivot_r2.index)):
                if not np.isnan(pivot_r2.iloc[j, i]):
                    ax2.text(j, i, f'{pivot_r2.iloc[j, i]:.2f}', 
                            ha='center', va='center', fontweight='bold')
        
        plt.colorbar(im2, ax=ax2, label='RÂ² Score')
        
        plt.tight_layout()
        comparison_file = f"{self.output_dir}/individual_model_performance_comparison.png"
        plt.savefig(comparison_file, dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾å½¢ï¼Œä¸æ˜¾ç¤º
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾: {comparison_file}")

    def save_analysis_results(self, combined_df, correlations, models):
        """ä¿å­˜åˆ†æç»“æœï¼ˆè‹±æ–‡ç‰ˆï¼‰"""
        # 1. ä¿å­˜åŒæ­¥æ•°æ®
        sync_file = f"{self.output_dir}/synchronized_ptt_cardiovascular_data.csv"
        combined_df.to_csv(sync_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜åŒæ­¥æ•°æ®: {sync_file}")
        
        # 2. ä¿å­˜ç›¸å…³æ€§ç»“æœ
        corr_results = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                corr_results.append({
                    'sensor_pair': sensor_pair,
                    'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                    'physiological_parameter': physio_col,
                    'parameter_label': self._format_physio_label_en(physio_col),
                    'correlation_coefficient': stats_data['correlation'],
                    'p_value': stats_data['p_value'],
                    'n_samples': stats_data['n_samples'],
                    'statistically_significant': stats_data['significant']
                })
        
        corr_df = pd.DataFrame(corr_results)
        corr_file = f"{self.output_dir}/ptt_cardiovascular_correlations.csv"
        corr_df.to_csv(corr_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜ç›¸å…³æ€§æ•°æ®: {corr_file}")

    def create_bland_altman_plots(self, sync_df, exp_id=None):
        """åˆ›å»ºBland-Altmanå›¾ - å…­ä¸ªä¼ æ„Ÿå™¨å¯¹çš„SBPã€DBPå’ŒMean BP"""
        try:
            # è¡€å‹æŒ‡æ ‡ - åŒ…æ‹¬Mean BP
            bp_indicators = ['systolic_bp_mean', 'diastolic_bp_mean', 'mean_bp_mean']
            bp_labels = ['Systolic BP', 'Diastolic BP', 'Mean BP']
            
            # ä¼ æ„Ÿå™¨å¯¹
            sensor_pairs = list(self.ptt_combinations_en.keys())
            
            # åˆ›å»º6x6çš„å­å›¾å¸ƒå±€ - 6è¡Œï¼ˆä¼ æ„Ÿå™¨å¯¹ï¼‰x 6åˆ—ï¼ˆæ¯ä¸ªç”Ÿç†æŒ‡æ ‡å·¦å³ä¸¤ä¸ªå›¾ï¼‰
            fig, axes = plt.subplots(6, 6, figsize=(24, 20))
            fig.suptitle(f'PTT vs Reference BP Analysis{"" if exp_id is None else f" (Exp {exp_id})"}', 
                        fontsize=16, fontweight='bold', y=1)
            
            if hasattr(self, 'subject'):
                fig.suptitle(f'PTT vs Reference BP Analysis - Subject {self.subject}{"" if exp_id is None else f" (Exp {exp_id})"}', 
                            fontsize=16, fontweight='bold', y=0.99)
            
            # å­˜å‚¨è¯¯å·®å¸¦ç»Ÿè®¡ä¿¡æ¯
            error_band_stats = []
            
            for sensor_idx, sensor_pair in enumerate(sensor_pairs):
                for bp_idx, (bp_indicator, bp_label) in enumerate(zip(bp_indicators, bp_labels)):
                    # è®¡ç®—å­å›¾ä½ç½® - 6è¡Œx6åˆ—å¸ƒå±€
                    row = sensor_idx  # 0-5 for 6 sensor pairs
                    col_left = bp_idx * 2      # 0, 2, 4 for left plots (regression)
                    col_right = bp_idx * 2 + 1 # 1, 3, 5 for right plots (bland-altman)
                    
                    ax_left = axes[row, col_left]   # å·¦ä¾§å›å½’å›¾
                    ax_right = axes[row, col_right] # å³ä¾§Bland-Altmanå›¾
                    
                    # è·å–è¯¥ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
                    pair_data = sync_df[sync_df['sensor_pair'] == sensor_pair].copy()
                    
                    if len(pair_data) < 10:
                        ax_left.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', 
                                   transform=ax_left.transAxes, fontsize=10)
                        ax_right.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', 
                                    transform=ax_right.transAxes, fontsize=10)
                        ax_left.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}')
                        continue
                    
                    # å‡†å¤‡æ•°æ®
                    mask = ~(pair_data['ptt_ms'].isna() | pair_data[bp_indicator].isna())
                    if mask.sum() < 10:
                        ax_left.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', 
                                   transform=ax_left.transAxes, fontsize=10)
                        ax_right.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', 
                                    transform=ax_right.transAxes, fontsize=10)
                        ax_left.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}')
                        continue
                    
                    ptt_vals = pair_data.loc[mask, 'ptt_ms'].values
                    bp_vals = pair_data.loc[mask, bp_indicator].values
                    
                    # æ„å»ºç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹è¿›è¡Œé¢„æµ‹
                    try:
                        # æ ‡å‡†åŒ–æ•°æ®
                        scaler_ptt = StandardScaler()
                        scaler_bp = StandardScaler()
                        ptt_scaled = scaler_ptt.fit_transform(ptt_vals.reshape(-1, 1))
                        bp_scaled = scaler_bp.fit_transform(bp_vals.reshape(-1, 1))
                        
                        # è®­ç»ƒæ¨¡å‹
                        model = LinearRegression()
                        model.fit(ptt_scaled, bp_scaled.flatten())
                        
                        # é¢„æµ‹
                        bp_pred_scaled = model.predict(ptt_scaled)
                        bp_pred = scaler_bp.inverse_transform(bp_pred_scaled.reshape(-1, 1)).flatten()
                        
                    except Exception as e:
                        print(f"âš ï¸ æ¨¡å‹è®­ç»ƒå¤±è´¥ {sensor_pair}-{bp_indicator}: {e}")
                        ax_left.text(0.5, 0.5, 'Model Error', ha='center', va='center', 
                                   transform=ax_left.transAxes, fontsize=10)
                        ax_right.text(0.5, 0.5, 'Model Error', ha='center', va='center', 
                                    transform=ax_right.transAxes, fontsize=10)
                        ax_left.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}')
                        continue
                    
                    # === å·¦ä¾§ï¼šå›å½’æ‹Ÿåˆå›¾ + è¯¯å·®å¸¦ ===
                    # ç»˜åˆ¶è¯¯å·®å¸¦ï¼ˆæ”¹è¿›çš„é¢œè‰²è®¾ç½®ï¼šä¸€å±‚ä¸€å±‚å åŠ ï¼‰
                    bp_range = [min(bp_vals.min(), bp_pred.min()), max(bp_vals.max(), bp_pred.max())]
                    # å…ˆç»˜åˆ¶æœ€å¤§çš„è¯¯å·®å¸¦ï¼ˆ15mmHgï¼‰
                    ax_left.fill_between(bp_range, 
                                       [b - 15 for b in bp_range], [b + 15 for b in bp_range],
                                       alpha=0.3, color='pink', label='Â±15 mmHg')
                    # å†ç»˜åˆ¶ä¸­ç­‰è¯¯å·®å¸¦ï¼ˆ10mmHgï¼‰
                    ax_left.fill_between(bp_range, 
                                       [b - 10 for b in bp_range], [b + 10 for b in bp_range],
                                       alpha=0.4, color=(1.0, 1.0, 0.6), label='Â±10 mmHg')
                    # æœ€åç»˜åˆ¶æœ€å°è¯¯å·®å¸¦ï¼ˆ5mmHgï¼‰
                    ax_left.fill_between(bp_range, 
                                       [b - 5 for b in bp_range], [b + 5 for b in bp_range],
                                       alpha=0.5, color=(0.7, 1.0, 0.7), label='Â±5 mmHg')
                    
                    # ç»˜åˆ¶ç†æƒ³çº¿ï¼ˆy=xï¼‰
                    ax_left.plot(bp_range, bp_range, 'k--', alpha=0.5, linewidth=1, label='Perfect Match')
                    
                    # æœ€åç»˜åˆ¶æ•°æ®ç‚¹ï¼ˆç¡®ä¿åœ¨æœ€ä¸Šå±‚ï¼‰
                    ax_left.scatter(bp_pred, bp_vals, alpha=0.6, s=20, color='blue')
                    
                    ax_left.set_xlabel('Predicted BP (mmHg)', fontsize=9)
                    ax_left.set_ylabel('Reference BP (mmHg)', fontsize=9)
                    ax_left.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}', fontsize=10)
                    ax_left.grid(True, alpha=0.3)
                    ax_left.legend(fontsize=7, loc='upper left')
                    
                    # === å³ä¾§ï¼šBland-Altmanå›¾ ===
                    # Bland-Altmanè®¡ç®—
                    mean_bp = (bp_vals + bp_pred) / 2
                    diff_bp = bp_pred - bp_vals
                    
                    # è®¡ç®—ç»Ÿè®¡é‡
                    mean_diff = np.mean(diff_bp)
                    std_diff = np.std(diff_bp)
                    limits_of_agreement_upper = mean_diff + 1.96 * std_diff
                    limits_of_agreement_lower = mean_diff - 1.96 * std_diff
                    
                    # ç»˜åˆ¶Bland-Altmanå›¾
                    ax_right.scatter(mean_bp, diff_bp, alpha=0.6, s=20, color='blue')
                    
                    # ç»˜åˆ¶å‡å€¼çº¿å’Œä¸€è‡´æ€§ç•Œé™
                    ax_right.axhline(y=mean_diff, color='red', linestyle='-', linewidth=2, 
                                   label=f'Mean: {mean_diff:.2f}')
                    ax_right.axhline(y=limits_of_agreement_upper, color='red', linestyle='--', linewidth=1, 
                                   label=f'Upper LoA: {limits_of_agreement_upper:.2f}')
                    ax_right.axhline(y=limits_of_agreement_lower, color='red', linestyle='--', linewidth=1, 
                                   label=f'Lower LoA: {limits_of_agreement_lower:.2f}')
                    
                    ax_right.set_xlabel('Mean BP (mmHg)', fontsize=9)
                    ax_right.set_ylabel('Difference (Predicted - Reference) (mmHg)', fontsize=9)
                    ax_right.set_title(f'{self.ptt_combinations_en[sensor_pair]}\n{bp_label}', fontsize=10)
                    ax_right.grid(True, alpha=0.3)
                    ax_right.legend(fontsize=7, loc='upper right')
                    
                    # è®¡ç®—è¯¯å·®å¸¦ç»Ÿè®¡
                    abs_diff = np.abs(diff_bp)
                    within_5 = np.sum(abs_diff <= 5) / len(abs_diff) * 100
                    within_10 = np.sum(abs_diff <= 10) / len(abs_diff) * 100
                    within_15 = np.sum(abs_diff <= 15) / len(abs_diff) * 100
                    
                    error_band_stats.append({
                        'exp_id': exp_id,
                        'sensor_pair': sensor_pair,
                        'sensor_label': self.ptt_combinations_en[sensor_pair],
                        'bp_type': bp_label,
                        'n_samples': len(diff_bp),
                        'within_5_mmhg': within_5,
                        'within_10_mmhg': within_10,
                        'within_15_mmhg': within_15,
                        'mean_diff': mean_diff,
                        'std_diff': std_diff,
                        'loa_upper': limits_of_agreement_upper,
                        'loa_lower': limits_of_agreement_lower
                    })
                    
                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯åˆ°å›¾ä¸­
                    stats_text = f'n={len(diff_bp)}\nÂ±5mmHg: {within_5:.1f}%\nÂ±10mmHg: {within_10:.1f}%\nÂ±15mmHg: {within_15:.1f}%'
                    ax_right.text(0.02, 0.98, stats_text, transform=ax_right.transAxes, 
                               verticalalignment='top', fontsize=7, 
                               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            
            # è®¾ç½®åˆ—æ ‡é¢˜
            for i, bp_label in enumerate(bp_labels):
                # å¦‚æœæ˜¯Systolic BPï¼Œä½¿ç”¨æ›´å¤§çš„å­—ä½“å’ŒåŠ ç²—
                if bp_label == 'Systolic BP':
                    fontsize = 14
                    fontweight = 'bold'
                else:
                    fontsize = 12
                    fontweight = 'bold'
                fig.text(0.167 + i * 0.333, 0.97, bp_label, ha='center', va='center', 
                        fontsize=fontsize, fontweight=fontweight)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾åƒåˆ°å¯¹åº”çš„å®éªŒæ–‡ä»¶å¤¹
            exp_output_dir = None
            if exp_id is not None:
                # åˆ›å»ºå®éªŒç‰¹å®šçš„æ–‡ä»¶å¤¹
                exp_output_dir = os.path.join(self.output_dir, f'exp_{exp_id}')
                os.makedirs(exp_output_dir, exist_ok=True)
                filename = f"{exp_output_dir}/bland_altman_bp_exp_{exp_id}.png"
            else:
                filename = f"{self.output_dir}/bland_altman_bp_overall.png"
            
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"ğŸ’¾ ä¿å­˜Bland-Altmanå›¾: {filename}")
            
            # ä¿å­˜è¯¯å·®å¸¦ç»Ÿè®¡åˆ°CSV
            if error_band_stats:
                stats_df = pd.DataFrame(error_band_stats)
                if exp_id is not None and exp_output_dir:
                    stats_filename = f"{exp_output_dir}/error_band_stats_exp_{exp_id}.csv"
                else:
                    stats_filename = f"{self.output_dir}/error_band_stats_overall.csv"
                stats_df.to_csv(stats_filename, index=False)
                print(f"ğŸ’¾ ä¿å­˜è¯¯å·®å¸¦ç»Ÿè®¡: {stats_filename}")
            
            return fig
            
        except Exception as e:
            print(f"âŒ Bland-Altmanå›¾åˆ›å»ºå¤±è´¥: {e}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ©º PTT-Cardiovascular Parameters Correlation Analysis")
    print("="*60)
    
    # # åˆ›å»ºåˆ†æå™¨
    # analyzer = PTTBloodPressureAnalyzer()
    root_path = '/root/autodl-tmp/'
    # è·å–æ‰€æœ‰å—è¯•è€…æ–‡ä»¶å¤¹
    subject_list = sorted([d for d in os.listdir(root_path) 
                           if os.path.isdir(os.path.join(root_path, d)) and d.startswith('00')])
    print(f"ğŸ“‹ å‘ç° {len(subject_list)} ä¸ªå—è¯•è€…")
    
    # print("\nğŸ“‹ è¯·é€‰æ‹©åˆ†ææ–¹å¼:")
    # print("1. ç»¼åˆåˆ†æ (å•å®éªŒ+è·¨å®éªŒ)")
    # print("2. å•å®éªŒåˆ†æ")
    # print("3. è·¨å®éªŒåˆ†æ")
    
    # try:
    #     choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3, é»˜è®¤1): ").strip()
    #     if not choice:
    #         choice = "1"  # é»˜è®¤ç»¼åˆåˆ†æ
    # except:
    #     choice = "1"  # é»˜è®¤é€‰æ‹©
    
    # if choice == "1":
    #     print("\nğŸ”¬ è¿è¡Œç»¼åˆåˆ†æ...")
    #     # è¿è¡Œç»¼åˆåˆ†æ
    for subject in subject_list:
        print(f"\nğŸ”¬ å¤„ç†å—è¯•è€…: {subject}")
        # ä¸ºæ¯ä¸ªå—è¯•è€…è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼‰
        subject_output_dir = os.path.join(root_path, subject, 'ptt_bp_analysis')
        os.makedirs(subject_output_dir, exist_ok=True)
        
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = PTTBloodPressureAnalyzer(output_dir=subject_output_dir)
        
        # ä¿®æ”¹æ•°æ®åŠ è½½è·¯å¾„ä»¥åŒ…å«subjectï¼ˆç»å¯¹è·¯å¾„ï¼‰
        analyzer.ptt_output_dir = os.path.join(root_path, subject, 'ptt_output')
        analyzer.csv_output_dir = os.path.join(root_path, subject, 'csv_output')
        analyzer.subject = subject  # æ·»åŠ subjectå±æ€§ç”¨äºæ–‡ä»¶å
        
        # è¿è¡Œç»¼åˆåˆ†æï¼ˆæ¨¡å¼1ï¼‰
        results = analyzer.run_comprehensive_analysis()
        
        if results and results['overall']:
            overall_results = results['overall']
            
            # æ˜¾ç¤ºæœ€ä½³ç›¸å…³æ€§
            # print(f"\nğŸ† Top Significant Correlations (Overall Analysis):")
            print(f"\nğŸ† Top Significant Correlations (Overall Analysis for {subject}):")
            all_corrs = []
            for sensor_pair, physio_data in overall_results['correlations'].items():
                for physio_col, stats_data in physio_data.items():
                    if stats_data['significant']:
                        all_corrs.append((abs(stats_data['correlation']), 
                                        analyzer._format_sensor_pair_label_en(sensor_pair),
                                        analyzer._format_physio_label_en(physio_col),
                                        stats_data['correlation'],
                                        stats_data['p_value'],
                                        stats_data['n_samples']))
            
            all_corrs.sort(reverse=True)
            for i, (abs_corr, sensor_label, physio_label, corr, p_val, n_samples) in enumerate(all_corrs[:10]):
                direction = "â†‘" if corr > 0 else "â†“"
                print(f"   {i+1:2d}. {sensor_label} â†â†’ {physio_label}")
                print(f"       r={corr:+.3f} {direction}, p={p_val:.2e}, N={n_samples}")
    
    #     elif choice == "2":
    #     print("\nğŸ¯ è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆåˆ†æ...")
    #     # è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆ
    #     individual_models = analyzer.run_individual_regression_analysis()
        
    #     if individual_models:
    #         print(f"\nğŸ“Š å•ç‹¬å®éªŒæ‹Ÿåˆå®Œæˆ!")
    #         print(f"   â€¢ æˆåŠŸåˆ†æå®éªŒæ•°: {len(individual_models)}")
    #         print(f"   â€¢ è¯¦ç»†ç»“æœå·²ä¿å­˜: individual_experiment_models.csv")
    #         print(f"   â€¢ æ€§èƒ½å¯¹æ¯”å›¾: individual_model_performance_comparison.png")
    
    # elif choice == "3":
    #      print("\nğŸ¯ è¿è¡Œè·¨å®éªŒæ‹Ÿåˆåˆ†æ...")
    #      # è¿è¡Œè·¨å®éªŒæ‹Ÿåˆåˆ†æ
    #      exp_sensor_models = analyzer.run_cross_experiments_analysis()
         
    #      if exp_sensor_models:
    #          print(f"\nâœ… è·¨å®éªŒæ‹Ÿåˆå®Œæˆ!")
    #          print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")
    # else:
    #     print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œç»¼åˆåˆ†æ")
    #     choice = "1"
    #     # é€’å½’è°ƒç”¨åŸå§‹åˆ†æ
    #     analyzer.run_comprehensive_analysis()
    
    # print(f"\nâœ… åˆ†æå®Œæˆ!")
    # print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")
    print(f"\nâœ… æ‰€æœ‰å—è¯•è€…åˆ†æå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨æ¯ä¸ªå—è¯•è€…çš„ ptt_bp_analysis ç›®å½•ä¸­")

if __name__ == "__main__":
    main() 