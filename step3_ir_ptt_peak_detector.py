#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ©º IRé€šé“ä¸“é—¨çš„PTTå³°å€¼æ£€æµ‹å™¨ - ä¼˜åŒ–è¾“å‡ºä¸PTTå‡†å¤‡ï¼ˆæ‰¹é‡å¤„ç†ç‰ˆï¼Œå«å‚…é‡Œå¶å¿ƒç‡åˆ†æï¼‰

åŸºäºå¸ˆå…„å»ºè®®çš„æ”¹è¿›ï¼š
1. âœ… ä¸“æ³¨IRé€šé“å³°å€¼æ£€æµ‹ï¼ˆä¿¡å·è´¨é‡æœ€ä½³ï¼‰
2. âœ… ä½¿ç”¨neurokit2è®¡ç®—IBIå¹¶éªŒè¯
3. âœ… åŒä¸€å¿ƒè·³åŒºé—´çš„å³°å€¼åŒ¹é…
4. âœ… è¾“å‡ºå³°å€¼ã€IBIå’ŒPTTé¢„è§ˆCSVï¼Œæ–¹ä¾¿åç»­å¤„ç†
5. âœ… æ‰¹é‡å¤„ç†æ‰€æœ‰å®éªŒï¼Œå­˜å‚¨åˆ°expXå­æ–‡ä»¶å¤¹
6. âœ… æ–°å¢å‚…é‡Œå¶å¿ƒç‡åˆ†æï¼Œä¸¥æ ¼ç…§æŠ„data_processor.pyçš„get_hrå’Œplot_psd_analysis

æ ¸å¿ƒåŸç†ï¼š
- PTTä½¿ç”¨å³°å€¼æ—¶é—´å·®è®¡ç®—
- IRé€šé“ä¿¡å·æœ€ç¨³å®š
- IBIéªŒè¯ç¡®ä¿å³°å€¼å‡†ç¡®
- å‚…é‡Œå¶åˆ†æéªŒè¯å¿ƒç‡ä¸€è‡´æ€§ï¼ˆä¸data_processor.pyä¸€è‡´ï¼‰
- 4ä¼ æ„Ÿå™¨ç”Ÿæˆ6ä¸ªPTTç»„åˆ
"""

import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
from scipy.signal import butter, filtfilt, find_peaks, welch
import warnings

# å°è¯•å¯¼å…¥ä¸“ä¸šåº“ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…å°±ä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
try:
    import neurokit2 as nk
    NEUROKIT_AVAILABLE = True
except ImportError:
    NEUROKIT_AVAILABLE = False
    print("âš ï¸  NeuroKit2æœªå®‰è£…ï¼Œå°†ä½¿ç”¨scipyå¤‡é€‰æ–¹æ¡ˆ")

try:
    import heartpy as hp
    HEARTPY_AVAILABLE = True
except ImportError:
    HEARTPY_AVAILABLE = False
    print("âš ï¸  HeartPyæœªå®‰è£…ï¼Œå°†ä½¿ç”¨scipyå¤‡é€‰æ–¹æ¡ˆ")

warnings.filterwarnings('ignore')

class IRBasedPTTPeakDetector:
    """åŸºäºIRé€šé“çš„PTTå³°å€¼æ£€æµ‹å™¨ - æ”¯æŒå¤šç§ä¸“ä¸šåº“åŠå‚…é‡Œå¶åˆ†æ"""
    
    def __init__(self, data_path="output/csv_output", method="auto"):
        self.data_path = data_path
        self.output_dir = "ptt_output"
        self.sensors = ['sensor2', 'sensor3', 'sensor4', 'sensor5']
        self.target_channel = 'ir'
        self.sensor_mapping = {
            'sensor2': 'nose', 'sensor3': 'finger', 
            'sensor4': 'wrist', 'sensor5': 'ear'
        }
        # åŠ¨æ€è®¡ç®—é‡‡æ ·ç‡ï¼Œè€Œä¸æ˜¯å›ºå®š100Hz
        self.fs = None  # å°†åœ¨æ•°æ®åŠ è½½æ—¶åŠ¨æ€è®¡ç®—
        self.default_fs = 100  # é»˜è®¤é‡‡æ ·ç‡ä½œä¸ºåå¤‡
        self.min_hr = 50
        self.max_hr = 200
        self.refractory_period = 0.3
        self.filter_lowcut = 0.5
        self.filter_highcut = 3.0
        self.filter_order = 3
        self.ibi_tolerance = 0.15
        
        # é€‰æ‹©å³°å€¼æ£€æµ‹æ–¹æ³•
        self.detection_method = self._select_method(method)
        print(f"ğŸ”§ å³°å€¼æ£€æµ‹æ–¹æ³•: {self.detection_method}")
        
        os.makedirs(self.output_dir, exist_ok=True)
    
    def calculate_sampling_rate(self, timestamps):
        """åŠ¨æ€è®¡ç®—é‡‡æ ·ç‡ï¼ŒåŸºäºæ—¶é—´æˆ³å·®å€¼"""
        if len(timestamps) < 2:
            return self.default_fs
        
        # è®¡ç®—æ—¶é—´æˆ³å·®å€¼
        time_diff = np.diff(timestamps)
        # è¿‡æ»¤æ‰è´Ÿå€¼å’Œé›¶å€¼
        valid_diffs = time_diff[time_diff > 0]
        if len(valid_diffs) == 0:
            return self.default_fs
        
        # è®¡ç®—é‡‡æ ·ç‡
        mean_interval = np.mean(valid_diffs)
        sampling_rate = 1 / mean_interval
        
        # åˆç†æ€§æ£€æŸ¥ï¼šé‡‡æ ·ç‡åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        if 50 <= sampling_rate <= 2500:
            return sampling_rate
        else:
            print(f"âš ï¸ è®¡ç®—å‡ºçš„é‡‡æ ·ç‡ {sampling_rate:.1f}Hz è¶…å‡ºåˆç†èŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤å€¼ {self.default_fs}Hz")
            return self.default_fs

    def _select_method(self, method):
        """æ™ºèƒ½é€‰æ‹©å¯ç”¨çš„å³°å€¼æ£€æµ‹æ–¹æ³•"""
        if method == "auto":
            if NEUROKIT_AVAILABLE:
                return "neurokit2"
            elif HEARTPY_AVAILABLE:
                return "heartpy"
            else:
                return "scipy_advanced"
        elif method == "neurokit2" and NEUROKIT_AVAILABLE:
            return "neurokit2"
        elif method == "heartpy" and HEARTPY_AVAILABLE:
            return "heartpy"
        else:
            return "scipy_advanced"

    def bandpass_filter(self, data, lowcut=0.5, highcut=3.0, fs=100, order=3):
        """å¸¦é€šæ»¤æ³¢ - å¢å¼ºç‰ˆï¼Œå¤„ç†NaNå€¼"""
        try:
            # æ£€æŸ¥è¾“å…¥æ•°æ®
            if len(data) == 0:
                return data
                
            # å¤„ç†NaNå€¼
            data_array = np.array(data, dtype=float)
            nan_count = np.isnan(data_array).sum()
            if nan_count > 0:
                # ä½¿ç”¨çº¿æ€§æ’å€¼å¡«å……NaNå€¼
                data_series = pd.Series(data_array)
                data_interpolated = data_series.interpolate(method='linear')
                data_clean = data_interpolated.fillna(method='bfill').fillna(method='ffill').values
            else:
                data_clean = data_array.copy()
            
            # æ£€æŸ¥æ•°æ®å˜å¼‚æ€§
            data_std = np.std(data_clean)
            if data_std < 1e-10:
                return data_clean
            
            nyquist = fs / 2
            low = max(lowcut / nyquist, 0.01)
            high = min(highcut / nyquist, 0.99)
            
            if low >= high:
                return data_clean
            
            b, a = butter(order, [low, high], btype='band')
            filtered_data = filtfilt(b, a, data_clean)
            
            # æ£€æŸ¥æ»¤æ³¢ç»“æœ
            if np.isnan(filtered_data).sum() > 0:
                return data_clean
            
            return filtered_data
            
        except Exception as e:
            print(f"âš ï¸  æ»¤æ³¢å¤±è´¥: {e}")
            try:
                data_array = np.array(data, dtype=float)
                data_series = pd.Series(data_array)
                data_interpolated = data_series.interpolate(method='linear')
                return data_interpolated.fillna(method='bfill').fillna(method='ffill').values
            except:
                return np.array(data, dtype=float)

    def get_hr(self, y, sr=100, min=50, max=200):
        """è®¡ç®—å¿ƒç‡ï¼ˆç›´æ¥ç…§æŠ„data_processor.pyçš„get_hrï¼‰"""
        try:
            p, q = welch(y, sr, nfft=1e5/sr, nperseg=np.min((len(y)-1, 256)))
            return p[(p>min/60)&(p<max/60)][np.argmax(q[(p>min/60)&(p<max/60)])]*60
        except Exception as e:
            print(f"âš ï¸  å¿ƒç‡è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def detect_peaks_neurokit2(self, signal, fs=100):
        """ä½¿ç”¨NeuroKit2è¿›è¡Œä¸“ä¸šå³°å€¼æ£€æµ‹"""
        try:
            filtered_signal = self.bandpass_filter(signal, self.filter_lowcut, self.filter_highcut, fs)
            peaks_dict, info_dict = nk.ppg_peaks(filtered_signal, sampling_rate=fs, method="elgendi")
            peak_indices = np.where(peaks_dict['PPG_Peaks'] == 1)[0]
            
            if len(peak_indices) < 2:
                return self._empty_result(filtered_signal, signal)
            
            peak_times = peak_indices / fs
            ibi_ms = np.diff(peak_times) * 1000
            
            try:
                hrv_dict = nk.hrv_time(ibi_ms, sampling_rate=1000, show=False)
                hrv_metrics = hrv_dict.to_dict('records')[0] if not hrv_dict.empty else {}
            except:
                hrv_metrics = {}
            
            return self._process_peak_results(peak_indices, peak_times, ibi_ms, filtered_signal, signal, hrv_metrics)
            
        except Exception as e:
            print(f"âš ï¸  NeuroKit2å³°å€¼æ£€æµ‹å¤±è´¥: {e}")
            return self._empty_result(signal, signal, 'error')
    
    def detect_peaks_heartpy(self, signal, fs=100):
        """ä½¿ç”¨HeartPyè¿›è¡Œå³°å€¼æ£€æµ‹"""
        try:
            filtered_signal = self.bandpass_filter(signal, self.filter_lowcut, self.filter_highcut, fs)
            working_data, measures = hp.process(filtered_signal, sample_rate=fs)
            peak_indices = working_data['peaklist']
            
            if len(peak_indices) < 2:
                return self._empty_result(filtered_signal, signal)
            
            peak_times = np.array(peak_indices) / fs
            ibi_ms = np.diff(peak_times) * 1000
            
            hrv_metrics = {
                'rmssd': measures.get('rmssd', 0),
                'pnn50': measures.get('pnn50', 0),
                'mean_hr': measures.get('bpm', 0)
            }
            
            return self._process_peak_results(peak_indices, peak_times, ibi_ms, filtered_signal, signal, hrv_metrics)
            
        except Exception as e:
            print(f"âš ï¸  HeartPyå³°å€¼æ£€æµ‹å¤±è´¥: {e}")
            return self._empty_result(signal, signal, 'error')
    
    def detect_peaks_scipy_advanced(self, signal, fs=100):
        """æ”¹è¿›çš„scipyå³°å€¼æ£€æµ‹"""
        try:
            filtered_signal = self.bandpass_filter(signal, self.filter_lowcut, self.filter_highcut, fs)
            min_distance = int(self.refractory_period * fs)
            signal_std = np.std(filtered_signal)
            signal_mean = np.mean(filtered_signal)
            
            thresholds = [
                (signal_mean + 0.2 * signal_std, 0.1 * signal_std),
                (signal_mean + 0.1 * signal_std, 0.05 * signal_std),
                (signal_mean, 0.02 * signal_std)
            ]
            
            peak_indices = np.array([])
            for height_threshold, prominence_threshold in thresholds:
                peak_indices, _ = find_peaks(
                    filtered_signal,
                    height=height_threshold,
                    distance=min_distance,
                    prominence=prominence_threshold
                )
                if len(peak_indices) >= 5:
                    break
            
            if len(peak_indices) < 2:
                return self._empty_result(filtered_signal, signal)
            
            peak_times = peak_indices / fs
            ibi_ms = np.diff(peak_times) * 1000
            hrv_metrics = self._calculate_hrv_metrics(ibi_ms)
            
            return self._process_peak_results(peak_indices, peak_times, ibi_ms, filtered_signal, signal, hrv_metrics)
            
        except Exception as e:
            print(f"âš ï¸  Scipyå³°å€¼æ£€æµ‹å¤±è´¥: {e}")
            return self._empty_result(signal, signal, 'error')
    
    def _calculate_hrv_metrics(self, ibi_ms):
        """è®¡ç®—HRVæŒ‡æ ‡"""
        if len(ibi_ms) < 2:
            return {}
        
        try:
            diff_ibi = np.diff(ibi_ms)
            rmssd = np.sqrt(np.mean(diff_ibi**2))
            pnn50 = np.sum(np.abs(diff_ibi) > 50) / len(diff_ibi) * 100
            sdnn = np.std(ibi_ms)
            
            return {
                'rmssd': rmssd,
                'pnn50': pnn50,
                'sdnn': sdnn
            }
        except:
            return {}
    
    def _process_peak_results(self, peak_indices, peak_times, ibi_ms, filtered_signal, original_signal, hrv_metrics=None):
        """å¤„ç†å³°å€¼æ£€æµ‹ç»“æœ"""
        valid_ibi_mask = (ibi_ms >= 300) & (ibi_ms <= 1200)
        valid_ratio = np.sum(valid_ibi_mask) / len(ibi_ms) if len(ibi_ms) > 0 else 0
        
        if valid_ratio >= 0.7:
            quality = 'excellent'
        elif valid_ratio >= 0.5:
            quality = 'good'
        elif valid_ratio >= 0.3:
            quality = 'fair'
        else:
            quality = 'poor'
        
        return {
            'peaks': peak_indices,
            'ibi_ms': ibi_ms,
            'filtered_signal': filtered_signal,
            'original_signal': original_signal,
            'peak_times': peak_times,
            'peak_count': len(peak_indices),
            'quality': quality,
            'valid_ibi_ratio': valid_ratio,
            'hrv_metrics': hrv_metrics or {}
        }
    
    def _empty_result(self, filtered_signal, original_signal, quality='poor'):
        """è¿”å›ç©ºç»“æœ"""
        return {
            'peaks': np.array([]),
            'ibi_ms': np.array([]),
            'filtered_signal': filtered_signal,
            'original_signal': original_signal,
            'peak_times': np.array([]),
            'peak_count': 0,
            'quality': quality,
            'valid_ibi_ratio': 0,
            'hrv_metrics': {}
        }
    
    def detect_peaks_robust(self, signal, fs=100):
        """ç»Ÿä¸€çš„å³°å€¼æ£€æµ‹å…¥å£ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•"""
        if self.detection_method == "neurokit2":
            return self.detect_peaks_neurokit2(signal, fs)
        elif self.detection_method == "heartpy":
            return self.detect_peaks_heartpy(signal, fs)
        else:
            return self.detect_peaks_scipy_advanced(signal, fs)
    
    def calculate_heart_rate_stats(self, ibi_ms):
        """è®¡ç®—å¿ƒç‡ç»Ÿè®¡ä¿¡æ¯"""
        if len(ibi_ms) == 0:
            return {
                'hr_mean': 0,
                'hr_std': 0,
                'ibi_mean': 0,
                'ibi_std': 0,
                'rmssd': 0,
                'pnn50': 0
            }
        
        hr_bpm = 60000 / ibi_ms
        ibi_mean = np.mean(ibi_ms)
        ibi_std = np.std(ibi_ms)
        hr_mean = np.mean(hr_bpm)
        hr_std = np.std(hr_bpm)
        
        if len(ibi_ms) > 1:
            diff_ibi = np.diff(ibi_ms)
            rmssd = np.sqrt(np.mean(diff_ibi**2))
            pnn50 = np.sum(np.abs(diff_ibi) > 50) / len(diff_ibi) * 100
        else:
            rmssd = 0
            pnn50 = 0
        
        return {
            'hr_mean': hr_mean,
            'hr_std': hr_std,
            'ibi_mean': ibi_mean,
            'ibi_std': ibi_std,
            'rmssd': rmssd,
            'pnn50': pnn50
        }
    
    def match_peaks_across_sensors(self, sensor_results):
        """åŒ¹é…ä¸åŒä¼ æ„Ÿå™¨é—´åŒä¸€å¿ƒè·³çš„å³°å€¼"""
        try:
            valid_sensors = [s for s in self.sensors 
                           if s in sensor_results 
                           and sensor_results[s]['peak_count'] > 5
                           and sensor_results[s]['quality'] in ['excellent', 'good']]
            
            if len(valid_sensors) < 2:
                print("âš ï¸  é«˜è´¨é‡ä¼ æ„Ÿå™¨æ•°é‡ä¸è¶³ï¼Œå°è¯•æ”¾å®½æ ‡å‡†")
                valid_sensors = [s for s in self.sensors 
                               if s in sensor_results 
                               and sensor_results[s]['peak_count'] > 3
                               and sensor_results[s]['quality'] != 'error']
            
            if len(valid_sensors) < 2:
                print("âš ï¸  æœ‰æ•ˆä¼ æ„Ÿå™¨æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå³°å€¼åŒ¹é…")
                return {}
            
            print(f"ğŸ“ æœ‰æ•ˆä¼ æ„Ÿå™¨: {valid_sensors}")
            
            reference_sensor = max(valid_sensors, 
                                 key=lambda s: sensor_results[s]['valid_ibi_ratio'])
            reference_peaks = sensor_results[reference_sensor]['peak_times']
            
            print(f"ğŸ“ å‚è€ƒä¼ æ„Ÿå™¨: {reference_sensor} (è´¨é‡: {sensor_results[reference_sensor]['quality']})")
            
            heartbeat_windows = []
            for i, ref_time in enumerate(reference_peaks):
                if i == 0:
                    window_start = 0
                    if len(reference_peaks) > 1:
                        window_end = ref_time + (reference_peaks[1] - reference_peaks[0])/2
                    else:
                        window_end = ref_time + 0.5
                elif i == len(reference_peaks) - 1:
                    window_start = ref_time - (reference_peaks[i] - reference_peaks[i-1])/2
                    window_end = float('inf')
                else:
                    window_start = ref_time - (reference_peaks[i] - reference_peaks[i-1])/2
                    window_end = ref_time + (reference_peaks[i+1] - reference_peaks[i])/2
                
                heartbeat_windows.append({
                    'heartbeat_id': i + 1,
                    'reference_time': ref_time,
                    'window_start': window_start,
                    'window_end': window_end,
                    'sensor_peaks': {reference_sensor: ref_time}
                })
            
            for sensor in valid_sensors:
                if sensor == reference_sensor:
                    continue
                    
                sensor_peaks = sensor_results[sensor]['peak_times']
                
                for peak_time in sensor_peaks:
                    best_window = None
                    min_distance = float('inf')
                    
                    for window in heartbeat_windows:
                        if window['window_start'] <= peak_time <= window['window_end']:
                            distance = abs(peak_time - window['reference_time'])
                            if distance < min_distance:
                                min_distance = distance
                                best_window = window
                    
                    if best_window is not None and min_distance < 0.2:
                        best_window['sensor_peaks'][sensor] = peak_time
            
            complete_heartbeats = [hb for hb in heartbeat_windows 
                                 if len(hb['sensor_peaks']) >= 2]
            
            print(f"ğŸ“Š å®Œæ•´å¿ƒè·³æ•°é‡: {len(complete_heartbeats)}/{len(heartbeat_windows)}")
            
            return {
                'heartbeat_windows': heartbeat_windows,
                'complete_heartbeats': complete_heartbeats,
                'valid_sensors': valid_sensors,
                'reference_sensor': reference_sensor
            }
            
        except Exception as e:
            print(f"âš ï¸  å³°å€¼åŒ¹é…å¤±è´¥: {e}")
            return {}
    
    def process_experiment(self, exp_id):
        """å¤„ç†å•ä¸ªå®éªŒçš„IRé€šé“æ•°æ®"""
        print(f"\nğŸ” å¼€å§‹å¤„ç†å®éªŒ {exp_id} - ä¸“æ³¨IRé€šé“")
        
        exp_output_dir = os.path.join(self.output_dir, f"exp_{exp_id}")
        os.makedirs(exp_output_dir, exist_ok=True)
        self.current_exp_output_dir = exp_output_dir
        
        sensor_results = {}
        all_signals = {}
        
        for sensor in self.sensors:
            try:
                file_path = os.path.join(self.data_path, f"{exp_id}_hub_{sensor}_aligned.csv")
                if not os.path.exists(file_path):
                    print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    continue
                
                df = pd.read_csv(file_path)
                all_signals[sensor] = df
                
                if len(df.columns) >= 3:
                    ir_signal = df.iloc[:, 2].values  # IRé€šé“
                    
                    # åŠ¨æ€è®¡ç®—å½“å‰ä¼ æ„Ÿå™¨çš„é‡‡æ ·ç‡
                    if 'timestamp' in df.columns:
                        current_fs = self.calculate_sampling_rate(df['timestamp'].values)
                        print(f"ğŸ“Š {sensor} è®¡ç®—é‡‡æ ·ç‡: {current_fs:.1f}Hz")
                    else:
                        current_fs = self.default_fs
                        print(f"âš ï¸ {sensor} ç¼ºå°‘æ—¶é—´æˆ³ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤é‡‡æ ·ç‡: {current_fs}Hz")
                    
                    # ç¨³å¥çš„å³°å€¼æ£€æµ‹
                    peak_result = self.detect_peaks_robust(ir_signal, current_fs)
                    
                    # è®¡ç®—å¿ƒç‡ç»Ÿè®¡
                    hr_stats = self.calculate_heart_rate_stats(peak_result['ibi_ms'])
                    
                    # è®¡ç®—å‚…é‡Œå¶å¿ƒç‡ï¼ˆç…§æŠ„get_hrï¼‰
                    fft_hr = self.get_hr(ir_signal, sr=current_fs, min=50, max=200)
                    fft_freq = fft_hr / 60.0  # è½¬æ¢ä¸ºHz
                    
                    # åˆå¹¶ç»“æœ
                    peak_result.update({
                        'sensor': sensor,
                        'sensor_name': self.sensor_mapping[sensor],
                        **hr_stats,
                        'fft_hr_bpm': fft_hr,
                        'fft_peak_freq_hz': fft_freq
                    })
                    
                    sensor_results[sensor] = peak_result
                    
                    # æ‰“å°ç»“æœ
                    quality_emoji = {
                        'excellent': 'ğŸŸ¢', 'good': 'ğŸŸ¡', 
                        'fair': 'ğŸŸ ', 'poor': 'ğŸ”´', 'error': 'âŒ'
                    }
                    quality_symbol = quality_emoji.get(peak_result['quality'], 'â“')
                    
                    if peak_result['peak_count'] > 0:
                        ibi_range = f"{np.min(peak_result['ibi_ms']):.0f}-{np.max(peak_result['ibi_ms']):.0f}ms" if len(peak_result['ibi_ms']) > 0 else "N/A"
                        print(f"  {quality_symbol} {sensor}({self.sensor_mapping[sensor]}): "
                              f"{peak_result['peak_count']}å³°å€¼, "
                              f"HR={hr_stats['hr_mean']:.1f}Â±{hr_stats['hr_std']:.1f}BPM, "
                              f"FFT HR={fft_hr:.1f}BPM, "
                              f"IBI={ibi_range}, "
                              f"è´¨é‡={peak_result['quality']}({peak_result.get('valid_ibi_ratio', 0)*100:.0f}%)")
                    else:
                        print(f"  {quality_symbol} {sensor}({self.sensor_mapping[sensor]}): æœªæ£€æµ‹åˆ°æœ‰æ•ˆå³°å€¼")
                        
                else:
                    print(f"âš ï¸  {sensor}: æ•°æ®åˆ—ä¸è¶³")
                    
            except Exception as e:
                print(f"âŒ å¤„ç† {sensor} å¤±è´¥: {e}")
                continue
        
        matched_results = self.match_peaks_across_sensors(sensor_results)
        self.save_results(exp_id, sensor_results, matched_results, all_signals)
        
        return sensor_results, matched_results
    
    def save_results(self, exp_id, sensor_results, matched_results, all_signals):
        """ä¿å­˜æ£€æµ‹ç»“æœ - 5ä¸ªæ ¸å¿ƒCSVæ–‡ä»¶ï¼ŒåŒ…å«å‚…é‡Œå¶å¿ƒç‡"""
        try:
            # 1. ä¼ æ„Ÿå™¨è´¨é‡æ±‡æ€»
            sensor_summary = []
            for sensor in sensor_results:
                result = sensor_results[sensor]
                
                # åŠ¨æ€è®¡ç®—å½“å‰ä¼ æ„Ÿå™¨çš„é‡‡æ ·ç‡
                if 'timestamp' in all_signals[sensor].columns:
                    current_fs = self.calculate_sampling_rate(all_signals[sensor]['timestamp'].values)
                else:
                    current_fs = self.default_fs
                
                signal_duration = len(all_signals[sensor].iloc[:, 2]) / current_fs
                
                sensor_summary.append({
                    'sensor': sensor,
                    'sensor_name': result['sensor_name'],
                    'peak_count': result['peak_count'],
                    'quality': result['quality'],
                    'valid_ibi_ratio': result.get('valid_ibi_ratio', 0),
                    'hr_mean_bpm': result['hr_mean'],
                    'hr_std_bpm': result['hr_std'],
                    'ibi_mean_ms': result['ibi_mean'],
                    'ibi_std_ms': result['ibi_std'],
                    'rmssd_ms': result['rmssd'],
                    'pnn50_percent': result['pnn50'],
                    'signal_duration_s': signal_duration,
                    'fft_hr_bpm': result['fft_hr_bpm'],
                    'fft_peak_freq_hz': result['fft_peak_freq_hz']
                })
            
            if sensor_summary:
                summary_df = pd.DataFrame(sensor_summary)
                summary_file = os.path.join(self.current_exp_output_dir, f"sensor_summary_exp_{exp_id}.csv")
                summary_df.to_csv(summary_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜ä¼ æ„Ÿå™¨æ±‡æ€»: {summary_file}")
            
            # 2. æ‰€æœ‰å³°å€¼è¯¦ç»†ä¿¡æ¯
            all_peaks = []
            for sensor in sensor_results:
                result = sensor_results[sensor]
                for i, (peak_idx, peak_time) in enumerate(zip(result['peaks'], result['peak_times'])):
                    all_peaks.append({
                        'sensor': sensor,
                        'sensor_name': result['sensor_name'],
                        'peak_number': i + 1,
                        'peak_index': int(peak_idx),
                        'peak_time_s': peak_time,
                        'quality': result['quality']
                    })
            
            if all_peaks:
                peaks_df = pd.DataFrame(all_peaks)
                peaks_file = os.path.join(self.current_exp_output_dir, f"all_peaks_exp_{exp_id}.csv")
                peaks_df.to_csv(peaks_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜æ‰€æœ‰å³°å€¼: {peaks_file}")
            
            # 3. æ‰€æœ‰IBIè¯¦ç»†ä¿¡æ¯
            all_ibi = []
            for sensor in sensor_results:
                result = sensor_results[sensor]
                for i, ibi_val in enumerate(result['ibi_ms']):
                    all_ibi.append({
                        'sensor': sensor,
                        'sensor_name': result['sensor_name'],
                        'ibi_number': i + 1,
                        'ibi_ms': ibi_val,
                        'hr_bpm': 60000 / ibi_val,
                        'is_valid': 300 <= ibi_val <= 1200,
                        'quality': result['quality']
                    })
            
            if all_ibi:
                ibi_df = pd.DataFrame(all_ibi)
                ibi_file = os.path.join(self.current_exp_output_dir, f"all_ibi_exp_{exp_id}.csv")
                ibi_df.to_csv(ibi_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜æ‰€æœ‰IBI: {ibi_file}")
            
            # 4. åŒ¹é…çš„å¿ƒè·³å’ŒPTTè®¡ç®—
            if matched_results and 'complete_heartbeats' in matched_results:
                heartbeat_data = []
                for hb in matched_results['complete_heartbeats']:
                    row = {'heartbeat_id': hb['heartbeat_id']}
                    for sensor in matched_results['valid_sensors']:
                        row[f'{sensor}_peak_time_s'] = hb['sensor_peaks'].get(sensor, np.nan)
                    heartbeat_data.append(row)
                
                if heartbeat_data:
                    heartbeat_df = pd.DataFrame(heartbeat_data)
                    heartbeat_file = os.path.join(self.current_exp_output_dir, f"matched_heartbeats_exp_{exp_id}.csv")
                    heartbeat_df.to_csv(heartbeat_file, index=False)
                    print(f"ğŸ’¾ ä¿å­˜åŒ¹é…å¿ƒè·³: {heartbeat_file}")
                    
                    self.calculate_ptt_analysis(heartbeat_df, exp_id, matched_results['valid_sensors'])
            
            # ç”Ÿæˆå¯è§†åŒ–
            self.create_visualizations(exp_id, sensor_results, matched_results, all_signals)
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def calculate_ptt_analysis(self, heartbeat_df, exp_id, valid_sensors):
        """è®¡ç®—PTTåˆ†æ - çŸ©é˜µæ±‡æ€» + æ—¶é—´åºåˆ—"""
        try:
            sensor_combinations = []
            for i in range(len(valid_sensors)):
                for j in range(i+1, len(valid_sensors)):
                    sensor_combinations.append((valid_sensors[i], valid_sensors[j]))
            
            print(f"\nğŸ“Š PTTåˆ†æ ({len(sensor_combinations)}ä¸ªä¼ æ„Ÿå™¨ç»„åˆ):")
            
            ptt_summary = []
            ptt_timeseries_all = []
            
            for sensor1, sensor2 in sensor_combinations:
                col1 = f'{sensor1}_peak_time_s'
                col2 = f'{sensor2}_peak_time_s'
                
                if col1 in heartbeat_df.columns and col2 in heartbeat_df.columns:
                    valid_data = heartbeat_df.dropna(subset=[col1, col2])
                    
                    if len(valid_data) > 0:
                        ptt_values = (valid_data[col2] - valid_data[col1]) * 1000
                        
                        ptt_summary.append({
                            'sensor_pair': f"{sensor1}-{sensor2}",
                            'sensor_names': f"{self.sensor_mapping[sensor1]}â†’{self.sensor_mapping[sensor2]}",
                            'valid_heartbeats': len(valid_data),
                            'mean_ptt_ms': np.mean(ptt_values),
                            'std_ptt_ms': np.std(ptt_values),
                            'min_ptt_ms': np.min(ptt_values),
                            'max_ptt_ms': np.max(ptt_values),
                            'median_ptt_ms': np.median(ptt_values),
                            'q25_ptt_ms': np.percentile(ptt_values, 25),
                            'q75_ptt_ms': np.percentile(ptt_values, 75)
                        })
                        
                        for idx, (heartbeat_id, ptt_val) in enumerate(zip(valid_data['heartbeat_id'], ptt_values)):
                            ptt_timeseries_all.append({
                                'heartbeat_id': heartbeat_id,
                                'sensor_pair': f"{sensor1}-{sensor2}",
                                'sensor_names': f"{self.sensor_mapping[sensor1]}â†’{self.sensor_mapping[sensor2]}",
                                'ptt_ms': ptt_val,
                                f'{sensor1}_time_s': valid_data[col1].iloc[idx],
                                f'{sensor2}_time_s': valid_data[col2].iloc[idx]
                            })
                        
                        print(f"  ğŸ“Š {self.sensor_mapping[sensor1]}â†’{self.sensor_mapping[sensor2]}: "
                              f"{np.mean(ptt_values):.1f}Â±{np.std(ptt_values):.1f}ms "
                              f"({len(valid_data)}å¿ƒè·³)")
            
            if ptt_summary:
                ptt_matrix_df = pd.DataFrame(ptt_summary)
                ptt_matrix_file = os.path.join(self.current_exp_output_dir, f"ptt_matrix_exp_{exp_id}.csv")
                ptt_matrix_df.to_csv(ptt_matrix_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜PTTçŸ©é˜µ: {ptt_matrix_file}")
            
            if ptt_timeseries_all:
                ptt_timeseries_df = pd.DataFrame(ptt_timeseries_all)
                ptt_timeseries_file = os.path.join(self.current_exp_output_dir, f"ptt_timeseries_exp_{exp_id}.csv")
                ptt_timeseries_df.to_csv(ptt_timeseries_file, index=False)
                print(f"ğŸ’¾ ä¿å­˜PTTæ—¶é—´åºåˆ—: {ptt_timeseries_file}")
                print(f"   ğŸ“ˆ å…±{len(ptt_timeseries_all)}ä¸ªPTTæ•°æ®ç‚¹ï¼Œå¯ç”¨äºè¡€å‹å»ºæ¨¡")
            
        except Exception as e:
            print(f"âš ï¸  PTTåˆ†æå¤±è´¥: {e}")
    
    def create_visualizations(self, exp_id, sensor_results, matched_results, all_signals):
        """åˆ›å»ºå¯è§†åŒ– - IRä¿¡å·å³°å€¼å›¾ + PSDå›¾ï¼ˆç…§æŠ„plot_psd_analysisï¼‰"""
        try:
            # 1. IRä¿¡å·å’Œå³°å€¼å›¾
            fig, axes = plt.subplots(len(self.sensors), 1, figsize=(16, 3*len(self.sensors)), sharex=True)
            if len(self.sensors) == 1:
                axes = [axes]
            
            colors = ['red', 'blue', 'green', 'orange']
            
            for idx, sensor in enumerate(self.sensors):
                ax = axes[idx]
                
                if sensor in all_signals and sensor in sensor_results:
                    result = sensor_results[sensor]
                    filtered_signal = result['filtered_signal']
                    peaks = result['peaks']
                    quality = result['quality']
                    fft_hr = result['fft_hr_bpm']
                    
                    # åŠ¨æ€è®¡ç®—å½“å‰ä¼ æ„Ÿå™¨çš„é‡‡æ ·ç‡
                    if 'timestamp' in all_signals[sensor].columns:
                        current_fs = self.calculate_sampling_rate(all_signals[sensor]['timestamp'].values)
                    else:
                        current_fs = self.default_fs
                    
                    time = np.arange(len(filtered_signal)) / current_fs
                    
                    ax.plot(time[:len(filtered_signal)], filtered_signal, 
                           color=colors[idx % len(colors)], linewidth=1.5, alpha=0.8,
                           label=f'{self.sensor_mapping[sensor]} IR')
                    
                    if len(peaks) > 0:
                        peak_times = peaks / current_fs
                        ax.scatter(peak_times, filtered_signal[peaks], 
                                 color='red', s=40, zorder=5, alpha=0.9)
                        
                        for i, (pt, ps) in enumerate(zip(peak_times, filtered_signal[peaks])):
                            if i % 10 == 0:
                                ax.annotate(f'{i+1}', (pt, ps), xytext=(5, 5), 
                                          textcoords='offset points', fontsize=8)
                    
                    ax.set_title(f'{self.sensor_mapping[sensor]} IR - {quality} - HR: {sensor_results[sensor]["hr_mean"]:.1f} BPM (FFT: {fft_hr:.1f} BPM)', 
                                fontsize=12, fontweight='bold')
                    ax.set_ylabel('Signal', fontsize=10)
                    ax.grid(True, alpha=0.3)
                    ax.legend()
                else:
                    ax.text(0.5, 0.5, f'{self.sensor_mapping[sensor]}: No Data', 
                           ha='center', va='center', transform=ax.transAxes)
                    ax.set_title(f'{self.sensor_mapping[sensor]} IR - No Data')
            
            axes[-1].set_xlabel('Time (seconds)', fontsize=12)
            plt.suptitle(f'Experiment {exp_id} - IR Channel Peak Detection', 
                        fontsize=16, fontweight='bold')
            plt.tight_layout()
            
            plot_file = os.path.join(self.current_exp_output_dir, f"ir_peaks_exp_{exp_id}.png")
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“Š ä¿å­˜IRä¿¡å·å›¾: {plot_file}")
            
            # 2. PSDå¯è§†åŒ–ï¼ˆç…§æŠ„data_processor.pyçš„plot_psd_analysisï¼‰
            sensor_dfs = {}
            for sensor in self.sensors:
                if sensor in all_signals and sensor in sensor_results:
                    df = all_signals[sensor][['timestamp', 'ir']].copy()
                    sensor_dfs[sensor] = df
            
            if sensor_dfs:
                n_sensors = len(sensor_dfs)
                channels = ['ir']  # ä»…å¤„ç†IRé€šé“
                fig, axes = plt.subplots(n_sensors, 1, figsize=(15, 4 * n_sensors))
                if n_sensors == 1:
                    axes = [axes]
                
                for i, (sensor, df) in enumerate(sensor_dfs.items()):
                    part = self.sensor_mapping[sensor]
                    ts = df['timestamp'].values
                    tsu = np.unique(ts)
                    ax = axes[i]
                    
                    if len(tsu) < 2:
                        ax.text(0.5, 0.5, 'æ—¶é—´æˆ³ä¸è¶³',
                                ha='center', va='center')
                        ax.set_title(f"{part}-ir")
                        continue
                    
                    dt = np.median(np.diff(tsu))
                    fs = 1.0 / dt
                    
                    col_idx = 1  # iré€šé“
                    if df.shape[1] <= col_idx:
                        ax.text(0.5, 0.5, 'No data',
                                ha='center', va='center', transform=ax.transAxes)
                        ax.set_title(f"{part}-ir")
                        continue
                    
                    y = df.iloc[:, col_idx].values
                    try:
                        p, q = welch(y, fs, nfft=int(1e5/fs), nperseg=min(len(y)-1, 256))
                        bpm = p * 60
                        mask = (bpm >= 30) & (bpm <= 180)
                        
                        ax.plot(bpm[mask], q[mask], linewidth=1.5, color='C0')
                        ax.set_title(f"{part}-ir")
                        ax.grid(True, alpha=0.3)
                        
                        if np.any(mask) and len(q[mask]) > 0:
                            peak_idx = np.argmax(q[mask])
                            peak_bpm = bpm[mask][peak_idx]
                            ax.axvline(peak_bpm, color='red', linestyle='--', alpha=0.5)
                            ax.text(0.98, 0.95, f'{peak_bpm:.1f} BPM',
                                    transform=ax.transAxes,
                                    ha='right', va='top',
                                    bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))
                    except Exception as e:
                        ax.text(0.5, 0.5, f"PSD å¤±è´¥\n{str(e)[:30]}",
                                ha='center', va='center', transform=ax.transAxes)
                    
                    ax.set_xlabel("Frequency (BPM)")
                    ax.set_ylabel(f"{part}\nPSD", rotation=0, labelpad=30)
                
                plt.suptitle(f"Power Spectral Density Analysis (Experiment {exp_id} - IR signals)", fontsize=16)
                plt.tight_layout(rect=[0, 0, 1, 0.96])
                
                psd_file = os.path.join(self.current_exp_output_dir, f"psd_exp_{exp_id}.png")
                plt.savefig(psd_file, dpi=300, bbox_inches='tight')
                plt.close()
                print(f"ğŸ“Š ä¿å­˜PSDå›¾: {psd_file}")
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {e}")
    
    def run_analysis(self, experiment_list=None):
        """è¿è¡ŒIRé€šé“PTTå³°å€¼æ£€æµ‹åˆ†æï¼ˆæ‰¹é‡å¤„ç†ï¼‰"""
        if experiment_list is None:
            experiment_list = [f.split('_')[0] for f in os.listdir(self.data_path) 
                             if f.endswith('_hub_sensor2_aligned.csv')]
            experiment_list = sorted(list(set(experiment_list)))
        
        print(f"\nğŸ”¬ å¼€å§‹IRé€šé“PTTå³°å€¼æ£€æµ‹åˆ†æï¼ˆæ‰¹é‡å¤„ç†ï¼‰")
        print(f"ğŸ“‹ å®éªŒåˆ—è¡¨: {experiment_list}")
        print(f"ğŸ¯ æ£€æµ‹ç­–ç•¥:")
        print(f"   - ä¸“æ³¨IRé€šé“ï¼ˆä¿¡å·è´¨é‡æœ€ä½³ï¼‰")
        print(f"   - ç¨³å¥å³°å€¼æ£€æµ‹ + IBIè´¨é‡æ§åˆ¶")
        print(f"   - å‚…é‡Œå¶å¿ƒç‡åˆ†æéªŒè¯ï¼ˆç…§æŠ„data_processor.pyï¼‰")
        print(f"   - å¿ƒç‡èŒƒå›´: {self.min_hr}-{self.max_hr} BPM")
        print(f"   - æ»¤æ³¢èŒƒå›´: {self.filter_lowcut}-{self.filter_highcut} Hz")
        print(f"   - è¾“å‡º5ä¸ªæ ‡å‡†CSVæ–‡ä»¶ + PSDå›¾ï¼ŒæŒ‰expXå­æ–‡ä»¶å¤¹å­˜å‚¨")
        
        all_results = {}
        
        for exp_id in tqdm(experiment_list, desc="å¤„ç†å®éªŒ"):
            try:
                sensor_results, matched_results = self.process_experiment(exp_id)
                all_results[exp_id] = {
                    'sensor_results': sensor_results,
                    'matched_results': matched_results
                }
            except Exception as e:
                print(f"âŒ å®éªŒ {exp_id} å¤„ç†å¤±è´¥: {e}")
                continue
        
        print(f"\nâœ… IRé€šé“PTTå³°å€¼æ£€æµ‹å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}/exp_X")
        print(f"\nğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜:")
        print(f"   1. sensor_summary_exp_X.csv - ä¼ æ„Ÿå™¨è´¨é‡æ±‡æ€»ï¼ˆå«å‚…é‡Œå¶å¿ƒç‡ï¼‰")
        print(f"   2. all_peaks_exp_X.csv - æ‰€æœ‰å³°å€¼è¯¦ç»†ä¿¡æ¯")
        print(f"   3. all_ibi_exp_X.csv - æ‰€æœ‰IBIè¯¦ç»†ä¿¡æ¯")
        print(f"   4. ptt_matrix_exp_X.csv - PTTçŸ©é˜µæ±‡æ€»")
        print(f"   5. ptt_timeseries_exp_X.csv - PTTæ—¶é—´åºåˆ—ï¼ˆç”¨äºå»ºæ¨¡ï¼‰")
        print(f"   6. psd_exp_X.png - å„ä¼ æ„Ÿå™¨IRé€šé“PSDå›¾ï¼ˆä¸data_processor.pyä¸€è‡´ï¼‰")
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥: ä½¿ç”¨ptt_timeseries_exp_X.csvè¿›è¡Œè¡€å‹å»ºæ¨¡ï¼Œæ£€æŸ¥fft_hr_bpméªŒè¯å¿ƒç‡ä¸€è‡´æ€§")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ©º IRé€šé“ä¸“é—¨çš„PTTå³°å€¼æ£€æµ‹å™¨ï¼ˆæ‰¹é‡å¤„ç†ç‰ˆï¼Œå«å‚…é‡Œå¶åˆ†æï¼‰")
    print("=" * 60)
    print("ğŸ“– ä¼˜åŒ–ç‰¹æ€§:")
    print("   â€¢ ä¸“æ³¨IRé€šé“å³°å€¼æ£€æµ‹")
    print("   â€¢ ç¨³å¥çš„IBIè®¡ç®—å’Œè´¨é‡æ§åˆ¶")
    print("   â€¢ å‚…é‡Œå¶å¿ƒç‡åˆ†æéªŒè¯ï¼ˆç…§æŠ„data_processor.pyï¼‰")
    print("   â€¢ æ™ºèƒ½å¿ƒè·³åŒ¹é…")
    print("   â€¢ æ ‡å‡†åŒ–CSVè¾“å‡ºä¾¿äºå»ºæ¨¡")
    print("   â€¢ æ‰¹é‡å¤„ç†æ‰€æœ‰å®éªŒï¼Œå­˜å‚¨åˆ°expXå­æ–‡ä»¶å¤¹")
    print("=" * 60)
    
    detector = IRBasedPTTPeakDetector()
    results = detector.run_analysis()
    
    print("\nğŸ¯ åˆ†æå®Œæˆï¼Œå»ºè®®ä¸‹ä¸€æ­¥:")
    print("1. æ£€æŸ¥æ¯ä¸ªexp_X/sensor_summary_exp_X.csväº†è§£ä¼ æ„Ÿå™¨è´¨é‡å’Œå‚…é‡Œå¶å¿ƒç‡")
    print("2. ä½¿ç”¨exp_X/ptt_timeseries_exp_X.csvè¿›è¡Œè¡€å‹å»ºæ¨¡")
    print("3. éªŒè¯PTTä¸è¡€å‹çš„ç›¸å…³æ€§ (a*PTT + b)")
    print("4. æ£€æŸ¥exp_X/psd_exp_X.pngç¡®è®¤å‚…é‡Œå¶åˆ†æç»“æœ")

if __name__ == "__main__":
    main()