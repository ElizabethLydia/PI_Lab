#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PTTä¸è¡€å‹ç›¸å…³æ€§åˆ†æ
åŸºäºå¸ˆå…„å»ºè®®ï¼šä½¿ç”¨åˆç†åŒºé—´çš„PTTæ•°æ®åˆ†æä¸è¡€å‹çš„ç›¸å…³æ€§
"""

import os
import pickle
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®éäº¤äº’æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºå¼¹çª—
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾ç‰‡ä¿å­˜æ¨¡å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.ioff()  # å…³é—­äº¤äº’æ¨¡å¼

class PTTBloodPressureAnalyzer:
    """PTTä¸è¡€å‹ç›¸å…³æ€§åˆ†æå™¨"""
    
    def __init__(self, output_dir="ptt_bp_analysis"):
        self.output_dir = output_dir
        self.ptt_output_dir = "ptt_output2"  # çª—å£åŒ–PTTæ•°æ®ç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # å®Œæ•´çš„ç”Ÿç†æŒ‡æ ‡æ˜ å°„ï¼ˆè‹±æ–‡ä¸“ä¸šæœ¯è¯­ï¼‰
        self.physiological_indicators = {
            'systolic_bp': 'Systolic BP (mmHg)',
            'diastolic_bp': 'Diastolic BP (mmHg)', 
            'mean_bp': 'Mean Arterial Pressure (mmHg)',
            'bp': 'Continuous BP (mmHg)',
            'cardiac_output': 'Cardiac Output (L/min)',
            'cardiac_index': 'Cardiac Index (L/min/mÂ²)',
            'hr': 'Heart Rate (bpm)',
            'systemic_vascular_resistance': 'Systemic Vascular Resistance (dynÂ·s/cmâµ)',
            'rsp': 'Respiration Rate (breaths/min)'
        }
        
        # PTTä¼ æ„Ÿå™¨ç»„åˆï¼ˆè‹±æ–‡æ ‡ç­¾ï¼‰
        self.ptt_combinations_en = {
            'sensor2-sensor3': 'Noseâ†’Finger',
            'sensor2-sensor4': 'Noseâ†’Wrist', 
            'sensor2-sensor5': 'Noseâ†’Ear',
            'sensor3-sensor4': 'Fingerâ†’Wrist',
            'sensor3-sensor5': 'Fingerâ†’Ear',
            'sensor4-sensor5': 'Wristâ†’Ear'
        }
        
        print("ğŸ”¬ Enhanced PTT-Cardiovascular Parameters Correlation Analyzer")
        print(f"ğŸ“ Results will be saved to: {self.output_dir}")
        print(f"ğŸ“Š Analyzing {len(self.physiological_indicators)} physiological indicators")
        print(f"ğŸ¯ Using {len(self.ptt_combinations_en)} PTT sensor combinations")
    
    def load_ground_truth_bp(self, exp_id):
        """åŠ è½½ç”Ÿç†æŒ‡æ ‡æ•°æ®ï¼ˆä»CSVæ–‡ä»¶ï¼‰"""
        try:
            # åŠ è½½CSVæ–‡ä»¶
            csv_file = f"output/csv_output/{exp_id}_biopac_aligned.csv"
            if not os.path.exists(csv_file):
                print(f"âŒ ç”Ÿç†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            # è¯»å–å®Œæ•´ç”Ÿç†æ•°æ®
            df = pd.read_csv(csv_file)
            print(f"âœ… åŠ è½½ç”Ÿç†æ•°æ®: {len(df)}æ¡è®°å½•")
            
            # æ˜¾ç¤ºå¯ç”¨çš„ç”Ÿç†æŒ‡æ ‡
            available_indicators = [col for col in df.columns if col in self.physiological_indicators.keys()]
            print(f"ğŸ“Š å¯ç”¨ç”Ÿç†æŒ‡æ ‡: {available_indicators}")
            
            return df
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç”Ÿç†æ•°æ®å¤±è´¥: {e}")
            return None
    
    def load_ptt_data(self, exp_id):
        """åŠ è½½æœ‰æ•ˆçª—å£çš„PTTæ•°æ®"""
        try:
            # åŠ è½½çª—å£éªŒè¯æ•°æ®
            window_file = f"{self.ptt_output_dir}/exp_{exp_id}/window_validation_exp_{exp_id}.csv"
            ptt_file = f"{self.ptt_output_dir}/exp_{exp_id}/ptt_windowed_exp_{exp_id}.csv"
            
            if not (os.path.exists(window_file) and os.path.exists(ptt_file)):
                print(f"âŒ PTTæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: exp_{exp_id}")
                return None
            
            # åŠ è½½çª—å£éªŒè¯ä¿¡æ¯
            window_df = pd.read_csv(window_file)
            # ç­›é€‰æœ‰æ•ˆçª—å£ï¼ˆæ—¶é¢‘åŸŸå¿ƒç‡è¯¯å·®åˆç†ï¼‰
            valid_windows = window_df[
                (window_df['is_valid'] == True) & 
                (window_df['hr_diff_bpm'].abs() <= 5)  # å¿ƒç‡è¯¯å·®â‰¤5BPM
            ]
            
            # åŠ è½½PTTæ•°æ®
            ptt_df = pd.read_csv(ptt_file)
            
            # æ–°å¢ï¼šåŸºäºIBIç­›é€‰ abs(PTT) < 0.5 * reference_mean_ibi_ms
            if 'reference_mean_ibi_ms' in ptt_df.columns:
                mask = np.abs(ptt_df['ptt_ms']) < 0.5 * ptt_df['reference_mean_ibi_ms']
                filtered_ptt = ptt_df[mask | ptt_df['reference_mean_ibi_ms'].isna()]  # å¦‚æœIBI NaNåˆ™ä¿ç•™
                print(f"ğŸ†• IBI-basedç­›é€‰: åŸå§‹{len(ptt_df)} â†’ ç­›é€‰å{len(filtered_ptt)}")
                print(f"ç­›é€‰åˆç†æ¯”ä¾‹: {len(filtered_ptt)/len(ptt_df)*100:.1f}%")  # æ–°å¢ï¼šè¾“å‡ºç­›é€‰æ¯”ä¾‹
            else:
                print("âš ï¸ æ— reference_mean_ibi_msåˆ—ï¼Œè·³è¿‡IBIç­›é€‰")
                filtered_ptt = ptt_df
            
            # åªä¿ç•™æœ‰æ•ˆçª—å£çš„PTTæ•°æ®
            valid_ptt = filtered_ptt[filtered_ptt['window_id'].isin(valid_windows['window_id'])]
            
            print(f"ğŸ“Š å®éªŒ{exp_id}: æ€»çª—å£{len(window_df)}, æœ‰æ•ˆçª—å£{len(valid_windows)}, æœ‰æ•ˆPTTæ•°æ®{len(valid_ptt)}")
            
            return {
                'window_info': valid_windows,
                'ptt_data': valid_ptt
            }
            
        except Exception as e:
            print(f"âŒ åŠ è½½PTTæ•°æ®å¤±è´¥: {e}")
            return None
    
    def remove_outliers_iqr(self, data_series):
        """ä½¿ç”¨IQRæ–¹æ³•å»é™¤æå€¼"""
        q1 = data_series.quantile(0.25)
        q3 = data_series.quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        return data_series[(data_series >= lower_bound) & (data_series <= upper_bound)]
    
    def synchronize_data(self, ptt_data, physio_data, exp_id):
        """æ—¶é—´åŒæ­¥PTTå’Œç”Ÿç†æ•°æ®"""
        synchronized_data = []
        
        for _, ptt_row in ptt_data['ptt_data'].iterrows():
            # PTTæ•°æ®çš„æ—¶é—´ä¿¡æ¯ï¼ˆä¿®æ­£åˆ—åï¼‰
            start_time = ptt_row['window_start_s']
            end_time = ptt_row['window_end_s']
            window_center = (start_time + end_time) / 2
            
            # è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆå‡è®¾ç”Ÿç†æ•°æ®çš„timestampæ˜¯ç»å¯¹æ—¶é—´æˆ³ï¼‰
            # éœ€è¦æ‰¾åˆ°ç”Ÿç†æ•°æ®æ—¶é—´æˆ³çš„èµ·å§‹ç‚¹
            physio_start_time = physio_data['timestamp'].iloc[0]
            start_timestamp = physio_start_time + start_time
            end_timestamp = physio_start_time + end_time
            
            # æ‰¾åˆ°æ—¶é—´çª—å£å†…çš„ç”Ÿç†æ•°æ®
            time_mask = (physio_data['timestamp'] >= start_timestamp) & (physio_data['timestamp'] <= end_timestamp)
            window_physio = physio_data[time_mask]
            
            if len(window_physio) == 0:
                continue  # è·³è¿‡æ²¡æœ‰ç”Ÿç†æ•°æ®çš„çª—å£
            
            # è®¡ç®—çª—å£å†…æ‰€æœ‰ç”Ÿç†æŒ‡æ ‡çš„ç»Ÿè®¡é‡ï¼ˆåªè®¡ç®—meanï¼‰
            physio_values = {}
            for indicator in self.physiological_indicators.keys():
                if indicator in physio_data.columns:
                    physio_values[f'{indicator}_mean'] = window_physio[indicator].mean()
                    # physio_values[f'{indicator}_std'] = window_physio[indicator].std()
                    # physio_values[f'{indicator}_min'] = window_physio[indicator].min()
                    # physio_values[f'{indicator}_max'] = window_physio[indicator].max()
                    physio_values[f'{indicator}_count'] = len(window_physio)
            
            # æ„å»ºåŒæ­¥æ•°æ®è¡Œ
            sync_row = {
                'exp_id': exp_id,
                'window_id': ptt_row['window_id'],
                'start_time': start_time,
                'end_time': end_time,
                'window_center': window_center,
                'sensor_pair': ptt_row['sensor_pair'],
                'ptt_ms': ptt_row['ptt_ms'],
                **physio_values
            }
            
            synchronized_data.append(sync_row)
        
        sync_df = pd.DataFrame(synchronized_data)
        print(f"ğŸ“Š åŒæ­¥å®Œæˆ: {len(sync_df)}ä¸ªæœ‰æ•ˆçª—å£")
        
        # æ–°å¢ï¼šIQRå»é™¤æå€¼ï¼ˆçª—å£çº§ï¼Ÿä½†è¿™é‡Œæ˜¯å¿ƒè·³çº§ï¼Œéœ€åˆ†ç»„ï¼‰
        # å‡è®¾åˆ†ç»„è®¡ç®—mean after IQR
        grouped = sync_df.groupby(['window_id', 'sensor_pair'])
        cleaned_data = []
        for name, group in grouped:
            clean_ptt = self.remove_outliers_iqr(group['ptt_ms'])
            if not clean_ptt.empty:
                mean_ptt = clean_ptt.mean()
                row = group.iloc[0].copy()
                row['ptt_ms'] = mean_ptt
                cleaned_data.append(row)
        cleaned_df = pd.DataFrame(cleaned_data)
        
        # ç”Ÿæˆç®±çº¿å›¾
        self.create_ptt_boxplot(cleaned_df, exp_id)  # ä¿®æ”¹ï¼šä¼ å…¥exp_id
        
        return cleaned_df
    
    def create_ptt_boxplot(self, df, exp_id=None):
        """ç”ŸæˆPTTç®±çº¿å›¾"""
        plt.figure(figsize=(10, 6))
        sns.boxplot(x='sensor_pair', y='ptt_ms', data=df)
        title = 'PTT Boxplot per Sensor Pair'
        if exp_id:
            title += f' (Exp {exp_id})'
            filename = f'exp_{exp_id}_ptt_boxplot.png'
        else:
            title += ' (Overall)'
            filename = 'overall_ptt_boxplot.png'
        plt.title(title)
        plt.savefig(os.path.join(self.output_dir, filename))
        plt.close()
    
    def calculate_correlations(self, sync_df):
        """è®¡ç®—PTTä¸æ‰€æœ‰ç”Ÿç†æŒ‡æ ‡çš„ç›¸å…³æ€§"""
        correlations = {}
        
        # ç”Ÿç†æŒ‡æ ‡ï¼ˆåªå¤„ç†meanï¼‰
        physio_metrics = []
        for indicator in self.physiological_indicators.keys():
            col_name = f'{indicator}_mean'
            if col_name in sync_df.columns:
                physio_metrics.append(col_name)
        
        # è·å–æ‰€æœ‰ä¼ æ„Ÿå™¨å¯¹
        sensor_pairs = sync_df['sensor_pair'].unique()
        
        print(f"\nğŸ“Š è®¡ç®—ç›¸å…³æ€§ï¼š{len(sensor_pairs)}ä¸ªä¼ æ„Ÿå™¨å¯¹ Ã— {len(physio_metrics)}ä¸ªç”Ÿç†æŒ‡æ ‡")
        
        for sensor_pair in sensor_pairs:
            correlations[sensor_pair] = {}
            
            # æå–è¯¥ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
            pair_data = sync_df[sync_df['sensor_pair'] == sensor_pair]
            
            if len(pair_data) < 10:  # è‡³å°‘10ä¸ªæ•°æ®ç‚¹
                continue
            
            for physio_col in physio_metrics:
                # æå–æœ‰æ•ˆæ•°æ®
                mask = ~(pair_data['ptt_ms'].isna() | pair_data[physio_col].isna())
                if mask.sum() < 10:
                    continue
                
                ptt_vals = pair_data.loc[mask, 'ptt_ms']
                physio_vals = pair_data.loc[mask, physio_col]
                
                # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
                try:
                    corr_coef, p_value = stats.pearsonr(ptt_vals, physio_vals)
                    
                    correlations[sensor_pair][physio_col] = {
                        'correlation': corr_coef,
                        'p_value': p_value,
                        'n_samples': len(ptt_vals),
                        'significant': p_value < 0.05
                    }
                except Exception as e:
                    print(f"âš ï¸ è®¡ç®—ç›¸å…³æ€§å¤±è´¥ {sensor_pair}-{physio_col}: {e}")
                    continue
        
        return correlations
    
    def create_correlation_heatmap(self, correlations, title_suffix=""):
        """åˆ›å»ºç›¸å…³æ€§çƒ­å›¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        # å‡†å¤‡æ•°æ®
        sensor_pairs = list(correlations.keys())
        physio_cols = set()
        for pair_data in correlations.values():
            physio_cols.update(pair_data.keys())
        physio_cols = sorted(list(physio_cols))
        
        if len(sensor_pairs) == 0 or len(physio_cols) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„ç›¸å…³æ€§æ•°æ®æ¥åˆ›å»ºçƒ­å›¾")
            return None
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        p_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        
        for i, sensor_pair in enumerate(sensor_pairs):
            for j, physio_col in enumerate(physio_cols):
                if physio_col in correlations[sensor_pair]:
                    corr_matrix[i, j] = correlations[sensor_pair][physio_col]['correlation']
                    p_matrix[i, j] = correlations[sensor_pair][physio_col]['p_value']
        
        # æ–°å¢ï¼šé¢„æ ¼å¼åŒ–annotå­—ç¬¦ä¸²
        annot_matrix = np.full((len(sensor_pairs), len(physio_cols)), '', dtype=object)
        for i in range(len(sensor_pairs)):
            for j in range(len(physio_cols)):
                if not np.isnan(corr_matrix[i, j]):
                    corr_str = f"{corr_matrix[i, j]:.3f}"
                    if p_matrix[i, j] < 0.05:
                        corr_str += '*'
                    annot_matrix[i, j] = corr_str
        
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(16, 10))
        
        # ç»˜åˆ¶çƒ­å›¾
        mask = np.isnan(corr_matrix)
        im = sns.heatmap(corr_matrix, 
                        xticklabels=[self._format_physio_label_en(col) for col in physio_cols],
                        yticklabels=[self._format_sensor_pair_label_en(pair) for pair in sensor_pairs],
                        annot=annot_matrix, fmt='', cmap='RdBu_r', center=0,
                        mask=mask, square=False, linewidths=0.5,
                        cbar_kws={'label': 'Correlation Coefficient'},
                        annot_kws={'size': 8})
        
        # ç§»é™¤æ—§çš„ax.text
        
        plt.title(f'PTT-Cardiovascular Parameters Correlation Analysis{title_suffix}', 
                 fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('Physiological Parameters', fontsize=12, fontweight='bold')
        plt.ylabel('PTT Sensor Combinations', fontsize=12, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        filename = f"{self.output_dir}/ptt_cardiovascular_correlation_heatmap{title_suffix.replace(' ', '_')}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜ç›¸å…³æ€§çƒ­å›¾: {filename}")
        
        return fig
    
    def _format_sensor_pair_label(self, sensor_pair):
        """æ ¼å¼åŒ–ä¼ æ„Ÿå™¨å¯¹æ ‡ç­¾"""
        # sensor2-sensor3 -> noseâ†’finger
        sensor_map = {'sensor2': 'nose', 'sensor3': 'finger', 'sensor4': 'wrist', 'sensor5': 'ear'}
        if '-' in sensor_pair:
            parts = sensor_pair.split('-')
            if len(parts) == 2:
                return f"{sensor_map.get(parts[0], parts[0])}â†’{sensor_map.get(parts[1], parts[1])}"
        return sensor_pair
    
    def _format_physio_label_en(self, physio_col):
        """æ ¼å¼åŒ–ç”Ÿç†æŒ‡æ ‡æ ‡ç­¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        # æå–åŸºç¡€æŒ‡æ ‡åç§°å’Œç»Ÿè®¡é‡
        for indicator, label in self.physiological_indicators.items():
            if physio_col.startswith(indicator):
                stat_part = physio_col.replace(indicator, '').replace('_', ' ')
                if stat_part == ' mean':
                    return label
                elif stat_part == ' std':
                    return f"{label} (SD)"
                elif stat_part == ' min':
                    return f"{label} (Min)"
                elif stat_part == ' max':
                    return f"{label} (Max)"
                else:
                    return f"{label}{stat_part}"
        return physio_col
    
    def _format_sensor_pair_label_en(self, sensor_pair):
        """æ ¼å¼åŒ–ä¼ æ„Ÿå™¨å¯¹æ ‡ç­¾ï¼ˆè‹±æ–‡ç‰ˆï¼‰"""
        return self.ptt_combinations_en.get(sensor_pair, sensor_pair)
    
    def build_regression_models(self, sync_df, correlations, exp_id=None):
        """æ„å»ºPTTâ†’ç”Ÿç†æŒ‡æ ‡çš„å›å½’æ¨¡å‹ï¼Œå¹¶è¿”å›æ¨¡å‹å’Œæ•°æ®"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)

        all_corrs = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                if stats_data['significant']:
                    all_corrs.append((abs(stats_data['correlation']), 
                                    self._format_sensor_pair_label_en(sensor_pair),
                                    self._format_physio_label_en(physio_col),
                                    stats_data['correlation'],
                                    stats_data['p_value'],
                                    stats_data['n_samples']))
                
        all_corrs.sort(reverse=True)
        
        # åˆ›å»ºç›¸å…³æ€§æ˜ å°„ï¼Œæ–¹ä¾¿åç»­æŸ¥æ‰¾
        corr_map = {}
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                key = f"{sensor_pair}â†’{physio_col}"
                corr_map[key] = {
                    'correlation': stats_data['correlation'],
                    'p_value': stats_data['p_value']
                }
        
        # ä¸»è¦ç”Ÿç†æŒ‡æ ‡ï¼ˆå‡å€¼ï¼‰
        main_physio_cols = []
        for indicator in ['systolic_bp', 'diastolic_bp', 'mean_bp', 'cardiac_output', 'cardiac_index']:
            col_name = f'{indicator}_mean'
            if col_name in sync_df.columns:
                main_physio_cols.append(col_name)
        
        # è·å–æ‰€æœ‰ä¼ æ„Ÿå™¨å¯¹
        sensor_pairs = sync_df['sensor_pair'].unique()
        print(f"ğŸ” å‘ç°ä¼ æ„Ÿå™¨å¯¹: {sensor_pairs}")
        
        # åˆ›å»ºç»“æœæ•°æ®ç»“æ„
        all_models = {}
        all_model_data = {}
        metrics_list = []  # ç”¨äºå­˜å‚¨ CSV çš„æŒ‡æ ‡æ•°æ®
        
        # ä¸ºæ¯ä¸ªä¼ æ„Ÿå™¨å¯¹å•ç‹¬å¤„ç†
        for sensor_pair in sensor_pairs:
            print(f"\nğŸ”§ å¤„ç†ä¼ æ„Ÿå™¨å¯¹: {sensor_pair}")
            
            # è¿‡æ»¤å½“å‰ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
            pair_df = sync_df[sync_df['sensor_pair'] == sensor_pair].copy()
            
            # åˆ›å»ºæ•°æ®é€è§†è¡¨ - æ¯ä¸ªçª—å£ä¸€ä¸ªPTTå€¼
            ptt_pivot = pair_df.pivot_table(
                index=['exp_id', 'window_id'], 
                values='ptt_ms',
                aggfunc='mean'
            ).reset_index().rename(columns={'ptt_ms': f'ptt_{sensor_pair}'})
            
            # åˆå¹¶ç”Ÿç†æ•°æ®ï¼ˆå–å¹³å‡å€¼ï¼‰
            physio_agg = pair_df.groupby(['exp_id', 'window_id']).agg({
                col: 'mean' for col in main_physio_cols if col in pair_df.columns
            }).reset_index()
            
            # åˆå¹¶PTTå’Œç”Ÿç†æ•°æ®
            model_data = pd.merge(ptt_pivot, physio_agg, on=['exp_id', 'window_id'], how='inner')
            
            # æ£€æŸ¥æ•°æ®é‡
            if len(model_data) < 10:
                print(f"âš ï¸ æ•°æ®ä¸è¶³: {sensor_pair} åªæœ‰{len(model_data)}ä¸ªæ ·æœ¬")
                continue
                
            # è·å–PTTç‰¹å¾åˆ—
            ptt_col = f'ptt_{sensor_pair}'
            
            # æ£€æŸ¥PTTåˆ—çš„NaNæ¯”ä¾‹
            nan_ratio = model_data[ptt_col].isna().mean()
            print(f"ğŸ“Š PTTåˆ— {ptt_col} NaNæ¯”ä¾‹: {nan_ratio:.2%}")
            
            # ä¸ºæ¯ä¸ªç”Ÿç†æŒ‡æ ‡å•ç‹¬å»ºæ¨¡
            for physio_col in main_physio_cols:
                if physio_col not in model_data.columns:
                    continue
                    
                # å‡†å¤‡æ•°æ® - ç§»é™¤NaN
                mask = ~model_data[physio_col].isna() & ~model_data[ptt_col].isna()
                
                if mask.sum() < 5:  # è‡³å°‘5ä¸ªæ ·æœ¬
                    print(f"âš ï¸ æ•°æ®ä¸è¶³: {sensor_pair}â†’{physio_col} æœ‰æ•ˆæ ·æœ¬={mask.sum()}")
                    continue
                
                X = model_data.loc[mask, ptt_col].values.reshape(-1, 1)
                y = model_data.loc[mask, physio_col].values
                
                # æ•°æ®æ ‡å‡†åŒ–
                scaler_X = StandardScaler()
                scaler_y = StandardScaler()
                X_scaled = scaler_X.fit_transform(X)
                y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
                
                # è®­ç»ƒæ¨¡å‹
                model = LinearRegression()
                model.fit(X_scaled, y_scaled)
                
                # é¢„æµ‹
                y_pred_scaled = model.predict(X_scaled)
                y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
                
                # è¯„ä¼°
                r2 = r2_score(y, y_pred)
                mae = mean_absolute_error(y, y_pred)
                
                # è·å–ç›¸å…³æ€§æ•°æ®
                model_key = f"{sensor_pair}â†’{physio_col}"
                corr_data = corr_map.get(model_key, {'correlation': float('nan'), 'p_value': float('nan')})
                ptt_correlation = corr_data['correlation']
                ptt_p_value = corr_data['p_value']
                
                # å­˜å‚¨æ¨¡å‹
                all_models[model_key] = {
                    'model': model,
                    'scaler_X': scaler_X,
                    'scaler_y': scaler_y,
                    'feature_names': [ptt_col],
                    'r2_score': r2,
                    'mae': mae,
                    'n_samples': len(y),
                    'y_true': y,
                    'y_pred': y_pred,
                    'sensor_pair': sensor_pair,
                    'physio_col': physio_col,
                    'ptt_correlation': ptt_correlation,
                    'ptt_p_value': ptt_p_value
                }
                
                print(f"ğŸ“ˆ {model_key}æ¨¡å‹: RÂ²={r2:.3f}, MAE={mae:.2f}, N={len(y)}")
                print(f"   ğŸ“Š PTTç›¸å…³æ€§: r={ptt_correlation:.3f}, p={ptt_p_value:.2e}")
                
                # åˆ›å»ºå›¾è¡¨
                plt.figure(figsize=(10, 8))  # å¢åŠ å›¾è¡¨é«˜åº¦ä»¥å®¹çº³æ›´å¤šä¿¡æ¯
                
                # 1. ç»˜åˆ¶åŸå§‹æ•°æ®ç‚¹
                plt.scatter(X, y, alpha=0.6, color='blue', label='åŸå§‹æ•°æ®')
                
                # 2. ç»˜åˆ¶æ‹Ÿåˆç›´çº¿
                x_min, x_max = np.min(X), np.max(X)
                x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)
                
                x_range_scaled = scaler_X.transform(x_range)
                y_range_scaled = model.predict(x_range_scaled)
                y_range = scaler_y.inverse_transform(y_range_scaled.reshape(-1, 1)).flatten()
                
                plt.plot(x_range, y_range, 'r-', linewidth=2, label='æ‹Ÿåˆç›´çº¿')
                
                # 3. æ·»åŠ å›¾ä¾‹å’Œæ ‡ç­¾
                plt.xlabel(f'PTT ({sensor_pair}) (ms)')
                plt.ylabel(f'{self._format_physio_label_en(physio_col)}')
                
                # è·å–æ–¹ç¨‹ç³»æ•°
                coef = model.coef_[0]
                intercept = model.intercept_
                
                # è®¡ç®—åŸå§‹æ•°æ®ç©ºé—´çš„æ–œç‡å’Œæˆªè·
                coef_original = coef * (scaler_y.scale_[0] / scaler_X.scale_[0])
                intercept_original = scaler_y.mean_[0] - coef * (scaler_X.mean_[0] * scaler_y.scale_[0] / scaler_X.scale_[0]) + intercept * scaler_y.scale_[0]
                
                # 4. æ›´æ–°æ ‡é¢˜ï¼ŒåŒ…å«ç›¸å…³æ€§ä¿¡æ¯
                plt.title(f'{self._format_physio_label_en(physio_col)} vs PTT ({sensor_pair})\n'
                        f'æ–¹ç¨‹: y = {coef_original:.3f}Â·x + {intercept_original:.3f} | ç›¸å…³æ€§: r={ptt_correlation:.3f}, p={ptt_p_value:.2e}\n'
                        f'RÂ²={r2:.3f}, MAE={mae:.2f}, n={len(y)}')
                
                plt.legend()
                plt.grid(alpha=0.3)
                
                # ä¿å­˜å›¾è¡¨
                safe_physio = physio_col.replace(' ', '_').replace('/', '_')
                safe_pair = sensor_pair.replace(' ', '_').replace('/', '_')
                if exp_id is not None:
                    plot_path = os.path.join(self.output_dir, f"exp{exp_id}_{safe_physio}_vs_{safe_pair}_fit.png")
                else:
                    plot_path = os.path.join(self.output_dir, f"{safe_physio}_vs_{safe_pair}_fit.png")
                plt.savefig(plot_path, bbox_inches='tight', dpi=150)
                plt.close()
                
                print(f"ğŸ’¾ ä¿å­˜ç‰¹å¾æ‹Ÿåˆå›¾: {plot_path}")
                
                # å­˜å‚¨æ¨¡å‹æ•°æ®
                all_model_data[model_key] = model_data.loc[mask, [ptt_col, physio_col]]
                
                # æ”¶é›†æŒ‡æ ‡æ•°æ®ç”¨äº CSV
                if exp_id is not None:
                    metrics_list.append({
                        'exp_id': exp_id,
                        'sensor_pair': sensor_pair,
                        'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                        'physiological_parameter': physio_col,
                        'parameter_label': self._format_physio_label_en(physio_col),
                        'r2_score': r2,
                        'mae': mae,
                        'n_samples': len(y),
                        'slope': coef_original,
                        'intercept': intercept_original,
                        'ptt_correlation': ptt_correlation,
                        'ptt_p_value': ptt_p_value,
                        'correlation_significant': ptt_p_value < 0.05
                    })
                else:
                    metrics_list.append({
                        'sensor_pair': sensor_pair,
                        'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                        'physiological_parameter': physio_col,
                        'parameter_label': self._format_physio_label_en(physio_col),
                        'r2_score': r2,
                        'mae': mae,
                        'n_samples': len(y),
                        'slope': coef_original,
                        'intercept': intercept_original,
                        'ptt_correlation': ptt_correlation,
                        'ptt_p_value': ptt_p_value,
                        'correlation_significant': ptt_p_value < 0.05
                    })
        
        # å¦‚æœæ²¡æœ‰ exp_idï¼Œä¿å­˜æŒ‡æ ‡åˆ° CSV
        if exp_id is None:
            print("ä¿å­˜æ•´ä½“æ¨¡å‹è¯„ä¼°ï¼š")
            csv_path = os.path.join(self.output_dir, "overall_regression_metrics.csv")
            metrics_df = pd.DataFrame(metrics_list)
            metrics_df.to_csv(csv_path, index=False)
        else:
            print("ä¿å­˜å•ä¸ªå®éªŒæ¨¡å‹è¯„ä¼°ï¼š")
            csv_path = os.path.join(self.output_dir, "all_experiments_regression_metrics.csv")
            metrics_df = pd.DataFrame(metrics_list)
            # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®ï¼›å¦åˆ™åˆ›å»ºæ–°æ–‡ä»¶
            if os.path.exists(csv_path):
                existing_df = pd.read_csv(csv_path)
                combined_df = pd.concat([existing_df, metrics_df], ignore_index=True)
                combined_df.to_csv(csv_path, index=False)
            else:
                metrics_df.to_csv(csv_path, index=False)
        
        return all_models, all_model_data

    def analyze_experiment(self, exp_id):
        """åˆ†æå•ä¸ªå®éªŒ"""
        print(f"\nğŸ” åˆ†æå®éªŒ {exp_id}")
        
        # 1. åŠ è½½æ•°æ®
        physio_data = self.load_ground_truth_bp(exp_id)
        ptt_data = self.load_ptt_data(exp_id)
        
        if physio_data is None or ptt_data is None:
            print(f"âŒ å®éªŒ {exp_id} æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        # 2. æ—¶é—´åŒæ­¥
        sync_df = self.synchronize_data(ptt_data, physio_data, exp_id)
        print(f"ğŸ“Š åŒæ­¥æ•°æ®: {len(sync_df)}ä¸ªæ—¶é—´çª—å£")
        
        # 3. ç›¸å…³æ€§åˆ†æ
        correlations = self.calculate_correlations(sync_df)
        
        # 4. å›å½’å»ºæ¨¡
        models, model_data = self.build_regression_models(sync_df, correlations, exp_id=exp_id)
        
        return {
            'sync_data': sync_df,
            'correlations': correlations,
            'models': models
        }
    
    def analyze_experiment_cross(self, exp_id):
        # 1. åŠ è½½æ•°æ®
        physio_data = self.load_ground_truth_bp(exp_id)
        ptt_data = self.load_ptt_data(exp_id)
        
        if physio_data is None or ptt_data is None:
            print(f"âŒ å®éªŒ {exp_id} æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        # 2. æ—¶é—´åŒæ­¥
        sync_df = self.synchronize_data(ptt_data, physio_data, exp_id)
        print(f"ğŸ“Š åŒæ­¥æ•°æ®: {len(sync_df)}ä¸ªæ—¶é—´çª—å£")

        return {
            'sync_data': sync_df,
        }
    
    def run_individual_experiment_analysis(self):
        """è¿è¡Œå•ä¸ªå®éªŒçš„åˆ†æ"""
        print("ğŸ”¬ å¼€å§‹å•ä¸ªå®éªŒåˆ†æ...")
        
        individual_results = {}
        all_experiments = []
        
        for exp_id in range(1, 12):
            print(f"\nğŸ” å•ç‹¬åˆ†æå®éªŒ {exp_id}")
            
            # åˆ†æå•ä¸ªå®éªŒ
            exp_result = self.analyze_experiment(exp_id)
            if exp_result:
                individual_results[exp_id] = exp_result['sync_data']
                
                # è®¡ç®—ç›¸å…³æ€§
                correlations = self.calculate_correlations(exp_result['sync_data'])
                
                # åˆ›å»ºå•ä¸ªå®éªŒçš„çƒ­å›¾
                self.create_focused_correlation_heatmap(correlations, f"_exp{exp_id}")
                
                # ä¿å­˜å•ä¸ªå®éªŒç»“æœ
                self.save_individual_experiment_results(exp_result['sync_data'], correlations, exp_id)

                # ç”¨äºç»“æœåˆå¹¶
                all_experiments.append(exp_result['sync_data'])
        
        if not all_experiments:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒæ•°æ®")
            return None
        
        # åˆå¹¶æ‰€æœ‰å®éªŒçš„æ•°æ®
        combined_df = pd.concat(all_experiments, ignore_index=True)
        print(combined_df.head())
        print(f"\nğŸ“Š åˆå¹¶æ•°æ®: {len(combined_df)}ä¸ªæ ·æœ¬ï¼Œæ¥è‡ª{len(all_experiments)}ä¸ªå®éªŒ")
        
        return individual_results, combined_df
    
    def create_focused_correlation_heatmap(self, correlations, title_suffix=""):
        """åˆ›å»ºèšç„¦çš„ç›¸å…³æ€§çƒ­å›¾ï¼ˆåªæ˜¾ç¤ºé‡è¦æŒ‡æ ‡ï¼‰"""
        # é€‰æ‹©é‡è¦çš„ç”Ÿç†æŒ‡æ ‡ï¼ˆå‡å°‘å›¾åƒå¤§å°ï¼‰
        important_indicators = [
            'systolic_bp_mean', 'diastolic_bp_mean', 'mean_bp_mean',
            'cardiac_output_mean', 'cardiac_index_mean', 'hr_mean',
            'rsp_mean', 'systemic_vascular_resistance_mean'
        ]
        
        # å‡†å¤‡æ•°æ®
        sensor_pairs = list(correlations.keys())
        filtered_correlations = {}
        
        for sensor_pair in sensor_pairs:
            filtered_correlations[sensor_pair] = {
                col: correlations[sensor_pair][col] 
                for col in important_indicators 
                if col in correlations[sensor_pair]
            }
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        physio_cols = list(set().union(*[pair_data.keys() for pair_data in filtered_correlations.values()]))
        physio_cols = sorted(physio_cols)
        
        if len(sensor_pairs) == 0 or len(physio_cols) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®åˆ›å»ºèšç„¦çƒ­å›¾")
            return None
        
        corr_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        p_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        
        for i, sensor_pair in enumerate(sensor_pairs):
            for j, physio_col in enumerate(physio_cols):
                if physio_col in filtered_correlations[sensor_pair]:
                    corr_matrix[i, j] = filtered_correlations[sensor_pair][physio_col]['correlation']
                    p_matrix[i, j] = filtered_correlations[sensor_pair][physio_col]['p_value']
        
        # æ–°å¢ï¼šé¢„æ ¼å¼åŒ–annotå­—ç¬¦ä¸²
        annot_matrix = np.full((len(sensor_pairs), len(physio_cols)), '', dtype=object)
        for i in range(len(sensor_pairs)):
            for j in range(len(physio_cols)):
                if not np.isnan(corr_matrix[i, j]):
                    corr_str = f"{corr_matrix[i, j]:.3f}"
                    if p_matrix[i, j] < 0.05:
                        corr_str += '*'
                    annot_matrix[i, j] = corr_str
        
        # åˆ›å»ºå›¾å½¢ï¼ˆæ›´å°æ›´æ¸…æ™°ï¼‰
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ç»˜åˆ¶çƒ­å›¾
        mask = np.isnan(corr_matrix)
        im = sns.heatmap(corr_matrix, 
                        xticklabels=[self._format_physio_label_en(col) for col in physio_cols],
                        yticklabels=[self._format_sensor_pair_label_en(pair) for pair in sensor_pairs],
                        annot=annot_matrix, fmt='', cmap='RdBu_r', center=0,
                        mask=mask, square=False, linewidths=0.5,
                        cbar_kws={'label': 'Correlation Coefficient'},
                        annot_kws={'size': 10})
        
        # ç§»é™¤æ—§çš„ax.text
        
        plt.title(f'PTT-Cardiovascular Correlation Analysis (Key Parameters){title_suffix}', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.xlabel('Physiological Parameters', fontsize=12, fontweight='bold')
        plt.ylabel('PTT Sensor Combinations', fontsize=12, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        filename = f"{self.output_dir}/ptt_cardiovascular_correlation_focused{title_suffix.replace(' ', '_')}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜èšç„¦çƒ­å›¾: {filename}")
        
        return fig
    
    def save_individual_experiment_results(self, sync_data, correlations, exp_id):
        """ä¿å­˜å•ä¸ªå®éªŒçš„ç»“æœ"""
        # ä¿å­˜ç›¸å…³æ€§ç»“æœ
        corr_results = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                corr_results.append({
                    'experiment_id': exp_id,
                    'sensor_pair': sensor_pair,
                    'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                    'physiological_parameter': physio_col,
                    'parameter_label': self._format_physio_label_en(physio_col),
                    'correlation_coefficient': stats_data['correlation'],
                    'p_value': stats_data['p_value'],
                    'n_samples': stats_data['n_samples'],
                    'statistically_significant': stats_data['significant']
                })
        
        corr_df = pd.DataFrame(corr_results)
        corr_file = f"{self.output_dir}/ptt_cardiovascular_correlations_exp_{exp_id}.csv"
        corr_df.to_csv(corr_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜å®éªŒ{exp_id}ç›¸å…³æ€§: {corr_file}")
    
    def run_comprehensive_analysis(self):
        """è¿è¡Œç»¼åˆåˆ†æï¼ˆå•ä¸ª+è·¨å®éªŒå®éªŒï¼‰"""
        print("ğŸ”¬ å¼€å§‹PTTä¸ç”Ÿç†å‚æ•°ç»¼åˆåˆ†æ")
        print("ğŸ“‹ åˆ†æå®éªŒåˆ—è¡¨: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]")

        # 1. å•ä¸ªå®éªŒåˆ†æï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬ä¸€éƒ¨åˆ†ï¼šå•ä¸ªå®éªŒåˆ†æ ===")
        individual_results, combined_df = self.run_individual_experiment_analysis()
        
        # 1. æ•´ä½“åˆ†æï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬äºŒéƒ¨åˆ†ï¼šæ•´ä½“åˆ†æ ===")
        overall_results = self.run_overall_analysis(combined_df)
        
        # 3. åˆ›å»ºèšç„¦çƒ­å›¾ï¼ˆä¼˜åŒ–æ˜¾ç¤ºï¼‰
        print("\n=== ç¬¬ä¸‰éƒ¨åˆ†ï¼šåˆ›å»ºèšç„¦çƒ­å›¾ï¼ˆåªæ˜¾ç¤ºé‡è¦æŒ‡æ ‡ï¼‰===")
        if overall_results:
            self.create_focused_correlation_heatmap(overall_results['correlations'], "_overall_focus")
        
        return {
            'overall': overall_results,
            'individual': individual_results
        }
    
    def run_overall_analysis(self, combined_df):
        """è¿è¡Œæ•´ä½“åˆ†æï¼ˆåŸæœ‰åŠŸèƒ½é‡å‘½åï¼‰"""
        # è®¡ç®—æ•´ä½“ç›¸å…³æ€§
        print("\nğŸ“ˆ è®¡ç®—æ•´ä½“ç›¸å…³æ€§...")
        correlations = self.calculate_correlations(combined_df)
        
        # åˆ›å»ºç›¸å…³æ€§çƒ­å›¾
        self.create_correlation_heatmap(correlations, "_overall")
        
        # æ„å»ºå›å½’æ¨¡å‹
        print("\nğŸ¯ æ„å»ºæ•´ä½“å›å½’æ¨¡å‹...")
        models = self.build_regression_models(combined_df, correlations, exp_id=None)
        
        # ä¿å­˜ç»“æœ
        self.save_analysis_results(combined_df, correlations, models)
        
        # æ–°å¢ï¼šæ•´ä½“ç®±çº¿å›¾
        self.create_ptt_boxplot(combined_df, None)
        
        return {
            'combined_data': combined_df,
            'correlations': correlations,
            'models': models
        }
    
    def run_cross_experiments_analysis(self):
        """è·¨å®éªŒæ„å»ºå›å½’æ¨¡å‹"""
        print("\nğŸ¯ å¼€å§‹è·¨å®éªŒæ‹Ÿåˆåˆ†æ...")
        # ä¸ºæ¯ä¸ªå®éªŒå•ç‹¬å»ºæ¨¡
        all_experiments = []
        
        for exp_id in range(1, 12):
            # åˆ†æå•ä¸ªå®éªŒ
            exp_result = self.analyze_experiment_cross(exp_id)
            if exp_result:
                # ç”¨äºç»“æœåˆå¹¶
                all_experiments.append(exp_result['sync_data'])
        
        if not all_experiments:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒæ•°æ®")
            return None
        
        # åˆå¹¶æ‰€æœ‰å®éªŒçš„æ•°æ®
        combined_df = pd.concat(all_experiments, ignore_index=True)
        print(combined_df.head())
        print(f"\nğŸ“Š åˆå¹¶æ•°æ®: {len(combined_df)}ä¸ªæ ·æœ¬ï¼Œæ¥è‡ª{len(all_experiments)}ä¸ªå®éªŒ")
            
        overall_results = self.run_overall_analysis(combined_df)

        if overall_results:
            self.create_focused_correlation_heatmap(overall_results['correlations'], "_overall_focus")
        
        return {
            'overall': overall_results,
        }
    
    def run_individual_regression_analysis(self):
        """ä¸ºæ¯ä¸ªå®éªŒå•ç‹¬æ„å»ºå›å½’æ¨¡å‹å¹¶ç»˜åˆ¶æ‹Ÿåˆç›´çº¿"""
        print("\nğŸ¯ å¼€å§‹å•ç‹¬å®éªŒå›å½’åˆ†æ...")
        individual_models = {}
        model_summary = []
        
        for exp_id in range(1, 12):  # å®éªŒ1-11
            print(f"\nğŸ“Š æ„å»ºå®éªŒ{exp_id}çš„å›å½’æ¨¡å‹")
            exp_data = self.analyze_experiment(exp_id)
            
            if not exp_data or len(exp_data['sync_data']) < 20:
                print(f"âŒ å®éªŒ{exp_id}æ•°æ®ä¸è¶³ï¼ˆ<20æ ·æœ¬ï¼‰")
                continue
            
            # ç›´æ¥ä»analyze_experimentçš„ç»“æœä¸­è·å–æ¨¡å‹
            if 'models' in exp_data and exp_data['models']:
                exp_models = exp_data['models']
                individual_models[f'exp_{exp_id}'] = exp_models
                
                # æ”¶é›†æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
                for model_key, model_info in exp_models.items():
                    # ä»model_keyä¸­æå–ç”Ÿç†æŒ‡æ ‡åç§°
                    # model_keyæ ¼å¼: "sensor_pairâ†’physio_col"
                    physio_param = model_key.split('â†’')[1] if 'â†’' in model_key else model_key
                    
                    model_summary.append({
                        'experiment': exp_id,
                        'physiological_parameter': physio_param,
                        'parameter_label': self._format_physio_label_en(physio_param),
                        'r2_score': model_info['r2_score'],
                        'mae': model_info['mae'],
                        'n_samples': model_info['n_samples'],
                        'sensor_pair': model_info.get('sensor_pair', ''),
                        'sensor_label': self._format_sensor_pair_label_en(model_info.get('sensor_pair', ''))
                    })
        
        # ä¿å­˜å•ç‹¬å®éªŒçš„æ¨¡å‹è¯„ä¼°
        if model_summary:
            model_df = pd.DataFrame(model_summary)
            model_file = f"{self.output_dir}/individual_experiment_models.csv"
            model_df.to_csv(model_file, index=False)
            print(f"ğŸ’¾ ä¿å­˜å•ç‹¬å®éªŒæ¨¡å‹è¯„ä¼°: {model_file}")

            # å¯¹æ¯ä¸ªå®éªŒçš„æ¯ä¸ªç”Ÿç†å‚æ•°ï¼Œé€‰æ‹©æœ€ä½³æ¨¡å‹ï¼ˆæŒ‰RÂ²ï¼‰
            # é¦–å…ˆæŒ‰å®éªŒå’Œç”Ÿç†å‚æ•°åˆ†ç»„ï¼Œç„¶ååœ¨æ¯ä¸ªç»„å†…å–RÂ²æœ€å¤§çš„è¡Œ
            best_model_df = model_df.loc[model_df.groupby(['experiment', 'physiological_parameter'])['r2_score'].idxmax()]
            
            # åˆ›å»ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”å¯è§†åŒ–
            self.create_individual_model_comparison(best_model_df)
        
        return individual_models

    def create_individual_model_comparison(self, model_df):
        """åˆ›å»ºå•ç‹¬å®éªŒæ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾"""
        if model_df.empty:
            return
        
        # åˆ›å»ºMAEå’ŒRÂ²å¯¹æ¯”å›¾
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))
        
        # MAEå¯¹æ¯”
        pivot_mae = model_df.pivot(index='experiment', columns='parameter_label', values='mae')
        im1 = ax1.imshow(pivot_mae.values.T, cmap='Reds', aspect='auto')
        ax1.set_title('å„å®éªŒMAEå¯¹æ¯” (è¶Šä½è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax1.set_xlabel('å®éªŒç¼–å·')
        ax1.set_ylabel('ç”Ÿç†å‚æ•°')
        ax1.set_xticks(range(len(pivot_mae.index)))
        ax1.set_xticklabels(pivot_mae.index)
        ax1.set_yticks(range(len(pivot_mae.columns)))
        ax1.set_yticklabels(pivot_mae.columns, fontsize=10)
        
        # æ·»åŠ MAEæ•°å€¼æ ‡æ³¨
        for i in range(len(pivot_mae.columns)):
            for j in range(len(pivot_mae.index)):
                if not np.isnan(pivot_mae.iloc[j, i]):
                    ax1.text(j, i, f'{pivot_mae.iloc[j, i]:.1f}', 
                            ha='center', va='center', fontweight='bold')
        
        plt.colorbar(im1, ax=ax1, label='MAE')
        
        # RÂ²å¯¹æ¯”
        pivot_r2 = model_df.pivot(index='experiment', columns='parameter_label', values='r2_score')
        im2 = ax2.imshow(pivot_r2.values.T, cmap='Blues', aspect='auto')
        ax2.set_title('å„å®éªŒRÂ²å¯¹æ¯” (è¶Šé«˜è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax2.set_xlabel('å®éªŒç¼–å·')
        ax2.set_ylabel('ç”Ÿç†å‚æ•°')
        ax2.set_xticks(range(len(pivot_r2.index)))
        ax2.set_xticklabels(pivot_r2.index)
        ax2.set_yticks(range(len(pivot_r2.columns)))
        ax2.set_yticklabels(pivot_r2.columns, fontsize=10)
        
        # æ·»åŠ RÂ²æ•°å€¼æ ‡æ³¨
        for i in range(len(pivot_r2.columns)):
            for j in range(len(pivot_r2.index)):
                if not np.isnan(pivot_r2.iloc[j, i]):
                    ax2.text(j, i, f'{pivot_r2.iloc[j, i]:.2f}', 
                            ha='center', va='center', fontweight='bold')
        
        plt.colorbar(im2, ax=ax2, label='RÂ² Score')
        
        plt.tight_layout()
        comparison_file = f"{self.output_dir}/individual_model_performance_comparison.png"
        plt.savefig(comparison_file, dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾å½¢ï¼Œä¸æ˜¾ç¤º
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾: {comparison_file}")

    def save_analysis_results(self, combined_df, correlations, models):
        """ä¿å­˜åˆ†æç»“æœï¼ˆè‹±æ–‡ç‰ˆï¼‰"""
        # 1. ä¿å­˜åŒæ­¥æ•°æ®
        sync_file = f"{self.output_dir}/synchronized_ptt_cardiovascular_data.csv"
        combined_df.to_csv(sync_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜åŒæ­¥æ•°æ®: {sync_file}")
        
        # 2. ä¿å­˜ç›¸å…³æ€§ç»“æœ
        corr_results = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                corr_results.append({
                    'sensor_pair': sensor_pair,
                    'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                    'physiological_parameter': physio_col,
                    'parameter_label': self._format_physio_label_en(physio_col),
                    'correlation_coefficient': stats_data['correlation'],
                    'p_value': stats_data['p_value'],
                    'n_samples': stats_data['n_samples'],
                    'statistically_significant': stats_data['significant']
                })
        
        corr_df = pd.DataFrame(corr_results)
        corr_file = f"{self.output_dir}/ptt_cardiovascular_correlations.csv"
        corr_df.to_csv(corr_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜ç›¸å…³æ€§æ•°æ®: {corr_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ©º PTT-Cardiovascular Parameters Correlation Analysis")
    print("="*60)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = PTTBloodPressureAnalyzer()
    
    print("\nğŸ“‹ è¯·é€‰æ‹©åˆ†ææ–¹å¼:")
    print("1. ç»¼åˆåˆ†æ (å•å®éªŒ+è·¨å®éªŒ)")
    print("2. å•å®éªŒåˆ†æ")
    print("3. è·¨å®éªŒåˆ†æ")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3, é»˜è®¤1): ").strip()
        if not choice:
            choice = "1"  # é»˜è®¤ç»¼åˆåˆ†æ
    except:
        choice = "1"  # é»˜è®¤é€‰æ‹©
    
    if choice == "1":
        print("\nğŸ”¬ è¿è¡Œç»¼åˆåˆ†æ...")
        # è¿è¡Œç»¼åˆåˆ†æ
        results = analyzer.run_comprehensive_analysis()
        
        if results and results['overall']:
            overall_results = results['overall']
            
            # æ˜¾ç¤ºæœ€ä½³ç›¸å…³æ€§
            print(f"\nğŸ† Top Significant Correlations (Overall Analysis):")
            all_corrs = []
            for sensor_pair, physio_data in overall_results['correlations'].items():
                for physio_col, stats_data in physio_data.items():
                    if stats_data['significant']:
                        all_corrs.append((abs(stats_data['correlation']), 
                                        analyzer._format_sensor_pair_label_en(sensor_pair),
                                        analyzer._format_physio_label_en(physio_col),
                                        stats_data['correlation'],
                                        stats_data['p_value'],
                                        stats_data['n_samples']))
            
            all_corrs.sort(reverse=True)
            for i, (abs_corr, sensor_label, physio_label, corr, p_val, n_samples) in enumerate(all_corrs[:10]):
                direction = "â†‘" if corr > 0 else "â†“"
                print(f"   {i+1:2d}. {sensor_label} â†â†’ {physio_label}")
                print(f"       r={corr:+.3f} {direction}, p={p_val:.2e}, N={n_samples}")
    
    elif choice == "2":
        print("\nğŸ¯ è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆåˆ†æ...")
        # è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆ
        individual_models = analyzer.run_individual_regression_analysis()
        
        if individual_models:
            print(f"\nğŸ“Š å•ç‹¬å®éªŒæ‹Ÿåˆå®Œæˆ!")
            print(f"   â€¢ æˆåŠŸåˆ†æå®éªŒæ•°: {len(individual_models)}")
            print(f"   â€¢ è¯¦ç»†ç»“æœå·²ä¿å­˜: individual_experiment_models.csv")
            print(f"   â€¢ æ€§èƒ½å¯¹æ¯”å›¾: individual_model_performance_comparison.png")
    
    elif choice == "3":
         print("\nğŸ¯ è¿è¡Œè·¨å®éªŒæ‹Ÿåˆåˆ†æ...")
         # è¿è¡Œè·¨å®éªŒæ‹Ÿåˆåˆ†æ
         exp_sensor_models = analyzer.run_cross_experiments_analysis()
         
         if exp_sensor_models:
             print(f"\nâœ… è·¨å®éªŒæ‹Ÿåˆå®Œæˆ!")
             print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œç»¼åˆåˆ†æ")
        choice = "1"
        # é€’å½’è°ƒç”¨åŸå§‹åˆ†æ
        analyzer.run_comprehensive_analysis()
    
    print(f"\nâœ… åˆ†æå®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")

if __name__ == "__main__":
    main() 