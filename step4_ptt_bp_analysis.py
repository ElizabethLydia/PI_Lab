#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PTTä¸è¡€å‹ç›¸å…³æ€§åˆ†æ
åŸºäºå¸ˆå…„å»ºè®®ï¼šä½¿ç”¨åˆç†åŒºé—´çš„PTTæ•°æ®åˆ†æä¸è¡€å‹çš„ç›¸å…³æ€§
"""

import os
import pickle
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®éäº¤äº’æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºå¼¹çª—
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾ç‰‡ä¿å­˜æ¨¡å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.ioff()  # å…³é—­äº¤äº’æ¨¡å¼

class PTTBloodPressureAnalyzer:
    """PTTä¸è¡€å‹ç›¸å…³æ€§åˆ†æå™¨"""
    
    def __init__(self, output_dir="ptt_bp_analysis"):
        self.output_dir = output_dir
        self.ptt_output_dir = "ptt_output2"  # çª—å£åŒ–PTTæ•°æ®ç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # å®Œæ•´çš„ç”Ÿç†æŒ‡æ ‡æ˜ å°„ï¼ˆè‹±æ–‡ä¸“ä¸šæœ¯è¯­ï¼‰
        self.physiological_indicators = {
            'systolic_bp': 'Systolic BP (mmHg)',
            'diastolic_bp': 'Diastolic BP (mmHg)', 
            'mean_bp': 'Mean Arterial Pressure (mmHg)',
            'bp': 'Continuous BP (mmHg)',
            'cardiac_output': 'Cardiac Output (L/min)',
            'cardiac_index': 'Cardiac Index (L/min/mÂ²)',
            'hr': 'Heart Rate (bpm)',
            'systemic_vascular_resistance': 'Systemic Vascular Resistance (dynÂ·s/cmâµ)',
            'rsp': 'Respiration Rate (breaths/min)'
        }
        
        # PTTä¼ æ„Ÿå™¨ç»„åˆï¼ˆè‹±æ–‡æ ‡ç­¾ï¼‰
        self.ptt_combinations_en = {
            'sensor2-sensor3': 'Noseâ†’Finger',
            'sensor2-sensor4': 'Noseâ†’Wrist', 
            'sensor2-sensor5': 'Noseâ†’Ear',
            'sensor3-sensor4': 'Fingerâ†’Wrist',
            'sensor3-sensor5': 'Fingerâ†’Ear',
            'sensor4-sensor5': 'Wristâ†’Ear'
        }
        
        print("ğŸ”¬ Enhanced PTT-Cardiovascular Parameters Correlation Analyzer")
        print(f"ğŸ“ Results will be saved to: {self.output_dir}")
        print(f"ğŸ“Š Analyzing {len(self.physiological_indicators)} physiological indicators")
        print(f"ğŸ¯ Using {len(self.ptt_combinations_en)} PTT sensor combinations")
    
    def load_ground_truth_bp(self, exp_id):
        """åŠ è½½ç”Ÿç†æŒ‡æ ‡æ•°æ®ï¼ˆä»CSVæ–‡ä»¶ï¼‰"""
        try:
            # åŠ è½½CSVæ–‡ä»¶
            csv_file = f"output/csv_output/{exp_id}_biopac_aligned.csv"
            if not os.path.exists(csv_file):
                print(f"âŒ ç”Ÿç†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            # è¯»å–å®Œæ•´ç”Ÿç†æ•°æ®
            df = pd.read_csv(csv_file)
            print(f"âœ… åŠ è½½ç”Ÿç†æ•°æ®: {len(df)}æ¡è®°å½•")
            
            # æ˜¾ç¤ºå¯ç”¨çš„ç”Ÿç†æŒ‡æ ‡
            available_indicators = [col for col in df.columns if col in self.physiological_indicators.keys()]
            print(f"ğŸ“Š å¯ç”¨ç”Ÿç†æŒ‡æ ‡: {available_indicators}")
            
            return df
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç”Ÿç†æ•°æ®å¤±è´¥: {e}")
            return None
    
    def load_ptt_data(self, exp_id):
        """åŠ è½½æœ‰æ•ˆçª—å£çš„PTTæ•°æ®"""
        try:
            # åŠ è½½çª—å£éªŒè¯æ•°æ®
            window_file = f"{self.ptt_output_dir}/exp_{exp_id}/window_validation_exp_{exp_id}.csv"
            ptt_file = f"{self.ptt_output_dir}/exp_{exp_id}/ptt_windowed_exp_{exp_id}.csv"
            
            if not (os.path.exists(window_file) and os.path.exists(ptt_file)):
                print(f"âŒ PTTæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: exp_{exp_id}")
                return None
            
            # åŠ è½½çª—å£éªŒè¯ä¿¡æ¯
            window_df = pd.read_csv(window_file)
            # ç­›é€‰æœ‰æ•ˆçª—å£ï¼ˆæ—¶é¢‘åŸŸå¿ƒç‡è¯¯å·®åˆç†ï¼‰
            valid_windows = window_df[
                (window_df['is_valid'] == True) & 
                (window_df['hr_diff_bpm'].abs() <= 5)  # å¿ƒç‡è¯¯å·®â‰¤5BPM
            ]
            
            # åŠ è½½PTTæ•°æ®
            ptt_df = pd.read_csv(ptt_file)
            
            # åªä¿ç•™æœ‰æ•ˆçª—å£çš„PTTæ•°æ®
            valid_ptt = ptt_df[ptt_df['window_id'].isin(valid_windows['window_id'])]
            
            print(f"ğŸ“Š å®éªŒ{exp_id}: æ€»çª—å£{len(window_df)}, æœ‰æ•ˆçª—å£{len(valid_windows)}, æœ‰æ•ˆPTTæ•°æ®{len(valid_ptt)}")
            
            return {
                'window_info': valid_windows,
                'ptt_data': valid_ptt
            }
            
        except Exception as e:
            print(f"âŒ åŠ è½½PTTæ•°æ®å¤±è´¥: {e}")
            return None
    
    def synchronize_data(self, ptt_data, physio_data, exp_id):
        """æ—¶é—´åŒæ­¥PTTå’Œç”Ÿç†æ•°æ®"""
        synchronized_data = []
        
        for _, ptt_row in ptt_data['ptt_data'].iterrows():
            # PTTæ•°æ®çš„æ—¶é—´ä¿¡æ¯ï¼ˆä¿®æ­£åˆ—åï¼‰
            start_time = ptt_row['window_start_s']
            end_time = ptt_row['window_end_s']
            window_center = (start_time + end_time) / 2
            
            # è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆå‡è®¾ç”Ÿç†æ•°æ®çš„timestampæ˜¯ç»å¯¹æ—¶é—´æˆ³ï¼‰
            # éœ€è¦æ‰¾åˆ°ç”Ÿç†æ•°æ®æ—¶é—´æˆ³çš„èµ·å§‹ç‚¹
            physio_start_time = physio_data['timestamp'].iloc[0]
            start_timestamp = physio_start_time + start_time
            end_timestamp = physio_start_time + end_time
            
            # æ‰¾åˆ°æ—¶é—´çª—å£å†…çš„ç”Ÿç†æ•°æ®
            time_mask = (physio_data['timestamp'] >= start_timestamp) & (physio_data['timestamp'] <= end_timestamp)
            window_physio = physio_data[time_mask]
            
            if len(window_physio) == 0:
                continue  # è·³è¿‡æ²¡æœ‰ç”Ÿç†æ•°æ®çš„çª—å£
            
            # è®¡ç®—çª—å£å†…æ‰€æœ‰ç”Ÿç†æŒ‡æ ‡çš„ç»Ÿè®¡é‡
            physio_values = {}
            for indicator in self.physiological_indicators.keys():
                if indicator in physio_data.columns:
                    physio_values[f'{indicator}_mean'] = window_physio[indicator].mean()
                    physio_values[f'{indicator}_std'] = window_physio[indicator].std()
                    physio_values[f'{indicator}_min'] = window_physio[indicator].min()
                    physio_values[f'{indicator}_max'] = window_physio[indicator].max()
                    physio_values[f'{indicator}_count'] = len(window_physio)
            
            # æ„å»ºåŒæ­¥æ•°æ®è¡Œ
            sync_row = {
                'exp_id': exp_id,
                'window_id': ptt_row['window_id'],
                'start_time': start_time,
                'end_time': end_time,
                'window_center': window_center,
                'sensor_pair': ptt_row['sensor_pair'],
                'ptt_ms': ptt_row['ptt_ms'],
                **physio_values
            }
            
            synchronized_data.append(sync_row)
        
        sync_df = pd.DataFrame(synchronized_data)
        print(f"ğŸ“Š åŒæ­¥å®Œæˆ: {len(sync_df)}ä¸ªæœ‰æ•ˆçª—å£")
        
        return sync_df
    
    def calculate_correlations(self, sync_df):
        """è®¡ç®—PTTä¸æ‰€æœ‰ç”Ÿç†æŒ‡æ ‡çš„ç›¸å…³æ€§"""
        correlations = {}
        
        # ç”Ÿç†æŒ‡æ ‡ï¼ˆæ‰©å±•åˆ°æ‰€æœ‰å¯ç”¨æŒ‡æ ‡ï¼‰
        physio_metrics = []
        for indicator in self.physiological_indicators.keys():
            for stat in ['_mean', '_std', '_min', '_max']:
                col_name = f'{indicator}{stat}'
                if col_name in sync_df.columns:
                    physio_metrics.append(col_name)
        
        # è·å–æ‰€æœ‰ä¼ æ„Ÿå™¨å¯¹
        sensor_pairs = sync_df['sensor_pair'].unique()
        
        print(f"\nğŸ“Š è®¡ç®—ç›¸å…³æ€§ï¼š{len(sensor_pairs)}ä¸ªä¼ æ„Ÿå™¨å¯¹ Ã— {len(physio_metrics)}ä¸ªç”Ÿç†æŒ‡æ ‡")
        
        for sensor_pair in sensor_pairs:
            correlations[sensor_pair] = {}
            
            # æå–è¯¥ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
            pair_data = sync_df[sync_df['sensor_pair'] == sensor_pair]
            
            if len(pair_data) < 10:  # è‡³å°‘10ä¸ªæ•°æ®ç‚¹
                continue
            
            for physio_col in physio_metrics:
                # æå–æœ‰æ•ˆæ•°æ®
                mask = ~(pair_data['ptt_ms'].isna() | pair_data[physio_col].isna())
                if mask.sum() < 10:
                    continue
                
                ptt_vals = pair_data.loc[mask, 'ptt_ms']
                physio_vals = pair_data.loc[mask, physio_col]
                
                # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
                try:
                    corr_coef, p_value = stats.pearsonr(ptt_vals, physio_vals)
                    
                    correlations[sensor_pair][physio_col] = {
                        'correlation': corr_coef,
                        'p_value': p_value,
                        'n_samples': len(ptt_vals),
                        'significant': p_value < 0.05
                    }
                except Exception as e:
                    print(f"âš ï¸ è®¡ç®—ç›¸å…³æ€§å¤±è´¥ {sensor_pair}-{physio_col}: {e}")
                    continue
        
        return correlations
    
    def create_correlation_heatmap(self, correlations, title_suffix=""):
        """åˆ›å»ºç›¸å…³æ€§çƒ­å›¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        # å‡†å¤‡æ•°æ®
        sensor_pairs = list(correlations.keys())
        physio_cols = set()
        for pair_data in correlations.values():
            physio_cols.update(pair_data.keys())
        physio_cols = sorted(list(physio_cols))
        
        if len(sensor_pairs) == 0 or len(physio_cols) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„ç›¸å…³æ€§æ•°æ®æ¥åˆ›å»ºçƒ­å›¾")
            return None
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        p_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        
        for i, sensor_pair in enumerate(sensor_pairs):
            for j, physio_col in enumerate(physio_cols):
                if physio_col in correlations[sensor_pair]:
                    corr_matrix[i, j] = correlations[sensor_pair][physio_col]['correlation']
                    p_matrix[i, j] = correlations[sensor_pair][physio_col]['p_value']
        
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(16, 10))
        
        # ç»˜åˆ¶çƒ­å›¾
        mask = np.isnan(corr_matrix)
        im = sns.heatmap(corr_matrix, 
                        xticklabels=[self._format_physio_label_en(col) for col in physio_cols],
                        yticklabels=[self._format_sensor_pair_label_en(pair) for pair in sensor_pairs],
                        annot=True, fmt='.3f', cmap='RdBu_r', center=0,
                        mask=mask, square=False, linewidths=0.5,
                        cbar_kws={'label': 'Correlation Coefficient'},
                        annot_kws={'size': 8})
        
        # æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
        for i in range(len(sensor_pairs)):
            for j in range(len(physio_cols)):
                if not np.isnan(p_matrix[i, j]) and p_matrix[i, j] < 0.05:
                    ax.text(j + 0.5, i + 0.5, '*', ha='center', va='center', 
                           color='white', fontsize=8, fontweight='bold')
        
        plt.title(f'PTT-Cardiovascular Parameters Correlation Analysis{title_suffix}', 
                 fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('Physiological Parameters', fontsize=12, fontweight='bold')
        plt.ylabel('PTT Sensor Combinations', fontsize=12, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        filename = f"{self.output_dir}/ptt_cardiovascular_correlation_heatmap{title_suffix.replace(' ', '_')}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜ç›¸å…³æ€§çƒ­å›¾: {filename}")
        
        return fig
    
    def _format_ptt_label(self, ptt_col):
        """æ ¼å¼åŒ–PTTæ ‡ç­¾"""
        # ptt_sensor2-sensor3_ms -> noseâ†’finger
        sensor_map = {'sensor2': 'nose', 'sensor3': 'finger', 'sensor4': 'wrist', 'sensor5': 'ear'}
        parts = ptt_col.replace('ptt_', '').replace('_ms', '').split('-')
        if len(parts) == 2:
            return f"{sensor_map.get(parts[0], parts[0])}â†’{sensor_map.get(parts[1], parts[1])}"
        return ptt_col
    
    def _format_bp_label(self, bp_col):
        """æ ¼å¼åŒ–è¡€å‹æ ‡ç­¾"""
        label_map = {
            'systolic_bp': 'æ”¶ç¼©å‹',
            'diastolic_bp': 'èˆ’å¼ å‹',
            'mean_bp': 'å¹³å‡åŠ¨è„‰å‹',
            'bp': 'è¿ç»­è¡€å‹'
        }
        
        for bp_type, label in label_map.items():
            if bp_col.startswith(bp_type):
                suffix = bp_col.replace(bp_type, '').replace('_', ' ')
                return f"{label}{suffix}"
        return bp_col
    
    def _format_sensor_pair_label(self, sensor_pair):
        """æ ¼å¼åŒ–ä¼ æ„Ÿå™¨å¯¹æ ‡ç­¾"""
        # sensor2-sensor3 -> noseâ†’finger
        sensor_map = {'sensor2': 'nose', 'sensor3': 'finger', 'sensor4': 'wrist', 'sensor5': 'ear'}
        if '-' in sensor_pair:
            parts = sensor_pair.split('-')
            if len(parts) == 2:
                return f"{sensor_map.get(parts[0], parts[0])}â†’{sensor_map.get(parts[1], parts[1])}"
        return sensor_pair
    
    def _format_physio_label_en(self, physio_col):
        """æ ¼å¼åŒ–ç”Ÿç†æŒ‡æ ‡æ ‡ç­¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        # æå–åŸºç¡€æŒ‡æ ‡åç§°å’Œç»Ÿè®¡é‡
        for indicator, label in self.physiological_indicators.items():
            if physio_col.startswith(indicator):
                stat_part = physio_col.replace(indicator, '').replace('_', ' ')
                if stat_part == ' mean':
                    return label
                elif stat_part == ' std':
                    return f"{label} (SD)"
                elif stat_part == ' min':
                    return f"{label} (Min)"
                elif stat_part == ' max':
                    return f"{label} (Max)"
                else:
                    return f"{label}{stat_part}"
        return physio_col
    
    def _format_sensor_pair_label_en(self, sensor_pair):
        """æ ¼å¼åŒ–ä¼ æ„Ÿå™¨å¯¹æ ‡ç­¾ï¼ˆè‹±æ–‡ç‰ˆï¼‰"""
        return self.ptt_combinations_en.get(sensor_pair, sensor_pair)
    
    def build_regression_models(self, sync_df, exp_id=None):
        """æ„å»ºPTTâ†’ç”Ÿç†æŒ‡æ ‡çš„å›å½’æ¨¡å‹ï¼Œå¹¶è¿”å›æ¨¡å‹å’Œæ•°æ®"""
        from sklearn.linear_model import LinearRegression
        from sklearn.preprocessing import StandardScaler
        from sklearn.metrics import r2_score, mean_absolute_error
        from sklearn.impute import SimpleImputer
        import pandas as pd
        import numpy as np
        import matplotlib.pyplot as plt
        import os
        
        models = {}
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ä¸»è¦ç”Ÿç†æŒ‡æ ‡ï¼ˆå‡å€¼ï¼‰
        main_physio_cols = []
        for indicator in ['systolic_bp', 'diastolic_bp', 'mean_bp', 'cardiac_output', 'cardiac_index']:
            col_name = f'{indicator}_mean'
            if col_name in sync_df.columns:
                main_physio_cols.append(col_name)
        
        # è·å–æ‰€æœ‰ä¼ æ„Ÿå™¨å¯¹
        sensor_pairs = sync_df['sensor_pair'].unique()
        print(f"ğŸ” å‘ç°ä¼ æ„Ÿå™¨å¯¹: {sensor_pairs}")
        
        # åˆ›å»ºç»“æœæ•°æ®ç»“æ„
        all_models = {}
        all_model_data = {}
        metrics_list = []  # ç”¨äºå­˜å‚¨ CSV çš„æŒ‡æ ‡æ•°æ®
        
        # ä¸ºæ¯ä¸ªä¼ æ„Ÿå™¨å¯¹å•ç‹¬å¤„ç†
        for sensor_pair in sensor_pairs:
            print(f"\nğŸ”§ å¤„ç†ä¼ æ„Ÿå™¨å¯¹: {sensor_pair}")
            
            # è¿‡æ»¤å½“å‰ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
            pair_df = sync_df[sync_df['sensor_pair'] == sensor_pair].copy()
            
            # åˆ›å»ºæ•°æ®é€è§†è¡¨ - æ¯ä¸ªçª—å£ä¸€ä¸ªPTTå€¼
            ptt_pivot = pair_df.pivot_table(
                index=['exp_id', 'window_id'], 
                values='ptt_ms',
                aggfunc='mean'
            ).reset_index().rename(columns={'ptt_ms': f'ptt_{sensor_pair}'})
            
            # åˆå¹¶ç”Ÿç†æ•°æ®ï¼ˆå–å¹³å‡å€¼ï¼‰
            physio_agg = pair_df.groupby(['exp_id', 'window_id']).agg({
                col: 'mean' for col in main_physio_cols if col in pair_df.columns
            }).reset_index()
            
            # åˆå¹¶PTTå’Œç”Ÿç†æ•°æ®
            model_data = pd.merge(ptt_pivot, physio_agg, on=['exp_id', 'window_id'], how='inner')
            
            # æ£€æŸ¥æ•°æ®é‡
            if len(model_data) < 10:
                print(f"âš ï¸ æ•°æ®ä¸è¶³: {sensor_pair} åªæœ‰{len(model_data)}ä¸ªæ ·æœ¬")
                continue
                
            # è·å–PTTç‰¹å¾åˆ—
            ptt_col = f'ptt_{sensor_pair}'
            
            # æ£€æŸ¥PTTåˆ—çš„NaNæ¯”ä¾‹
            nan_ratio = model_data[ptt_col].isna().mean()
            print(f"ğŸ“Š PTTåˆ— {ptt_col} NaNæ¯”ä¾‹: {nan_ratio:.2%}")
            
            # ä¸ºæ¯ä¸ªç”Ÿç†æŒ‡æ ‡å•ç‹¬å»ºæ¨¡
            for physio_col in main_physio_cols:
                if physio_col not in model_data.columns:
                    continue
                    
                # å‡†å¤‡æ•°æ® - ç§»é™¤NaN
                mask = ~model_data[physio_col].isna() & ~model_data[ptt_col].isna()
                
                if mask.sum() < 5:  # è‡³å°‘5ä¸ªæ ·æœ¬
                    print(f"âš ï¸ æ•°æ®ä¸è¶³: {sensor_pair}â†’{physio_col} æœ‰æ•ˆæ ·æœ¬={mask.sum()}")
                    continue
                
                X = model_data.loc[mask, ptt_col].values.reshape(-1, 1)
                y = model_data.loc[mask, physio_col].values
                
                # æ•°æ®æ ‡å‡†åŒ–
                scaler_X = StandardScaler()
                scaler_y = StandardScaler()
                X_scaled = scaler_X.fit_transform(X)
                y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
                
                # è®­ç»ƒæ¨¡å‹
                model = LinearRegression()
                model.fit(X_scaled, y_scaled)
                
                # é¢„æµ‹
                y_pred_scaled = model.predict(X_scaled)
                y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
                
                # è¯„ä¼°
                r2 = r2_score(y, y_pred)
                mae = mean_absolute_error(y, y_pred)
                
                # å­˜å‚¨æ¨¡å‹
                model_key = f"{sensor_pair}â†’{physio_col}"
                all_models[model_key] = {
                    'model': model,
                    'scaler_X': scaler_X,
                    'scaler_y': scaler_y,
                    'feature_names': [ptt_col],
                    'r2_score': r2,
                    'mae': mae,
                    'n_samples': len(y),
                    'y_true': y,
                    'y_pred': y_pred,
                    'sensor_pair': sensor_pair,
                    'physio_col': physio_col
                }
                
                print(f"ğŸ“ˆ {model_key}æ¨¡å‹: RÂ²={r2:.3f}, MAE={mae:.2f}, N={len(y)}")
                
                # åˆ›å»ºå›¾è¡¨
                plt.figure(figsize=(10, 6))
                
                # 1. ç»˜åˆ¶åŸå§‹æ•°æ®ç‚¹
                plt.scatter(X, y, alpha=0.6, color='blue', label='åŸå§‹æ•°æ®')
                
                # 2. ç»˜åˆ¶æ‹Ÿåˆç›´çº¿
                x_min, x_max = np.min(X), np.max(X)
                x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)
                
                x_range_scaled = scaler_X.transform(x_range)
                y_range_scaled = model.predict(x_range_scaled)
                y_range = scaler_y.inverse_transform(y_range_scaled.reshape(-1, 1)).flatten()
                
                plt.plot(x_range, y_range, 'r-', linewidth=2, label='æ‹Ÿåˆç›´çº¿')
                
                # 3. æ·»åŠ å›¾ä¾‹å’Œæ ‡ç­¾
                plt.xlabel(f'PTT ({sensor_pair}) (ms)')
                plt.ylabel(f'{physio_col}')
                
                # è·å–æ–¹ç¨‹ç³»æ•°
                coef = model.coef_[0]
                intercept = model.intercept_
                
                # è®¡ç®—åŸå§‹æ•°æ®ç©ºé—´çš„æ–œç‡å’Œæˆªè·ï¼Œç¡®ä¿ä½¿ç”¨æ ‡é‡å€¼
                coef_original = coef * (scaler_y.scale_[0] / scaler_X.scale_[0])
                intercept_original = scaler_y.mean_[0] - coef * (scaler_X.mean_[0] * scaler_y.scale_[0] / scaler_X.scale_[0]) + intercept * scaler_y.scale_[0]
                
                print(f"ğŸ” {model_key} æ–¹ç¨‹ï¼ˆåŸå§‹ç©ºé—´ï¼‰: y = {coef_original:.3f}Â·x + {intercept_original:.3f}")
                
                plt.title(f'{physio_col} vs PTT ({sensor_pair})\n'
                        f'æ–¹ç¨‹: y = {coef_original:.3f}Â·x + {intercept_original:.3f}\n'
                        f'RÂ²={r2:.3f}, MAE={mae:.2f}, n={len(y)}')
                
                plt.legend()
                plt.grid(alpha=0.3)
                
                # ä¿å­˜å›¾è¡¨
                safe_physio = physio_col.replace(' ', '_').replace('/', '_')
                safe_pair = sensor_pair.replace(' ', '_').replace('/', '_')
                if exp_id is not None:
                    plot_path = os.path.join(self.output_dir, f"exp{exp_id}_{safe_physio}_vs_{safe_pair}_fit.png")
                else:
                    plot_path = os.path.join(self.output_dir, f"{safe_physio}_vs_{safe_pair}_fit.png")
                plt.savefig(plot_path, bbox_inches='tight', dpi=150)
                plt.close()
                
                print(f"ğŸ’¾ ä¿å­˜ç‰¹å¾æ‹Ÿåˆå›¾: {plot_path}")
                
                # å­˜å‚¨æ¨¡å‹æ•°æ®
                all_model_data[model_key] = model_data.loc[mask, [ptt_col, physio_col]]
                
                # æ”¶é›†æŒ‡æ ‡æ•°æ®ç”¨äº CSV
                if exp_id is not None:
                    metrics_list.append({
                        'exp_id': exp_id,
                        'sensor_pair': sensor_pair,
                        'physio_col': physio_col,
                        'r2_score': r2,
                        'mae': mae,
                        'n_samples': len(y),
                        'slope': coef_original,
                        'intercept': intercept_original
                    })
        
        # å¦‚æœæœ‰ exp_idï¼Œä¿å­˜æŒ‡æ ‡åˆ° CSV
        if exp_id is not None and metrics_list:
            csv_path = os.path.join(self.output_dir, "all_experiments_regression_metrics.csv")
            metrics_df = pd.DataFrame(metrics_list)
            # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®ï¼›å¦åˆ™åˆ›å»ºæ–°æ–‡ä»¶
            if os.path.exists(csv_path):
                existing_df = pd.read_csv(csv_path)
                combined_df = pd.concat([existing_df, metrics_df], ignore_index=True)
                combined_df.to_csv(csv_path, index=False)
            else:
                metrics_df.to_csv(csv_path, index=False)
            print(f"ğŸ’¾ è¿½åŠ å›å½’æŒ‡æ ‡åˆ° CSV: {csv_path}")
        
        return all_models, all_model_data


    def create_regression_plots(self, models):
        """åˆ›å»ºå›å½’åˆ†æå›¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        print('å¼€å§‹åˆ›å»ºå›å½’åˆ†æå›¾')
        try:
            n_models = len(models)
            if n_models == 0:
                return
            
            fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))
            if n_models == 1:
                axes = [axes]
            
            for idx, (physio_col, model_data) in enumerate(models.items()):
                ax = axes[idx]
                
                y_true = model_data['y_true']
                y_pred = model_data['y_pred']
                r2 = model_data['r2_score']
                mae = model_data['mae']
                
                # æ•£ç‚¹å›¾
                ax.scatter(y_true, y_pred, alpha=0.6, s=50, color='steelblue')
                
                # ç†æƒ³çº¿
                min_val = min(y_true.min(), y_pred.min())
                max_val = max(y_true.max(), y_pred.max())
                ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')
                
                # æ ¼å¼åŒ–
                physio_label = self._format_physio_label_en(physio_col)
                ax.set_xlabel(f'Actual {physio_label}', fontweight='bold')
                ax.set_ylabel(f'Predicted {physio_label}', fontweight='bold')
                ax.set_title(f'{physio_label}\nRÂ²={r2:.3f}, MAE={mae:.2f}', fontweight='bold')
                ax.grid(True, alpha=0.3)
                ax.legend()
            
            plt.suptitle('PTT-Based Physiological Parameter Prediction Models', 
                        fontsize=16, fontweight='bold', y=1.02)
            plt.tight_layout()
            
            # ä¿å­˜å›¾åƒ
            filename = f"{self.output_dir}/ptt_cardiovascular_regression_analysis.png"
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ ä¿å­˜å›å½’åˆ†æå›¾: {filename}")
            
            return fig
        except Exception as e:
            print(f"åˆ›å»ºå›å½’å›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()  # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆä¿¡æ¯
            return None
    
    def analyze_experiment(self, exp_id):
        """åˆ†æå•ä¸ªå®éªŒ"""
        print(f"\nğŸ” åˆ†æå®éªŒ {exp_id}")
        
        # 1. åŠ è½½æ•°æ®
        physio_data = self.load_ground_truth_bp(exp_id)
        ptt_data = self.load_ptt_data(exp_id)
        
        if physio_data is None or ptt_data is None:
            print(f"âŒ å®éªŒ {exp_id} æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        # 2. æ—¶é—´åŒæ­¥
        sync_df = self.synchronize_data(ptt_data, physio_data, exp_id)
        print(f"ğŸ“Š åŒæ­¥æ•°æ®: {len(sync_df)}ä¸ªæ—¶é—´çª—å£")
        
        # 3. ç›¸å…³æ€§åˆ†æ
        correlations = self.calculate_correlations(sync_df)
        
        # 4. å›å½’å»ºæ¨¡
        models, model_data = self.build_regression_models(sync_df, exp_id=exp_id)
        
        return {
            'sync_data': sync_df,
            'correlations': correlations,
            'models': models
        }
    
    def run_individual_experiment_analysis(self):
        """è¿è¡Œå•ä¸ªå®éªŒçš„åˆ†æ"""
        print("ğŸ”¬ å¼€å§‹å•ä¸ªå®éªŒåˆ†æ...")
        
        individual_results = {}
        
        # è·å–å®éªŒåˆ—è¡¨
        exp_list = [1, 2, 7, 9, 10]  # åªåˆ†ææœ‰PTTæ•°æ®çš„å®éªŒ
        
        for exp_id in exp_list:
            print(f"\nğŸ” å•ç‹¬åˆ†æå®éªŒ {exp_id}")
            
            # åˆ†æå•ä¸ªå®éªŒ
            exp_result = self.analyze_experiment(exp_id)
            if exp_result:
                individual_results[exp_id] = exp_result['sync_data']
                
                # è®¡ç®—ç›¸å…³æ€§
                correlations = self.calculate_correlations(exp_result['sync_data'])
                
                # åˆ›å»ºå•ä¸ªå®éªŒçš„çƒ­å›¾
                self.create_focused_correlation_heatmap(correlations, f"_å®éªŒ{exp_id}")
                
                # ä¿å­˜å•ä¸ªå®éªŒç»“æœ
                self.save_individual_experiment_results(exp_result['sync_data'], correlations, exp_id)
        
        return individual_results
    
    def create_focused_correlation_heatmap(self, correlations, title_suffix=""):
        """åˆ›å»ºèšç„¦çš„ç›¸å…³æ€§çƒ­å›¾ï¼ˆåªæ˜¾ç¤ºé‡è¦æŒ‡æ ‡ï¼‰"""
        # é€‰æ‹©é‡è¦çš„ç”Ÿç†æŒ‡æ ‡ï¼ˆå‡å°‘å›¾åƒå¤§å°ï¼‰
        important_indicators = [
            'systolic_bp_mean', 'diastolic_bp_mean', 'mean_bp_mean',
            'cardiac_output_mean', 'cardiac_index_mean', 'hr_mean',
            'rsp_mean', 'systemic_vascular_resistance_mean'
        ]
        
        # å‡†å¤‡æ•°æ®
        sensor_pairs = list(correlations.keys())
        filtered_correlations = {}
        
        for sensor_pair in sensor_pairs:
            filtered_correlations[sensor_pair] = {
                col: correlations[sensor_pair][col] 
                for col in important_indicators 
                if col in correlations[sensor_pair]
            }
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        physio_cols = list(set().union(*[pair_data.keys() for pair_data in filtered_correlations.values()]))
        physio_cols = sorted(physio_cols)
        
        if len(sensor_pairs) == 0 or len(physio_cols) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®åˆ›å»ºèšç„¦çƒ­å›¾")
            return None
        
        corr_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        p_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        
        for i, sensor_pair in enumerate(sensor_pairs):
            for j, physio_col in enumerate(physio_cols):
                if physio_col in filtered_correlations[sensor_pair]:
                    corr_matrix[i, j] = filtered_correlations[sensor_pair][physio_col]['correlation']
                    p_matrix[i, j] = filtered_correlations[sensor_pair][physio_col]['p_value']
        
        # åˆ›å»ºå›¾å½¢ï¼ˆæ›´å°æ›´æ¸…æ™°ï¼‰
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ç»˜åˆ¶çƒ­å›¾
        mask = np.isnan(corr_matrix)
        im = sns.heatmap(corr_matrix, 
                        xticklabels=[self._format_physio_label_en(col) for col in physio_cols],
                        yticklabels=[self._format_sensor_pair_label_en(pair) for pair in sensor_pairs],
                        annot=True, fmt='.3f', cmap='RdBu_r', center=0,
                        mask=mask, square=False, linewidths=0.5,
                        cbar_kws={'label': 'Correlation Coefficient'},
                        annot_kws={'size': 10})
        
        # æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
        for i in range(len(sensor_pairs)):
            for j in range(len(physio_cols)):
                if not np.isnan(p_matrix[i, j]) and p_matrix[i, j] < 0.05:
                    ax.text(j + 0.5, i + 0.5, '*', ha='center', va='center', 
                           color='white', fontsize=14, fontweight='bold')
        
        plt.title(f'PTT-Cardiovascular Correlation Analysis (Key Parameters){title_suffix}', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.xlabel('Physiological Parameters', fontsize=12, fontweight='bold')
        plt.ylabel('PTT Sensor Combinations', fontsize=12, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        filename = f"{self.output_dir}/ptt_cardiovascular_correlation_focused{title_suffix.replace(' ', '_')}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜èšç„¦çƒ­å›¾: {filename}")
        
        return fig
    
    def save_individual_experiment_results(self, sync_data, correlations, exp_id):
        """ä¿å­˜å•ä¸ªå®éªŒçš„ç»“æœ"""
        # ä¿å­˜ç›¸å…³æ€§ç»“æœ
        corr_results = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                corr_results.append({
                    'experiment_id': exp_id,
                    'sensor_pair': sensor_pair,
                    'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                    'physiological_parameter': physio_col,
                    'parameter_label': self._format_physio_label_en(physio_col),
                    'correlation_coefficient': stats_data['correlation'],
                    'p_value': stats_data['p_value'],
                    'n_samples': stats_data['n_samples'],
                    'statistically_significant': stats_data['significant']
                })
        
        corr_df = pd.DataFrame(corr_results)
        corr_file = f"{self.output_dir}/ptt_cardiovascular_correlations_exp_{exp_id}.csv"
        corr_df.to_csv(corr_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜å®éªŒ{exp_id}ç›¸å…³æ€§: {corr_file}")
    
    def compare_experiments(self, individual_results):
        """æ¯”è¾ƒä¸åŒå®éªŒçš„ç»“æœ"""
        print("\nğŸ“Š å®éªŒé—´å¯¹æ¯”åˆ†æ...")
        
        # æ”¶é›†æ‰€æœ‰å®éªŒçš„ç›¸å…³æ€§æ•°æ®
        all_exp_correlations = []
        
        for exp_id, exp_data in individual_results.items():
            correlations = self.calculate_correlations(exp_data)
            
            for sensor_pair, physio_data in correlations.items():
                for physio_col, stats_data in physio_data.items():
                    if stats_data['significant']:
                        all_exp_correlations.append({
                            'experiment': exp_id,
                            'sensor_pair': sensor_pair,
                            'parameter': physio_col,
                            'correlation': stats_data['correlation'],
                            'n_samples': stats_data['n_samples']
                        })
        
        # è½¬æ¢ä¸ºDataFrame
        comp_df = pd.DataFrame(all_exp_correlations)
        
        if len(comp_df) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œå®éªŒé—´æ¯”è¾ƒ")
            return
        
        # ä¿å­˜æ¯”è¾ƒç»“æœ
        comp_file = f"{self.output_dir}/experiment_comparison.csv"
        comp_df.to_csv(comp_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜å®éªŒæ¯”è¾ƒ: {comp_file}")
        
        # æ‰“å°æ€»ç»“
        print(f"\nğŸ“‹ å®éªŒé—´æ¯”è¾ƒæ€»ç»“:")
        for exp_id in sorted(individual_results.keys()):
            exp_corr = comp_df[comp_df['experiment'] == exp_id]
            print(f"   å®éªŒ{exp_id}: {len(exp_corr)}ä¸ªæ˜¾è‘—ç›¸å…³æ€§")
            
            if len(exp_corr) > 0:
                strongest = exp_corr.loc[exp_corr['correlation'].abs().idxmax()]
                print(f"     æœ€å¼º: {strongest['sensor_pair']}-{strongest['parameter']} (r={strongest['correlation']:.3f})")
    
    def run_comprehensive_analysis(self):
        """è¿è¡Œç»¼åˆåˆ†æï¼ˆæ•´ä½“+å•ä¸ªå®éªŒï¼‰"""
        print("ğŸ”¬ å¼€å§‹PTTä¸ç”Ÿç†å‚æ•°ç»¼åˆåˆ†æ")
        print("ğŸ“‹ åˆ†æå®éªŒåˆ—è¡¨: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]")
        
        # 1. æ•´ä½“åˆ†æï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•´ä½“åˆ†æ ===")
        overall_results = self.run_overall_analysis()
        
        # 2. å•ä¸ªå®éªŒåˆ†æï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬äºŒéƒ¨åˆ†ï¼šå•ä¸ªå®éªŒåˆ†æ ===")
        individual_results = self.run_individual_experiment_analysis()
        
        # 3. å®éªŒé—´æ¯”è¾ƒï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®éªŒé—´æ¯”è¾ƒ ===")
        if individual_results:
            self.compare_experiments(individual_results)
        
        # 4. åˆ›å»ºèšç„¦çƒ­å›¾ï¼ˆä¼˜åŒ–æ˜¾ç¤ºï¼‰
        print("\n=== ç¬¬å››éƒ¨åˆ†ï¼šåˆ›å»ºèšç„¦çƒ­å›¾ ===")
        if overall_results:
            self.create_focused_correlation_heatmap(overall_results['correlations'], "_æ•´ä½“åˆ†æ_èšç„¦")
        
        return {
            'overall': overall_results,
            'individual': individual_results
        }
    
    def run_overall_analysis(self):
        """è¿è¡Œæ•´ä½“åˆ†æï¼ˆåŸæœ‰åŠŸèƒ½é‡å‘½åï¼‰"""
        # åŸæœ‰çš„ run_comprehensive_analysis å†…å®¹
        all_experiments = []
        
        # åˆ†ææ‰€æœ‰å®éªŒ
        for exp_id in range(1, 12):  # å®éªŒ1-11
            print(f"\nğŸ” åˆ†æå®éªŒ {exp_id}")
            exp_data = self.analyze_experiment(exp_id)
            
            if exp_data:
                # æå–sync_dataï¼ˆDataFrameï¼‰
                all_experiments.append(exp_data['sync_data'])
        
        if not all_experiments:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒæ•°æ®")
            return None
        
        # åˆå¹¶æ‰€æœ‰å®éªŒçš„æ•°æ®ï¼ˆä¿®æ­£ï¼šæå–DataFrameï¼‰
        combined_df = pd.concat(all_experiments, ignore_index=True)
        print(combined_df.head())
        print(f"\nğŸ“Š åˆå¹¶æ•°æ®: {len(combined_df)}ä¸ªæ ·æœ¬ï¼Œæ¥è‡ª{len(all_experiments)}ä¸ªå®éªŒ")
        
        # è®¡ç®—æ•´ä½“ç›¸å…³æ€§
        print("\nğŸ“ˆ è®¡ç®—æ•´ä½“ç›¸å…³æ€§...")
        correlations = self.calculate_correlations(combined_df)
        
        # åˆ›å»ºç›¸å…³æ€§çƒ­å›¾
        self.create_correlation_heatmap(correlations, " (æ•´ä½“åˆ†æ)")
        
        # æ„å»ºå›å½’æ¨¡å‹
        print("\nğŸ¯ æ„å»ºæ•´ä½“å›å½’æ¨¡å‹...")
        models = self.build_regression_models(combined_df, exp_id=None)
        
        # åˆ›å»ºå›å½’å›¾
        if models is not None:
            self.create_regression_plots(models)
        
        # ä¿å­˜ç»“æœ
        self.save_analysis_results(combined_df, correlations, models)
        
        return {
            'combined_data': combined_df,
            'correlations': correlations,
            'models': models
        }
    
    def run_individual_experiment_sensor_regression_analysis(self):
        """ä¸ºæ¯ä¸ªå®éªŒçš„æ¯ä¸ªä¼ æ„Ÿå™¨å¯¹å•ç‹¬æ„å»ºå›å½’æ¨¡å‹"""
        print("\nğŸ¯ å¼€å§‹æŒ‰å®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹å•ç‹¬æ‹Ÿåˆåˆ†æ...")
        print("ğŸ“‹ æ‹Ÿåˆç­–ç•¥: æ¯ä¸ªå®éªŒçš„æ¯ä¸ªä¼ æ„Ÿå™¨å¯¹å¯¹æ¯ä¸ªç”Ÿç†æŒ‡æ ‡å»ºç«‹ç‹¬ç«‹æ¨¡å‹")
        
        all_models = {}
        model_summary = []
        
        # ç”Ÿç†æŒ‡æ ‡åˆ—è¡¨
        main_physio_cols = []
        for indicator in ['systolic_bp', 'diastolic_bp', 'mean_bp', 'cardiac_output', 'cardiac_index']:
            col_name = f'{indicator}_mean'
            main_physio_cols.append(col_name)
        
        # ä¸ºæ¯ä¸ªå®éªŒå•ç‹¬å»ºæ¨¡
        for exp_id in range(1, 12):  # å®éªŒ1-11
            print(f"\nğŸ” åˆ†æå®éªŒ {exp_id}")
            exp_data = self.analyze_experiment(exp_id)
            
            if not exp_data or len(exp_data['sync_data']) < 10:
                print(f"âŒ å®éªŒ{exp_id}æ•°æ®ä¸è¶³")
                continue
            
            sync_df = exp_data['sync_data']
            all_models[f'exp_{exp_id}'] = {}
            
            # è·å–è¯¥å®éªŒçš„ä¼ æ„Ÿå™¨å¯¹
            sensor_pairs = sync_df['sensor_pair'].unique()
            print(f"   ğŸ“¡ ä¼ æ„Ÿå™¨å¯¹: {list(sensor_pairs)}")
            
            # ä¸ºæ¯ä¸ªä¼ æ„Ÿå™¨å¯¹å»ºæ¨¡
            for sensor_pair in sensor_pairs:
                print(f"   ğŸ”§ ä¼ æ„Ÿå™¨å¯¹: {sensor_pair} ({self._format_sensor_pair_label_en(sensor_pair)})")
                
                # ç­›é€‰è¯¥ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
                sensor_data = sync_df[sync_df['sensor_pair'] == sensor_pair].copy()
                
                if len(sensor_data) < 5:
                    print(f"      âš ï¸ æ•°æ®ä¸è¶³: {len(sensor_data)}ä¸ªæ ·æœ¬")
                    continue
                
                all_models[f'exp_{exp_id}'][sensor_pair] = {}
                
                # ä¸ºæ¯ä¸ªç”Ÿç†æŒ‡æ ‡å»ºæ¨¡
                for physio_col in main_physio_cols:
                    if physio_col not in sensor_data.columns:
                        continue
                    
                    # å‡†å¤‡æ•°æ®ï¼ˆå»é™¤NaNï¼‰
                    mask = (~sensor_data[physio_col].isna()) & (~sensor_data['ptt_ms'].isna())
                    valid_data = sensor_data[mask]
                    
                    if len(valid_data) < 5:
                        print(f"      âš ï¸ {physio_col}: æœ‰æ•ˆæ ·æœ¬ä¸è¶³({len(valid_data)}<5)")
                        continue
                    
                    # å•å˜é‡çº¿æ€§å›å½’: PTT â†’ ç”Ÿç†æŒ‡æ ‡
                    X = valid_data[['ptt_ms']].values
                    y = valid_data[physio_col].values
                    
                    # æ•°æ®æ ‡å‡†åŒ–
                    scaler_X = StandardScaler()
                    scaler_y = StandardScaler()
                    X_scaled = scaler_X.fit_transform(X)
                    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
                    
                    # è®­ç»ƒæ¨¡å‹
                    model = LinearRegression()
                    model.fit(X_scaled, y_scaled)
                    
                    # é¢„æµ‹
                    y_pred_scaled = model.predict(X_scaled)
                    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
                    
                    # è¯„ä¼°
                    r2 = r2_score(y, y_pred)
                    mae = mean_absolute_error(y, y_pred)
                    
                    # ä¿å­˜æ¨¡å‹
                    all_models[f'exp_{exp_id}'][sensor_pair][physio_col] = {
                        'model': model,
                        'scaler_X': scaler_X,
                        'scaler_y': scaler_y,
                        'r2_score': r2,
                        'mae': mae,
                        'n_samples': len(y),
                        'y_true': y,
                        'y_pred': y_pred
                    }
                    
                    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                    model_summary.append({
                        'experiment': exp_id,
                        'sensor_pair': sensor_pair,
                        'sensor_label': self._format_sensor_pair_label_en(sensor_pair),
                        'physiological_parameter': physio_col,
                        'parameter_label': self._format_physio_label_en(physio_col),
                        'r2_score': r2,
                        'mae': mae,
                        'n_samples': len(y)
                    })
                    
                    print(f"      ğŸ“ˆ {self._format_physio_label_en(physio_col)}: RÂ²={r2:.3f}, MAE={mae:.2f}, N={len(y)}")
        
        # ä¿å­˜ç»“æœ
        if model_summary:
            model_df = pd.DataFrame(model_summary)
            model_file = f"{self.output_dir}/experiment_sensor_models.csv"
            model_df.to_csv(model_file, index=False)
            print(f"ğŸ’¾ ä¿å­˜å®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹æ¨¡å‹è¯„ä¼°: {model_file}")
            
            # åˆ›å»ºè¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”å›¾
            self.create_experiment_sensor_comparison(model_df)
            
            # ç»Ÿè®¡æ€»ç»“
            total_models = len(model_summary)
            successful_models = len([m for m in model_summary if m['r2_score'] > 0])
            print(f"\nğŸ“Š å»ºæ¨¡ç»Ÿè®¡:")
            print(f"   â€¢ æ€»æ¨¡å‹æ•°: {total_models}")
            print(f"   â€¢ æˆåŠŸæ¨¡å‹æ•°: {successful_models}")
            print(f"   â€¢ æˆåŠŸç‡: {successful_models/total_models*100:.1f}%")
            
            # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
            best_models = sorted(model_summary, key=lambda x: x['r2_score'], reverse=True)[:5]
            print(f"\nğŸ† Top 5 æœ€ä½³æ¨¡å‹:")
            for i, model in enumerate(best_models):
                print(f"   {i+1}. å®éªŒ{model['experiment']} {model['sensor_label']} â†’ {model['parameter_label']}")
                print(f"      RÂ²={model['r2_score']:.3f}, MAE={model['mae']:.2f}, N={model['n_samples']}")
        
        return all_models
    
    def run_individual_regression_analysis(self):
        """ä¸ºæ¯ä¸ªå®éªŒå•ç‹¬æ„å»ºå›å½’æ¨¡å‹å¹¶ç»˜åˆ¶æ‹Ÿåˆç›´çº¿"""
        print("\nğŸ¯ å¼€å§‹å•ç‹¬å®éªŒå›å½’åˆ†æ...")
        individual_models = {}
        model_summary = []
        
        for exp_id in range(1, 12):  # å®éªŒ1-11
            print(f"\nğŸ“Š æ„å»ºå®éªŒ{exp_id}çš„å›å½’æ¨¡å‹")
            exp_data = self.analyze_experiment(exp_id)
            
            if not exp_data or len(exp_data['sync_data']) < 20:
                print(f"âŒ å®éªŒ{exp_id}æ•°æ®ä¸è¶³ï¼ˆ<20æ ·æœ¬ï¼‰")
                continue
            
            # ç›´æ¥ä»analyze_experimentçš„ç»“æœä¸­è·å–æ¨¡å‹
            if 'models' in exp_data and exp_data['models']:
                exp_models = exp_data['models']
                individual_models[f'exp_{exp_id}'] = exp_models
                
                # æ”¶é›†æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
                for model_key, model_info in exp_models.items():
                    # ä»model_keyä¸­æå–ç”Ÿç†æŒ‡æ ‡åç§°
                    # model_keyæ ¼å¼: "sensor_pairâ†’physio_col"
                    physio_param = model_key.split('â†’')[1] if 'â†’' in model_key else model_key
                    
                    model_summary.append({
                        'experiment': exp_id,
                        'physiological_parameter': physio_param,
                        'parameter_label': self._format_physio_label_en(physio_param),
                        'r2_score': model_info['r2_score'],
                        'mae': model_info['mae'],
                        'n_samples': model_info['n_samples'],
                        'sensor_pair': model_info.get('sensor_pair', ''),
                        'sensor_label': self._format_sensor_pair_label_en(model_info.get('sensor_pair', ''))
                    })
        
        # ä¿å­˜å•ç‹¬å®éªŒçš„æ¨¡å‹è¯„ä¼°
        if model_summary:
            model_df = pd.DataFrame(model_summary)
            model_file = f"{self.output_dir}/individual_experiment_models.csv"
            model_df.to_csv(model_file, index=False)
            print(f"ğŸ’¾ ä¿å­˜å•ç‹¬å®éªŒæ¨¡å‹è¯„ä¼°: {model_file}")

            # å¯¹æ¯ä¸ªå®éªŒçš„æ¯ä¸ªç”Ÿç†å‚æ•°ï¼Œé€‰æ‹©æœ€ä½³æ¨¡å‹ï¼ˆæŒ‰RÂ²ï¼‰
            # é¦–å…ˆæŒ‰å®éªŒå’Œç”Ÿç†å‚æ•°åˆ†ç»„ï¼Œç„¶ååœ¨æ¯ä¸ªç»„å†…å–RÂ²æœ€å¤§çš„è¡Œ
            best_model_df = model_df.loc[model_df.groupby(['experiment', 'physiological_parameter'])['r2_score'].idxmax()]
            
            # åˆ›å»ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”å¯è§†åŒ–
            self.create_individual_model_comparison(best_model_df)
        
        return individual_models

    def create_experiment_sensor_comparison(self, model_df):
        """åˆ›å»ºå®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹æ€§èƒ½å¯¹æ¯”å›¾"""
        if model_df.empty:
            return
        
        # åˆ›å»ºå¤šç»´åº¦å¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        
        # 1. æŒ‰å®éªŒåˆ†ç»„çš„RÂ²çƒ­å›¾
        exp_r2_pivot = model_df.pivot_table(
            index='experiment', 
            columns=['sensor_label', 'parameter_label'], 
            values='r2_score', 
            aggfunc='mean'
        )
        sns.heatmap(exp_r2_pivot, annot=True, fmt='.2f', cmap='Blues', 
                   ax=axes[0,0], cbar_kws={'label': 'RÂ² Score'})
        axes[0,0].set_title('å„å®éªŒRÂ²å¯¹æ¯” (æŒ‰ä¼ æ„Ÿå™¨å¯¹Ã—ç”Ÿç†å‚æ•°)', fontsize=12, fontweight='bold')
        axes[0,0].set_xlabel('ä¼ æ„Ÿå™¨å¯¹ Ã— ç”Ÿç†å‚æ•°')
        axes[0,0].set_ylabel('å®éªŒç¼–å·')
        
        # 2. æŒ‰å®éªŒåˆ†ç»„çš„MAEçƒ­å›¾
        exp_mae_pivot = model_df.pivot_table(
            index='experiment', 
            columns=['sensor_label', 'parameter_label'], 
            values='mae', 
            aggfunc='mean'
        )
        sns.heatmap(exp_mae_pivot, annot=True, fmt='.1f', cmap='Reds', 
                   ax=axes[0,1], cbar_kws={'label': 'MAE'})
        axes[0,1].set_title('å„å®éªŒMAEå¯¹æ¯” (æŒ‰ä¼ æ„Ÿå™¨å¯¹Ã—ç”Ÿç†å‚æ•°)', fontsize=12, fontweight='bold')
        axes[0,1].set_xlabel('ä¼ æ„Ÿå™¨å¯¹ Ã— ç”Ÿç†å‚æ•°')
        axes[0,1].set_ylabel('å®éªŒç¼–å·')
        
        # 3. æŒ‰ä¼ æ„Ÿå™¨å¯¹åˆ†ç»„çš„å¹³å‡RÂ²
        sensor_avg_r2 = model_df.groupby(['sensor_label', 'parameter_label'])['r2_score'].mean().reset_index()
        sensor_r2_pivot = sensor_avg_r2.pivot(index='sensor_label', columns='parameter_label', values='r2_score')
        sns.heatmap(sensor_r2_pivot, annot=True, fmt='.3f', cmap='Blues', 
                   ax=axes[1,0], cbar_kws={'label': 'Average RÂ²'})
        axes[1,0].set_title('å„ä¼ æ„Ÿå™¨å¯¹å¹³å‡RÂ² (è·¨å®éªŒ)', fontsize=12, fontweight='bold')
        axes[1,0].set_xlabel('ç”Ÿç†å‚æ•°')
        axes[1,0].set_ylabel('ä¼ æ„Ÿå™¨å¯¹')
        
        # 4. æŒ‰ä¼ æ„Ÿå™¨å¯¹åˆ†ç»„çš„å¹³å‡MAE
        sensor_avg_mae = model_df.groupby(['sensor_label', 'parameter_label'])['mae'].mean().reset_index()
        sensor_mae_pivot = sensor_avg_mae.pivot(index='sensor_label', columns='parameter_label', values='mae')
        sns.heatmap(sensor_mae_pivot, annot=True, fmt='.1f', cmap='Reds', 
                   ax=axes[1,1], cbar_kws={'label': 'Average MAE'})
        axes[1,1].set_title('å„ä¼ æ„Ÿå™¨å¯¹å¹³å‡MAE (è·¨å®éªŒ)', fontsize=12, fontweight='bold')
        axes[1,1].set_xlabel('ç”Ÿç†å‚æ•°')
        axes[1,1].set_ylabel('ä¼ æ„Ÿå™¨å¯¹')
        
        plt.tight_layout()
        comparison_file = f"{self.output_dir}/experiment_sensor_performance_comparison.png"
        plt.savefig(comparison_file, dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾å½¢ï¼Œä¸æ˜¾ç¤º
        print(f"ğŸ’¾ ä¿å­˜å®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹æ€§èƒ½å¯¹æ¯”å›¾: {comparison_file}")
        
        # ä¿å­˜æœ€ä½³ä¼ æ„Ÿå™¨å¯¹æ’åï¼ˆè·¨å®éªŒå¹³å‡ï¼‰
        best_sensors = []
        for param in sensor_r2_pivot.columns:
            if param in sensor_r2_pivot.columns:
                best_r2_idx = sensor_r2_pivot[param].idxmax()
                best_r2_val = sensor_r2_pivot.loc[best_r2_idx, param]
                best_mae_val = sensor_mae_pivot.loc[best_r2_idx, param]
                best_sensors.append({
                    'parameter': param,
                    'best_sensor': best_r2_idx,
                    'avg_r2_score': best_r2_val,
                    'avg_mae': best_mae_val
                })
        
        if best_sensors:
            best_df = pd.DataFrame(best_sensors)
            best_file = f"{self.output_dir}/best_sensors_across_experiments.csv"
            best_df.to_csv(best_file, index=False)
            print(f"ğŸ’¾ ä¿å­˜è·¨å®éªŒæœ€ä½³ä¼ æ„Ÿå™¨å¯¹: {best_file}")
    
    def create_sensor_pair_comparison(self, model_df):
        """åˆ›å»ºä¼ æ„Ÿå™¨å¯¹æ€§èƒ½å¯¹æ¯”å›¾"""
        if model_df.empty:
            return
        
        # åˆ›å»ºMAEå’ŒRÂ²å¯¹æ¯”å›¾
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12))
        
        # MAEå¯¹æ¯”çƒ­å›¾
        pivot_mae = model_df.pivot(index='sensor_label', columns='parameter_label', values='mae')
        sns.heatmap(pivot_mae, annot=True, fmt='.1f', cmap='Reds', ax=ax1, cbar_kws={'label': 'MAE'})
        ax1.set_title('å„ä¼ æ„Ÿå™¨å¯¹MAEå¯¹æ¯” (è¶Šä½è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax1.set_xlabel('ç”Ÿç†å‚æ•°')
        ax1.set_ylabel('ä¼ æ„Ÿå™¨å¯¹')
        
        # RÂ²å¯¹æ¯”çƒ­å›¾
        pivot_r2 = model_df.pivot(index='sensor_label', columns='parameter_label', values='r2_score')
        sns.heatmap(pivot_r2, annot=True, fmt='.3f', cmap='Blues', ax=ax2, cbar_kws={'label': 'RÂ² Score'})
        ax2.set_title('å„ä¼ æ„Ÿå™¨å¯¹RÂ²å¯¹æ¯” (è¶Šé«˜è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax2.set_xlabel('ç”Ÿç†å‚æ•°')
        ax2.set_ylabel('ä¼ æ„Ÿå™¨å¯¹')
        
        plt.tight_layout()
        comparison_file = f"{self.output_dir}/sensor_pair_performance_comparison.png"
        plt.savefig(comparison_file, dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾å½¢ï¼Œä¸æ˜¾ç¤º
        print(f"ğŸ’¾ ä¿å­˜ä¼ æ„Ÿå™¨å¯¹æ€§èƒ½å¯¹æ¯”å›¾: {comparison_file}")
        
        # åˆ›å»ºæœ€ä½³ä¼ æ„Ÿå™¨å¯¹æ’å
        best_sensors = []
        for param in pivot_r2.columns:
            if param in pivot_r2.columns:
                best_r2_idx = pivot_r2[param].idxmax()
                best_r2_val = pivot_r2.loc[best_r2_idx, param]
                best_mae_val = pivot_mae.loc[best_r2_idx, param]
                best_sensors.append({
                    'parameter': param,
                    'best_sensor': best_r2_idx,
                    'r2_score': best_r2_val,
                    'mae': best_mae_val
                })
        
        if best_sensors:
            best_df = pd.DataFrame(best_sensors)
            best_file = f"{self.output_dir}/best_sensor_pairs.csv"
            best_df.to_csv(best_file, index=False)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³ä¼ æ„Ÿå™¨å¯¹æ’å: {best_file}")
            
            print(f"\nğŸ† å„ç”Ÿç†å‚æ•°çš„æœ€ä½³ä¼ æ„Ÿå™¨å¯¹:")
            for _, row in best_df.iterrows():
                print(f"   â€¢ {row['parameter']}: {row['best_sensor']} (RÂ²={row['r2_score']:.3f}, MAE={row['mae']:.1f})")
    
    def create_individual_model_comparison(self, model_df):
        """åˆ›å»ºå•ç‹¬å®éªŒæ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾"""
        if model_df.empty:
            return
        
        # åˆ›å»ºMAEå’ŒRÂ²å¯¹æ¯”å›¾
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))
        
        # MAEå¯¹æ¯”
        pivot_mae = model_df.pivot(index='experiment', columns='parameter_label', values='mae')
        im1 = ax1.imshow(pivot_mae.values.T, cmap='Reds', aspect='auto')
        ax1.set_title('å„å®éªŒMAEå¯¹æ¯” (è¶Šä½è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax1.set_xlabel('å®éªŒç¼–å·')
        ax1.set_ylabel('ç”Ÿç†å‚æ•°')
        ax1.set_xticks(range(len(pivot_mae.index)))
        ax1.set_xticklabels(pivot_mae.index)
        ax1.set_yticks(range(len(pivot_mae.columns)))
        ax1.set_yticklabels(pivot_mae.columns, fontsize=10)
        
        # æ·»åŠ MAEæ•°å€¼æ ‡æ³¨
        for i in range(len(pivot_mae.columns)):
            for j in range(len(pivot_mae.index)):
                if not np.isnan(pivot_mae.iloc[j, i]):
                    ax1.text(j, i, f'{pivot_mae.iloc[j, i]:.1f}', 
                            ha='center', va='center', fontweight='bold')
        
        plt.colorbar(im1, ax=ax1, label='MAE')
        
        # RÂ²å¯¹æ¯”
        pivot_r2 = model_df.pivot(index='experiment', columns='parameter_label', values='r2_score')
        im2 = ax2.imshow(pivot_r2.values.T, cmap='Blues', aspect='auto')
        ax2.set_title('å„å®éªŒRÂ²å¯¹æ¯” (è¶Šé«˜è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax2.set_xlabel('å®éªŒç¼–å·')
        ax2.set_ylabel('ç”Ÿç†å‚æ•°')
        ax2.set_xticks(range(len(pivot_r2.index)))
        ax2.set_xticklabels(pivot_r2.index)
        ax2.set_yticks(range(len(pivot_r2.columns)))
        ax2.set_yticklabels(pivot_r2.columns, fontsize=10)
        
        # æ·»åŠ RÂ²æ•°å€¼æ ‡æ³¨
        for i in range(len(pivot_r2.columns)):
            for j in range(len(pivot_r2.index)):
                if not np.isnan(pivot_r2.iloc[j, i]):
                    ax2.text(j, i, f'{pivot_r2.iloc[j, i]:.2f}', 
                            ha='center', va='center', fontweight='bold')
        
        plt.colorbar(im2, ax=ax2, label='RÂ² Score')
        
        plt.tight_layout()
        comparison_file = f"{self.output_dir}/individual_model_performance_comparison.png"
        plt.savefig(comparison_file, dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾å½¢ï¼Œä¸æ˜¾ç¤º
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾: {comparison_file}")

    def save_analysis_results(self, combined_df, correlations, models):
        """ä¿å­˜åˆ†æç»“æœï¼ˆè‹±æ–‡ç‰ˆï¼‰"""
        # 1. ä¿å­˜åŒæ­¥æ•°æ®
        sync_file = f"{self.output_dir}/synchronized_ptt_cardiovascular_data.csv"
        combined_df.to_csv(sync_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜åŒæ­¥æ•°æ®: {sync_file}")
        
        # 2. ä¿å­˜ç›¸å…³æ€§ç»“æœ
        corr_results = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                corr_results.append({
                    'sensor_pair': sensor_pair,
                    'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                    'physiological_parameter': physio_col,
                    'parameter_label': self._format_physio_label_en(physio_col),
                    'correlation_coefficient': stats_data['correlation'],
                    'p_value': stats_data['p_value'],
                    'n_samples': stats_data['n_samples'],
                    'statistically_significant': stats_data['significant']
                })
        
        corr_df = pd.DataFrame(corr_results)
        corr_file = f"{self.output_dir}/ptt_cardiovascular_correlations.csv"
        corr_df.to_csv(corr_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜ç›¸å…³æ€§åˆ†æ: {corr_file}")
        
        # 3. ä¿å­˜æ¨¡å‹è¯„ä¼°ç»“æœ
        model_results = []
        for physio_col, model_data in models.items():
            model_results.append({
                'physiological_parameter': physio_col,
                'parameter_label': self._format_physio_label_en(physio_col),
                'r2_score': model_data['r2_score'],
                'mae': model_data['mae'],
                'n_samples': model_data['n_samples']
            })
        
        model_df = pd.DataFrame(model_results)
        model_file = f"{self.output_dir}/ptt_cardiovascular_model_evaluation.csv"
        model_df.to_csv(model_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹è¯„ä¼°: {model_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ©º PTT-Cardiovascular Parameters Correlation Analysis")
    print("="*60)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = PTTBloodPressureAnalyzer()
    
    print("\nğŸ“‹ è¯·é€‰æ‹©åˆ†ææ–¹å¼:")
    print("1. ç»¼åˆåˆ†æ (åŸå§‹ï¼šæ± åŒ–æ‰€æœ‰å®éªŒæ•°æ®æ‹Ÿåˆ)")
    print("2. å•ç‹¬å®éªŒæ‹Ÿåˆåˆ†æ (æ¯ä¸ªå®éªŒå•ç‹¬å»ºæ¨¡)")
    print("3. ä¼ æ„Ÿå™¨å¯¹å•ç‹¬æ‹Ÿåˆåˆ†æ (æ¯ä¸ªä¼ æ„Ÿå™¨å¯¹å•ç‹¬å»ºæ¨¡) â­æ¨è")
    print("4. å®Œæ•´å¯¹æ¯”åˆ†æ (åŒ…å«1+2+3)")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3/4, é»˜è®¤3): ").strip()
        if not choice:
            choice = "3"  # é»˜è®¤é€‰æ‹©ä¼ æ„Ÿå™¨å¯¹æ‹Ÿåˆ
    except:
        choice = "3"  # é»˜è®¤é€‰æ‹©
    
    if choice == "1":
        print("\nğŸ”¬ è¿è¡Œç»¼åˆåˆ†æï¼ˆæ± åŒ–æ‹Ÿåˆï¼‰...")
        # è¿è¡Œç»¼åˆåˆ†æ
        results = analyzer.run_comprehensive_analysis()
        
        if results and results['overall']:
            overall_results = results['overall']
            individual_results = results['individual']
            
            print("\nğŸ“‹ Analysis Summary:")
            print(f"   â€¢ Total samples: {len(overall_results['combined_data'])}")
            physio_indicators = len([col for col in overall_results['combined_data'].columns 
                                   if any(indicator in col for indicator in analyzer.physiological_indicators.keys())])
            print(f"   â€¢ PTT combinations: {len(analyzer.ptt_combinations_en)}")
            print(f"   â€¢ Physiological parameters: {physio_indicators}")
            print(f"   â€¢ Regression models: {len(overall_results['models'])}")
            print(f"   â€¢ Individual experiments analyzed: {len(individual_results) if individual_results else 0}")
            
            # æ˜¾ç¤ºæœ€ä½³ç›¸å…³æ€§
            print(f"\nğŸ† Top Significant Correlations (Overall Analysis):")
            all_corrs = []
            for sensor_pair, physio_data in overall_results['correlations'].items():
                for physio_col, stats_data in physio_data.items():
                    if stats_data['significant']:
                        all_corrs.append((abs(stats_data['correlation']), 
                                        analyzer._format_sensor_pair_label_en(sensor_pair),
                                        analyzer._format_physio_label_en(physio_col),
                                        stats_data['correlation'],
                                        stats_data['p_value'],
                                        stats_data['n_samples']))
            
            all_corrs.sort(reverse=True)
            for i, (abs_corr, sensor_label, physio_label, corr, p_val, n_samples) in enumerate(all_corrs[:10]):
                direction = "â†‘" if corr > 0 else "â†“"
                print(f"   {i+1:2d}. {sensor_label} â†â†’ {physio_label}")
                print(f"       r={corr:+.3f} {direction}, p={p_val:.2e}, N={n_samples}")
            
            # æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½
            if overall_results['models']:
                print(f"\nğŸ“ˆ Best Prediction Models (æ± åŒ–æ‹Ÿåˆ):")
                model_performance = [(model_data['r2_score'], physio_col, model_data) 
                                   for physio_col, model_data in overall_results['models'].items()]
                model_performance.sort(reverse=True)
                
                for i, (r2, physio_col, model_data) in enumerate(model_performance[:5]):
                    physio_label = analyzer._format_physio_label_en(physio_col)
                    print(f"   {i+1}. {physio_label}: RÂ²={r2:.3f}, MAE={model_data['mae']:.2f}")
    
    elif choice == "2":
        print("\nğŸ¯ è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆåˆ†æ...")
        # è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆ
        individual_models = analyzer.run_individual_regression_analysis()
        
        if individual_models:
            print(f"\nğŸ“Š å•ç‹¬å®éªŒæ‹Ÿåˆå®Œæˆ!")
            print(f"   â€¢ æˆåŠŸåˆ†æå®éªŒæ•°: {len(individual_models)}")
            print(f"   â€¢ è¯¦ç»†ç»“æœå·²ä¿å­˜: individual_experiment_models.csv")
            print(f"   â€¢ æ€§èƒ½å¯¹æ¯”å›¾: individual_model_performance_comparison.png")
    
    elif choice == "3":
         print("\nğŸ¯ è¿è¡Œå®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹å•ç‹¬æ‹Ÿåˆåˆ†æ...")
         # è¿è¡Œå®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹å•ç‹¬æ‹Ÿåˆ
         exp_sensor_models = analyzer.run_individual_experiment_sensor_regression_analysis()
         
         if exp_sensor_models:
             print(f"\nâœ… å®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹å•ç‹¬æ‹Ÿåˆå®Œæˆ!")
             print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")
             print(f"ğŸ“Š æˆåŠŸåˆ†æçš„å®éªŒæ•°é‡: {len(exp_sensor_models)}")
             print(f"ğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
             print(f"   â€¢ experiment_sensor_models.csv - è¯¦ç»†æ¨¡å‹æ€§èƒ½")
             print(f"   â€¢ experiment_sensor_performance_comparison.png - æ€§èƒ½å¯¹æ¯”å›¾")
             print(f"   â€¢ best_sensors_across_experiments.csv - è·¨å®éªŒæœ€ä½³ä¼ æ„Ÿå™¨å¯¹")
    
    elif choice == "4":
         print("\nğŸ”¬ è¿è¡Œå®Œæ•´å¯¹æ¯”åˆ†æ...")
         # å…ˆè¿è¡Œç»¼åˆåˆ†æ
         print("\nç¬¬ä¸€éƒ¨åˆ†ï¼šç»¼åˆåˆ†æ")
         results = analyzer.run_comprehensive_analysis()
         
         # å†è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆ
         print("\n" + "="*60)
         print("ç¬¬äºŒéƒ¨åˆ†ï¼šå•ç‹¬å®éªŒåˆ†æ")
         individual_models = analyzer.run_individual_regression_analysis()
         
         # æœ€åè¿è¡Œå®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹å•ç‹¬æ‹Ÿåˆ
         print("\n" + "="*60)
         print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹å•ç‹¬æ‹Ÿåˆ")
         exp_sensor_models = analyzer.run_individual_experiment_sensor_regression_analysis()
         
         # å¯¹æ¯”æ€»ç»“
         if results and results['overall'] and individual_models and exp_sensor_models:
             print("\n" + "="*60)
             print("ç¬¬å››éƒ¨åˆ†ï¼šä¸‰ç§æ–¹æ³•å¯¹æ¯”æ€»ç»“")
             overall_models = results['overall']['models']
             
             print("\nğŸ“ˆ ä¸‰ç§æ‹Ÿåˆæ–¹å¼å¯¹æ¯”:")
             for physio_param in ['systolic_bp_mean', 'diastolic_bp_mean', 'mean_bp_mean']:
                 if physio_param in overall_models:
                     physio_label = analyzer._format_physio_label_en(physio_param)
                     print(f"\nğŸ“Š {physio_label}:")
                     
                     # æ± åŒ–æ‹Ÿåˆç»“æœ
                     overall_mae = overall_models[physio_param]['mae']
                     overall_r2 = overall_models[physio_param]['r2_score']
                     overall_n = overall_models[physio_param]['n_samples']
                     print(f"   æ± åŒ–æ‹Ÿåˆ: RÂ²={overall_r2:.3f}, MAE={overall_mae:.2f}, N={overall_n}")
                     
                     # å•ç‹¬å®éªŒçš„å¹³å‡æ€§èƒ½
                     individual_r2s = []
                     individual_maes = []
                     for exp_key, exp_models in individual_models.items():
                         if physio_param in exp_models:
                             individual_r2s.append(exp_models[physio_param]['r2_score'])
                             individual_maes.append(exp_models[physio_param]['mae'])
                     
                     if individual_r2s:
                         avg_r2 = np.mean(individual_r2s)
                         avg_mae = np.mean(individual_maes)
                         print(f"   å•ç‹¬å®éªŒ: RÂ²={avg_r2:.3f}Â±{np.std(individual_r2s):.3f}, MAE={avg_mae:.2f}Â±{np.std(individual_maes):.2f}")
                     
                     # å®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹çš„æ€§èƒ½ç»Ÿè®¡
                     exp_sensor_r2s = []
                     exp_sensor_maes = []
                     for exp_key, exp_data in exp_sensor_models.items():
                         for sensor_pair, sensor_models in exp_data.items():
                             if physio_param in sensor_models:
                                 exp_sensor_r2s.append(sensor_models[physio_param]['r2_score'])
                                 exp_sensor_maes.append(sensor_models[physio_param]['mae'])
                     
                     if exp_sensor_r2s:
                         best_r2 = max(exp_sensor_r2s)
                         best_mae = min(exp_sensor_maes)
                         avg_r2 = np.mean(exp_sensor_r2s)
                         avg_mae = np.mean(exp_sensor_maes)
                         print(f"   å®éªŒÃ—ä¼ æ„Ÿå™¨å¯¹: æœ€ä½³RÂ²={best_r2:.3f}, æœ€ä½³MAE={best_mae:.2f}")
                         print(f"                 å¹³å‡RÂ²={avg_r2:.3f}Â±{np.std(exp_sensor_r2s):.3f}, å¹³å‡MAE={avg_mae:.2f}Â±{np.std(exp_sensor_maes):.2f}")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œç»¼åˆåˆ†æ")
        choice = "1"
        # é€’å½’è°ƒç”¨åŸå§‹åˆ†æ
        analyzer.run_comprehensive_analysis()
    
    print(f"\nâœ… åˆ†æå®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")

if __name__ == "__main__":
    main() 