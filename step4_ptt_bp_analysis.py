#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PTTä¸è¡€å‹ç›¸å…³æ€§åˆ†æ
åŸºäºå¸ˆå…„å»ºè®®ï¼šä½¿ç”¨åˆç†åŒºé—´çš„PTTæ•°æ®åˆ†æä¸è¡€å‹çš„ç›¸å…³æ€§
"""

import os
import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class PTTBloodPressureAnalyzer:
    """PTTä¸è¡€å‹ç›¸å…³æ€§åˆ†æå™¨"""
    
    def __init__(self, output_dir="ptt_bp_analysis"):
        self.output_dir = output_dir
        self.ptt_output_dir = "ptt_output2"  # çª—å£åŒ–PTTæ•°æ®ç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # å®Œæ•´çš„ç”Ÿç†æŒ‡æ ‡æ˜ å°„ï¼ˆè‹±æ–‡ä¸“ä¸šæœ¯è¯­ï¼‰
        self.physiological_indicators = {
            'systolic_bp': 'Systolic BP (mmHg)',
            'diastolic_bp': 'Diastolic BP (mmHg)', 
            'mean_bp': 'Mean Arterial Pressure (mmHg)',
            'bp': 'Continuous BP (mmHg)',
            'cardiac_output': 'Cardiac Output (L/min)',
            'cardiac_index': 'Cardiac Index (L/min/mÂ²)',
            'hr': 'Heart Rate (bpm)',
            'systemic_vascular_resistance': 'Systemic Vascular Resistance (dynÂ·s/cmâµ)',
            'rsp': 'Respiration Rate (breaths/min)'
        }
        
        # PTTä¼ æ„Ÿå™¨ç»„åˆï¼ˆè‹±æ–‡æ ‡ç­¾ï¼‰
        self.ptt_combinations_en = {
            'sensor2-sensor3': 'Noseâ†’Finger',
            'sensor2-sensor4': 'Noseâ†’Wrist', 
            'sensor2-sensor5': 'Noseâ†’Ear',
            'sensor3-sensor4': 'Fingerâ†’Wrist',
            'sensor3-sensor5': 'Fingerâ†’Ear',
            'sensor4-sensor5': 'Wristâ†’Ear'
        }
        
        print("ğŸ”¬ Enhanced PTT-Cardiovascular Parameters Correlation Analyzer")
        print(f"ğŸ“ Results will be saved to: {self.output_dir}")
        print(f"ğŸ“Š Analyzing {len(self.physiological_indicators)} physiological indicators")
        print(f"ğŸ¯ Using {len(self.ptt_combinations_en)} PTT sensor combinations")
    
    def load_ground_truth_bp(self, exp_id):
        """åŠ è½½ç”Ÿç†æŒ‡æ ‡æ•°æ®ï¼ˆä»CSVæ–‡ä»¶ï¼‰"""
        try:
            # åŠ è½½CSVæ–‡ä»¶
            csv_file = f"output/csv_output/{exp_id}_biopac_aligned.csv"
            if not os.path.exists(csv_file):
                print(f"âŒ ç”Ÿç†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            # è¯»å–å®Œæ•´ç”Ÿç†æ•°æ®
            df = pd.read_csv(csv_file)
            print(f"âœ… åŠ è½½ç”Ÿç†æ•°æ®: {len(df)}æ¡è®°å½•")
            
            # æ˜¾ç¤ºå¯ç”¨çš„ç”Ÿç†æŒ‡æ ‡
            available_indicators = [col for col in df.columns if col in self.physiological_indicators.keys()]
            print(f"ğŸ“Š å¯ç”¨ç”Ÿç†æŒ‡æ ‡: {available_indicators}")
            
            return df
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç”Ÿç†æ•°æ®å¤±è´¥: {e}")
            return None
    
    def load_ptt_data(self, exp_id):
        """åŠ è½½æœ‰æ•ˆçª—å£çš„PTTæ•°æ®"""
        try:
            # åŠ è½½çª—å£éªŒè¯æ•°æ®
            window_file = f"{self.ptt_output_dir}/exp_{exp_id}/window_validation_exp_{exp_id}.csv"
            ptt_file = f"{self.ptt_output_dir}/exp_{exp_id}/ptt_windowed_exp_{exp_id}.csv"
            
            if not (os.path.exists(window_file) and os.path.exists(ptt_file)):
                print(f"âŒ PTTæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: exp_{exp_id}")
                return None
            
            # åŠ è½½çª—å£éªŒè¯ä¿¡æ¯
            window_df = pd.read_csv(window_file)
            # ç­›é€‰æœ‰æ•ˆçª—å£ï¼ˆæ—¶é¢‘åŸŸå¿ƒç‡è¯¯å·®åˆç†ï¼‰
            valid_windows = window_df[
                (window_df['is_valid'] == True) & 
                (window_df['hr_diff_bpm'].abs() <= 5)  # å¿ƒç‡è¯¯å·®â‰¤5BPM
            ]
            
            # åŠ è½½PTTæ•°æ®
            ptt_df = pd.read_csv(ptt_file)
            
            # åªä¿ç•™æœ‰æ•ˆçª—å£çš„PTTæ•°æ®
            valid_ptt = ptt_df[ptt_df['window_id'].isin(valid_windows['window_id'])]
            
            print(f"ğŸ“Š å®éªŒ{exp_id}: æ€»çª—å£{len(window_df)}, æœ‰æ•ˆçª—å£{len(valid_windows)}, æœ‰æ•ˆPTTæ•°æ®{len(valid_ptt)}")
            
            return {
                'window_info': valid_windows,
                'ptt_data': valid_ptt
            }
            
        except Exception as e:
            print(f"âŒ åŠ è½½PTTæ•°æ®å¤±è´¥: {e}")
            return None
    
    def synchronize_data(self, ptt_data, physio_data, exp_id):
        """æ—¶é—´åŒæ­¥PTTå’Œç”Ÿç†æ•°æ®"""
        synchronized_data = []
        
        for _, ptt_row in ptt_data['ptt_data'].iterrows():
            # PTTæ•°æ®çš„æ—¶é—´ä¿¡æ¯ï¼ˆä¿®æ­£åˆ—åï¼‰
            start_time = ptt_row['window_start_s']
            end_time = ptt_row['window_end_s']
            window_center = (start_time + end_time) / 2
            
            # è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆå‡è®¾ç”Ÿç†æ•°æ®çš„timestampæ˜¯ç»å¯¹æ—¶é—´æˆ³ï¼‰
            # éœ€è¦æ‰¾åˆ°ç”Ÿç†æ•°æ®æ—¶é—´æˆ³çš„èµ·å§‹ç‚¹
            physio_start_time = physio_data['timestamp'].iloc[0]
            start_timestamp = physio_start_time + start_time
            end_timestamp = physio_start_time + end_time
            
            # æ‰¾åˆ°æ—¶é—´çª—å£å†…çš„ç”Ÿç†æ•°æ®
            time_mask = (physio_data['timestamp'] >= start_timestamp) & (physio_data['timestamp'] <= end_timestamp)
            window_physio = physio_data[time_mask]
            
            if len(window_physio) == 0:
                continue  # è·³è¿‡æ²¡æœ‰ç”Ÿç†æ•°æ®çš„çª—å£
            
            # è®¡ç®—çª—å£å†…æ‰€æœ‰ç”Ÿç†æŒ‡æ ‡çš„ç»Ÿè®¡é‡
            physio_values = {}
            for indicator in self.physiological_indicators.keys():
                if indicator in physio_data.columns:
                    physio_values[f'{indicator}_mean'] = window_physio[indicator].mean()
                    physio_values[f'{indicator}_std'] = window_physio[indicator].std()
                    physio_values[f'{indicator}_min'] = window_physio[indicator].min()
                    physio_values[f'{indicator}_max'] = window_physio[indicator].max()
                    physio_values[f'{indicator}_count'] = len(window_physio)
            
            # æ„å»ºåŒæ­¥æ•°æ®è¡Œ
            sync_row = {
                'exp_id': exp_id,
                'window_id': ptt_row['window_id'],
                'start_time': start_time,
                'end_time': end_time,
                'window_center': window_center,
                'sensor_pair': ptt_row['sensor_pair'],
                'ptt_ms': ptt_row['ptt_ms'],
                **physio_values
            }
            
            synchronized_data.append(sync_row)
        
        sync_df = pd.DataFrame(synchronized_data)
        print(f"ğŸ“Š åŒæ­¥å®Œæˆ: {len(sync_df)}ä¸ªæœ‰æ•ˆçª—å£")
        
        return sync_df
    
    def calculate_correlations(self, sync_df):
        """è®¡ç®—PTTä¸æ‰€æœ‰ç”Ÿç†æŒ‡æ ‡çš„ç›¸å…³æ€§"""
        correlations = {}
        
        # ç”Ÿç†æŒ‡æ ‡ï¼ˆæ‰©å±•åˆ°æ‰€æœ‰å¯ç”¨æŒ‡æ ‡ï¼‰
        physio_metrics = []
        for indicator in self.physiological_indicators.keys():
            for stat in ['_mean', '_std', '_min', '_max']:
                col_name = f'{indicator}{stat}'
                if col_name in sync_df.columns:
                    physio_metrics.append(col_name)
        
        # è·å–æ‰€æœ‰ä¼ æ„Ÿå™¨å¯¹
        sensor_pairs = sync_df['sensor_pair'].unique()
        
        print(f"\nğŸ“Š è®¡ç®—ç›¸å…³æ€§ï¼š{len(sensor_pairs)}ä¸ªä¼ æ„Ÿå™¨å¯¹ Ã— {len(physio_metrics)}ä¸ªç”Ÿç†æŒ‡æ ‡")
        
        for sensor_pair in sensor_pairs:
            correlations[sensor_pair] = {}
            
            # æå–è¯¥ä¼ æ„Ÿå™¨å¯¹çš„æ•°æ®
            pair_data = sync_df[sync_df['sensor_pair'] == sensor_pair]
            
            if len(pair_data) < 10:  # è‡³å°‘10ä¸ªæ•°æ®ç‚¹
                continue
            
            for physio_col in physio_metrics:
                # æå–æœ‰æ•ˆæ•°æ®
                mask = ~(pair_data['ptt_ms'].isna() | pair_data[physio_col].isna())
                if mask.sum() < 10:
                    continue
                
                ptt_vals = pair_data.loc[mask, 'ptt_ms']
                physio_vals = pair_data.loc[mask, physio_col]
                
                # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
                try:
                    corr_coef, p_value = stats.pearsonr(ptt_vals, physio_vals)
                    
                    correlations[sensor_pair][physio_col] = {
                        'correlation': corr_coef,
                        'p_value': p_value,
                        'n_samples': len(ptt_vals),
                        'significant': p_value < 0.05
                    }
                except Exception as e:
                    print(f"âš ï¸ è®¡ç®—ç›¸å…³æ€§å¤±è´¥ {sensor_pair}-{physio_col}: {e}")
                    continue
        
        return correlations
    
    def create_correlation_heatmap(self, correlations, title_suffix=""):
        """åˆ›å»ºç›¸å…³æ€§çƒ­å›¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        # å‡†å¤‡æ•°æ®
        sensor_pairs = list(correlations.keys())
        physio_cols = set()
        for pair_data in correlations.values():
            physio_cols.update(pair_data.keys())
        physio_cols = sorted(list(physio_cols))
        
        if len(sensor_pairs) == 0 or len(physio_cols) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„ç›¸å…³æ€§æ•°æ®æ¥åˆ›å»ºçƒ­å›¾")
            return None
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        p_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        
        for i, sensor_pair in enumerate(sensor_pairs):
            for j, physio_col in enumerate(physio_cols):
                if physio_col in correlations[sensor_pair]:
                    corr_matrix[i, j] = correlations[sensor_pair][physio_col]['correlation']
                    p_matrix[i, j] = correlations[sensor_pair][physio_col]['p_value']
        
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(16, 10))
        
        # ç»˜åˆ¶çƒ­å›¾
        mask = np.isnan(corr_matrix)
        im = sns.heatmap(corr_matrix, 
                        xticklabels=[self._format_physio_label_en(col) for col in physio_cols],
                        yticklabels=[self._format_sensor_pair_label_en(pair) for pair in sensor_pairs],
                        annot=True, fmt='.3f', cmap='RdBu_r', center=0,
                        mask=mask, square=False, linewidths=0.5,
                        cbar_kws={'label': 'Correlation Coefficient'},
                        annot_kws={'size': 8})
        
        # æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
        for i in range(len(sensor_pairs)):
            for j in range(len(physio_cols)):
                if not np.isnan(p_matrix[i, j]) and p_matrix[i, j] < 0.05:
                    ax.text(j + 0.5, i + 0.5, '*', ha='center', va='center', 
                           color='white', fontsize=8, fontweight='bold')
        
        plt.title(f'PTT-Cardiovascular Parameters Correlation Analysis{title_suffix}', 
                 fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('Physiological Parameters', fontsize=12, fontweight='bold')
        plt.ylabel('PTT Sensor Combinations', fontsize=12, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        filename = f"{self.output_dir}/ptt_cardiovascular_correlation_heatmap{title_suffix.replace(' ', '_')}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜ç›¸å…³æ€§çƒ­å›¾: {filename}")
        
        return fig
    
    def _format_ptt_label(self, ptt_col):
        """æ ¼å¼åŒ–PTTæ ‡ç­¾"""
        # ptt_sensor2-sensor3_ms -> noseâ†’finger
        sensor_map = {'sensor2': 'nose', 'sensor3': 'finger', 'sensor4': 'wrist', 'sensor5': 'ear'}
        parts = ptt_col.replace('ptt_', '').replace('_ms', '').split('-')
        if len(parts) == 2:
            return f"{sensor_map.get(parts[0], parts[0])}â†’{sensor_map.get(parts[1], parts[1])}"
        return ptt_col
    
    def _format_bp_label(self, bp_col):
        """æ ¼å¼åŒ–è¡€å‹æ ‡ç­¾"""
        label_map = {
            'systolic_bp': 'æ”¶ç¼©å‹',
            'diastolic_bp': 'èˆ’å¼ å‹',
            'mean_bp': 'å¹³å‡åŠ¨è„‰å‹',
            'bp': 'è¿ç»­è¡€å‹'
        }
        
        for bp_type, label in label_map.items():
            if bp_col.startswith(bp_type):
                suffix = bp_col.replace(bp_type, '').replace('_', ' ')
                return f"{label}{suffix}"
        return bp_col
    
    def _format_sensor_pair_label(self, sensor_pair):
        """æ ¼å¼åŒ–ä¼ æ„Ÿå™¨å¯¹æ ‡ç­¾"""
        # sensor2-sensor3 -> noseâ†’finger
        sensor_map = {'sensor2': 'nose', 'sensor3': 'finger', 'sensor4': 'wrist', 'sensor5': 'ear'}
        if '-' in sensor_pair:
            parts = sensor_pair.split('-')
            if len(parts) == 2:
                return f"{sensor_map.get(parts[0], parts[0])}â†’{sensor_map.get(parts[1], parts[1])}"
        return sensor_pair
    
    def _format_physio_label_en(self, physio_col):
        """æ ¼å¼åŒ–ç”Ÿç†æŒ‡æ ‡æ ‡ç­¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        # æå–åŸºç¡€æŒ‡æ ‡åç§°å’Œç»Ÿè®¡é‡
        for indicator, label in self.physiological_indicators.items():
            if physio_col.startswith(indicator):
                stat_part = physio_col.replace(indicator, '').replace('_', ' ')
                if stat_part == ' mean':
                    return label
                elif stat_part == ' std':
                    return f"{label} (SD)"
                elif stat_part == ' min':
                    return f"{label} (Min)"
                elif stat_part == ' max':
                    return f"{label} (Max)"
                else:
                    return f"{label}{stat_part}"
        return physio_col
    
    def _format_sensor_pair_label_en(self, sensor_pair):
        """æ ¼å¼åŒ–ä¼ æ„Ÿå™¨å¯¹æ ‡ç­¾ï¼ˆè‹±æ–‡ç‰ˆï¼‰"""
        return self.ptt_combinations_en.get(sensor_pair, sensor_pair)
    
    def build_regression_models(self, sync_df):
        """æ„å»ºPTTâ†’ç”Ÿç†æŒ‡æ ‡çš„å›å½’æ¨¡å‹"""
        models = {}
        
        # ä¸»è¦ç”Ÿç†æŒ‡æ ‡ï¼ˆå‡å€¼ï¼‰
        main_physio_cols = []
        for indicator in ['systolic_bp', 'diastolic_bp', 'mean_bp', 'cardiac_output', 'cardiac_index']:
            col_name = f'{indicator}_mean'
            if col_name in sync_df.columns:
                main_physio_cols.append(col_name)
        
        # åˆ›å»ºä¼ æ„Ÿå™¨å¯¹çš„é€è§†è¡¨
        ptt_pivot = sync_df.pivot_table(
            index=['exp_id', 'window_id'], 
            columns='sensor_pair', 
            values='ptt_ms',
            aggfunc='mean'
        ).reset_index()
        
        # åˆå¹¶ç”Ÿç†æ•°æ®ï¼ˆå–å¹³å‡å€¼ï¼‰
        physio_agg = sync_df.groupby(['exp_id', 'window_id']).agg({
            col: 'mean' for col in main_physio_cols if col in sync_df.columns
        }).reset_index()
        
        # åˆå¹¶PTTå’Œç”Ÿç†æ•°æ®
        model_data = pd.merge(ptt_pivot, physio_agg, on=['exp_id', 'window_id'], how='inner')
        
        if len(model_data) < 20:
            print(f"âš ï¸ æ¨¡å‹æ•°æ®ä¸è¶³: åªæœ‰{len(model_data)}ä¸ªæ ·æœ¬")
            return models
        
        # è·å–PTTç‰¹å¾åˆ—
        ptt_cols = [col for col in model_data.columns if col not in ['exp_id', 'window_id'] + main_physio_cols]
        # å»é™¤å…¨ç©ºçš„PTTåˆ—
        ptt_cols = [col for col in ptt_cols if not model_data[col].isna().all()]
        
        if len(ptt_cols) == 0:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„PTTç‰¹å¾")
            return models
        
        for physio_col in main_physio_cols:
            if physio_col not in model_data.columns:
                continue
                
            # å‡†å¤‡æ•°æ®
            mask = ~model_data[physio_col].isna()
            for ptt_col in ptt_cols:
                mask &= ~model_data[ptt_col].isna()
            
            if mask.sum() < 10:  # è‡³å°‘10ä¸ªæ ·æœ¬
                continue
            
            X = model_data.loc[mask, ptt_cols].values
            y = model_data.loc[mask, physio_col].values
            
            # æ•°æ®æ ‡å‡†åŒ–
            scaler_X = StandardScaler()
            scaler_y = StandardScaler()
            X_scaled = scaler_X.fit_transform(X)
            y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
            
            # è®­ç»ƒæ¨¡å‹
            model = LinearRegression()
            model.fit(X_scaled, y_scaled)
            
            # é¢„æµ‹
            y_pred_scaled = model.predict(X_scaled)
            y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
            
            # è¯„ä¼°
            r2 = r2_score(y, y_pred)
            mae = mean_absolute_error(y, y_pred)
            
            models[physio_col] = {
                'model': model,
                'scaler_X': scaler_X,
                'scaler_y': scaler_y,
                'feature_names': ptt_cols,
                'r2_score': r2,
                'mae': mae,
                'n_samples': len(y),
                'y_true': y,
                'y_pred': y_pred
            }
            
            print(f"ğŸ“ˆ {self._format_physio_label_en(physio_col)}æ¨¡å‹: RÂ²={r2:.3f}, MAE={mae:.2f}, N={len(y)}")
        
        return models
    
    def create_regression_plots(self, models):
        """åˆ›å»ºå›å½’åˆ†æå›¾ï¼ˆè‹±æ–‡ä¸“ä¸šç‰ˆï¼‰"""
        n_models = len(models)
        if n_models == 0:
            return
        
        fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))
        if n_models == 1:
            axes = [axes]
        
        for idx, (physio_col, model_data) in enumerate(models.items()):
            ax = axes[idx]
            
            y_true = model_data['y_true']
            y_pred = model_data['y_pred']
            r2 = model_data['r2_score']
            mae = model_data['mae']
            
            # æ•£ç‚¹å›¾
            ax.scatter(y_true, y_pred, alpha=0.6, s=50, color='steelblue')
            
            # ç†æƒ³çº¿
            min_val = min(y_true.min(), y_pred.min())
            max_val = max(y_true.max(), y_pred.max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')
            
            # æ ¼å¼åŒ–
            physio_label = self._format_physio_label_en(physio_col)
            ax.set_xlabel(f'Actual {physio_label}', fontweight='bold')
            ax.set_ylabel(f'Predicted {physio_label}', fontweight='bold')
            ax.set_title(f'{physio_label}\nRÂ²={r2:.3f}, MAE={mae:.2f}', fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend()
        
        plt.suptitle('PTT-Based Physiological Parameter Prediction Models', 
                    fontsize=16, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        filename = f"{self.output_dir}/ptt_cardiovascular_regression_analysis.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜å›å½’åˆ†æå›¾: {filename}")
        
        return fig
    
    def analyze_experiment(self, exp_id):
        """åˆ†æå•ä¸ªå®éªŒ"""
        print(f"\nğŸ” åˆ†æå®éªŒ {exp_id}")
        
        # 1. åŠ è½½æ•°æ®
        physio_data = self.load_ground_truth_bp(exp_id)
        ptt_data = self.load_ptt_data(exp_id)
        
        if physio_data is None or ptt_data is None:
            print(f"âŒ å®éªŒ {exp_id} æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        # 2. æ—¶é—´åŒæ­¥
        sync_df = self.synchronize_data(ptt_data, physio_data, exp_id)
        print(f"ğŸ“Š åŒæ­¥æ•°æ®: {len(sync_df)}ä¸ªæ—¶é—´çª—å£")
        
        # 3. ç›¸å…³æ€§åˆ†æ
        correlations = self.calculate_correlations(sync_df)
        
        # 4. å›å½’å»ºæ¨¡
        models = self.build_regression_models(sync_df)
        
        return {
            'sync_data': sync_df,
            'correlations': correlations,
            'models': models
        }
    
    def run_individual_experiment_analysis(self):
        """è¿è¡Œå•ä¸ªå®éªŒçš„åˆ†æ"""
        print("ğŸ”¬ å¼€å§‹å•ä¸ªå®éªŒåˆ†æ...")
        
        individual_results = {}
        
        # è·å–å®éªŒåˆ—è¡¨
        exp_list = [1, 2, 7, 9, 10]  # åªåˆ†ææœ‰PTTæ•°æ®çš„å®éªŒ
        
        for exp_id in exp_list:
            print(f"\nğŸ” å•ç‹¬åˆ†æå®éªŒ {exp_id}")
            
            # åˆ†æå•ä¸ªå®éªŒ
            exp_result = self.analyze_experiment(exp_id)
            if exp_result:
                individual_results[exp_id] = exp_result['sync_data']
                
                # è®¡ç®—ç›¸å…³æ€§
                correlations = self.calculate_correlations(exp_result['sync_data'])
                
                # åˆ›å»ºå•ä¸ªå®éªŒçš„çƒ­å›¾
                self.create_focused_correlation_heatmap(correlations, f"_å®éªŒ{exp_id}")
                
                # ä¿å­˜å•ä¸ªå®éªŒç»“æœ
                self.save_individual_experiment_results(exp_result['sync_data'], correlations, exp_id)
        
        return individual_results
    
    def create_focused_correlation_heatmap(self, correlations, title_suffix=""):
        """åˆ›å»ºèšç„¦çš„ç›¸å…³æ€§çƒ­å›¾ï¼ˆåªæ˜¾ç¤ºé‡è¦æŒ‡æ ‡ï¼‰"""
        # é€‰æ‹©é‡è¦çš„ç”Ÿç†æŒ‡æ ‡ï¼ˆå‡å°‘å›¾åƒå¤§å°ï¼‰
        important_indicators = [
            'systolic_bp_mean', 'diastolic_bp_mean', 'mean_bp_mean',
            'cardiac_output_mean', 'cardiac_index_mean', 'hr_mean',
            'rsp_mean', 'systemic_vascular_resistance_mean'
        ]
        
        # å‡†å¤‡æ•°æ®
        sensor_pairs = list(correlations.keys())
        filtered_correlations = {}
        
        for sensor_pair in sensor_pairs:
            filtered_correlations[sensor_pair] = {
                col: correlations[sensor_pair][col] 
                for col in important_indicators 
                if col in correlations[sensor_pair]
            }
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        physio_cols = list(set().union(*[pair_data.keys() for pair_data in filtered_correlations.values()]))
        physio_cols = sorted(physio_cols)
        
        if len(sensor_pairs) == 0 or len(physio_cols) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®åˆ›å»ºèšç„¦çƒ­å›¾")
            return None
        
        corr_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        p_matrix = np.full((len(sensor_pairs), len(physio_cols)), np.nan)
        
        for i, sensor_pair in enumerate(sensor_pairs):
            for j, physio_col in enumerate(physio_cols):
                if physio_col in filtered_correlations[sensor_pair]:
                    corr_matrix[i, j] = filtered_correlations[sensor_pair][physio_col]['correlation']
                    p_matrix[i, j] = filtered_correlations[sensor_pair][physio_col]['p_value']
        
        # åˆ›å»ºå›¾å½¢ï¼ˆæ›´å°æ›´æ¸…æ™°ï¼‰
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ç»˜åˆ¶çƒ­å›¾
        mask = np.isnan(corr_matrix)
        im = sns.heatmap(corr_matrix, 
                        xticklabels=[self._format_physio_label_en(col) for col in physio_cols],
                        yticklabels=[self._format_sensor_pair_label_en(pair) for pair in sensor_pairs],
                        annot=True, fmt='.3f', cmap='RdBu_r', center=0,
                        mask=mask, square=False, linewidths=0.5,
                        cbar_kws={'label': 'Correlation Coefficient'},
                        annot_kws={'size': 10})
        
        # æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
        for i in range(len(sensor_pairs)):
            for j in range(len(physio_cols)):
                if not np.isnan(p_matrix[i, j]) and p_matrix[i, j] < 0.05:
                    ax.text(j + 0.5, i + 0.5, '*', ha='center', va='center', 
                           color='white', fontsize=14, fontweight='bold')
        
        plt.title(f'PTT-Cardiovascular Correlation Analysis (Key Parameters){title_suffix}', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.xlabel('Physiological Parameters', fontsize=12, fontweight='bold')
        plt.ylabel('PTT Sensor Combinations', fontsize=12, fontweight='bold')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        filename = f"{self.output_dir}/ptt_cardiovascular_correlation_focused{title_suffix.replace(' ', '_')}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä¿å­˜èšç„¦çƒ­å›¾: {filename}")
        
        return fig
    
    def save_individual_experiment_results(self, sync_data, correlations, exp_id):
        """ä¿å­˜å•ä¸ªå®éªŒçš„ç»“æœ"""
        # ä¿å­˜ç›¸å…³æ€§ç»“æœ
        corr_results = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                corr_results.append({
                    'experiment_id': exp_id,
                    'sensor_pair': sensor_pair,
                    'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                    'physiological_parameter': physio_col,
                    'parameter_label': self._format_physio_label_en(physio_col),
                    'correlation_coefficient': stats_data['correlation'],
                    'p_value': stats_data['p_value'],
                    'n_samples': stats_data['n_samples'],
                    'statistically_significant': stats_data['significant']
                })
        
        corr_df = pd.DataFrame(corr_results)
        corr_file = f"{self.output_dir}/ptt_cardiovascular_correlations_exp_{exp_id}.csv"
        corr_df.to_csv(corr_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜å®éªŒ{exp_id}ç›¸å…³æ€§: {corr_file}")
    
    def compare_experiments(self, individual_results):
        """æ¯”è¾ƒä¸åŒå®éªŒçš„ç»“æœ"""
        print("\nğŸ“Š å®éªŒé—´å¯¹æ¯”åˆ†æ...")
        
        # æ”¶é›†æ‰€æœ‰å®éªŒçš„ç›¸å…³æ€§æ•°æ®
        all_exp_correlations = []
        
        for exp_id, exp_data in individual_results.items():
            correlations = self.calculate_correlations(exp_data)
            
            for sensor_pair, physio_data in correlations.items():
                for physio_col, stats_data in physio_data.items():
                    if stats_data['significant']:
                        all_exp_correlations.append({
                            'experiment': exp_id,
                            'sensor_pair': sensor_pair,
                            'parameter': physio_col,
                            'correlation': stats_data['correlation'],
                            'n_samples': stats_data['n_samples']
                        })
        
        # è½¬æ¢ä¸ºDataFrame
        comp_df = pd.DataFrame(all_exp_correlations)
        
        if len(comp_df) == 0:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œå®éªŒé—´æ¯”è¾ƒ")
            return
        
        # ä¿å­˜æ¯”è¾ƒç»“æœ
        comp_file = f"{self.output_dir}/experiment_comparison.csv"
        comp_df.to_csv(comp_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜å®éªŒæ¯”è¾ƒ: {comp_file}")
        
        # æ‰“å°æ€»ç»“
        print(f"\nğŸ“‹ å®éªŒé—´æ¯”è¾ƒæ€»ç»“:")
        for exp_id in sorted(individual_results.keys()):
            exp_corr = comp_df[comp_df['experiment'] == exp_id]
            print(f"   å®éªŒ{exp_id}: {len(exp_corr)}ä¸ªæ˜¾è‘—ç›¸å…³æ€§")
            
            if len(exp_corr) > 0:
                strongest = exp_corr.loc[exp_corr['correlation'].abs().idxmax()]
                print(f"     æœ€å¼º: {strongest['sensor_pair']}-{strongest['parameter']} (r={strongest['correlation']:.3f})")
    
    def run_comprehensive_analysis(self):
        """è¿è¡Œç»¼åˆåˆ†æï¼ˆæ•´ä½“+å•ä¸ªå®éªŒï¼‰"""
        print("ğŸ”¬ å¼€å§‹PTTä¸ç”Ÿç†å‚æ•°ç»¼åˆåˆ†æ")
        print("ğŸ“‹ åˆ†æå®éªŒåˆ—è¡¨: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]")
        
        # 1. æ•´ä½“åˆ†æï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•´ä½“åˆ†æ ===")
        overall_results = self.run_overall_analysis()
        
        # 2. å•ä¸ªå®éªŒåˆ†æï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬äºŒéƒ¨åˆ†ï¼šå•ä¸ªå®éªŒåˆ†æ ===")
        individual_results = self.run_individual_experiment_analysis()
        
        # 3. å®éªŒé—´æ¯”è¾ƒï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
        print("\n=== ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®éªŒé—´æ¯”è¾ƒ ===")
        if individual_results:
            self.compare_experiments(individual_results)
        
        # 4. åˆ›å»ºèšç„¦çƒ­å›¾ï¼ˆä¼˜åŒ–æ˜¾ç¤ºï¼‰
        print("\n=== ç¬¬å››éƒ¨åˆ†ï¼šåˆ›å»ºèšç„¦çƒ­å›¾ ===")
        if overall_results:
            self.create_focused_correlation_heatmap(overall_results['correlations'], "_æ•´ä½“åˆ†æ_èšç„¦")
        
        return {
            'overall': overall_results,
            'individual': individual_results
        }
    
    def run_overall_analysis(self):
        """è¿è¡Œæ•´ä½“åˆ†æï¼ˆåŸæœ‰åŠŸèƒ½é‡å‘½åï¼‰"""
        # åŸæœ‰çš„ run_comprehensive_analysis å†…å®¹
        all_experiments = []
        
        # åˆ†ææ‰€æœ‰å®éªŒ
        for exp_id in range(1, 12):  # å®éªŒ1-11
            print(f"\nğŸ” åˆ†æå®éªŒ {exp_id}")
            exp_data = self.analyze_experiment(exp_id)
            
            if exp_data:
                # æå–sync_dataï¼ˆDataFrameï¼‰
                all_experiments.append(exp_data['sync_data'])
        
        if not all_experiments:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒæ•°æ®")
            return None
        
        # åˆå¹¶æ‰€æœ‰å®éªŒçš„æ•°æ®ï¼ˆä¿®æ­£ï¼šæå–DataFrameï¼‰
        combined_df = pd.concat(all_experiments, ignore_index=True)
        print(f"\nğŸ“Š åˆå¹¶æ•°æ®: {len(combined_df)}ä¸ªæ ·æœ¬ï¼Œæ¥è‡ª{len(all_experiments)}ä¸ªå®éªŒ")
        
        # è®¡ç®—æ•´ä½“ç›¸å…³æ€§
        print("\nğŸ“ˆ è®¡ç®—æ•´ä½“ç›¸å…³æ€§...")
        correlations = self.calculate_correlations(combined_df)
        
        # åˆ›å»ºç›¸å…³æ€§çƒ­å›¾
        self.create_correlation_heatmap(correlations, " (æ•´ä½“åˆ†æ)")
        
        # æ„å»ºå›å½’æ¨¡å‹
        print("\nğŸ¯ æ„å»ºæ•´ä½“å›å½’æ¨¡å‹...")
        models = self.build_regression_models(combined_df)
        
        # åˆ›å»ºå›å½’å›¾
        if models:
            self.create_regression_plots(models)
        
        # ä¿å­˜ç»“æœ
        self.save_analysis_results(combined_df, correlations, models)
        
        return {
            'combined_data': combined_df,
            'correlations': correlations,
            'models': models
        }
    
    def run_individual_regression_analysis(self):
        """ä¸ºæ¯ä¸ªå®éªŒå•ç‹¬æ„å»ºå›å½’æ¨¡å‹"""
        print("\nğŸ¯ å¼€å§‹å•ç‹¬å®éªŒå›å½’åˆ†æ...")
        individual_models = {}
        model_summary = []
        
        for exp_id in range(1, 12):  # å®éªŒ1-11
            print(f"\nğŸ“Š æ„å»ºå®éªŒ{exp_id}çš„å›å½’æ¨¡å‹")
            exp_data = self.analyze_experiment(exp_id)
            
            if not exp_data or len(exp_data['sync_data']) < 20:
                print(f"âŒ å®éªŒ{exp_id}æ•°æ®ä¸è¶³ï¼ˆ<20æ ·æœ¬ï¼‰")
                continue
            
            # ä¸ºå•ä¸ªå®éªŒæ„å»ºæ¨¡å‹
            exp_models = self.build_regression_models(exp_data['sync_data'])
            
            if exp_models:
                individual_models[f'exp_{exp_id}'] = exp_models
                
                # æ”¶é›†æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
                for physio_param, model_info in exp_models.items():
                    model_summary.append({
                        'experiment': exp_id,
                        'physiological_parameter': physio_param,
                        'parameter_label': self._format_physio_label_en(physio_param),
                        'r2_score': model_info['r2_score'],
                        'mae': model_info['mae'],
                        'n_samples': model_info['n_samples']
                    })
        
        # ä¿å­˜å•ç‹¬å®éªŒçš„æ¨¡å‹è¯„ä¼°
        if model_summary:
            model_df = pd.DataFrame(model_summary)
            model_file = f"{self.output_dir}/individual_experiment_models.csv"
            model_df.to_csv(model_file, index=False)
            print(f"ğŸ’¾ ä¿å­˜å•ç‹¬å®éªŒæ¨¡å‹è¯„ä¼°: {model_file}")
            
            # åˆ›å»ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”å¯è§†åŒ–
            self.create_individual_model_comparison(model_df)
        
        return individual_models
    
    def create_individual_model_comparison(self, model_df):
        """åˆ›å»ºå•ç‹¬å®éªŒæ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾"""
        if model_df.empty:
            return
        
        # åˆ›å»ºMAEå’ŒRÂ²å¯¹æ¯”å›¾
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))
        
        # MAEå¯¹æ¯”
        pivot_mae = model_df.pivot(index='experiment', columns='parameter_label', values='mae')
        im1 = ax1.imshow(pivot_mae.values.T, cmap='Reds', aspect='auto')
        ax1.set_title('å„å®éªŒMAEå¯¹æ¯” (è¶Šä½è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax1.set_xlabel('å®éªŒç¼–å·')
        ax1.set_ylabel('ç”Ÿç†å‚æ•°')
        ax1.set_xticks(range(len(pivot_mae.index)))
        ax1.set_xticklabels(pivot_mae.index)
        ax1.set_yticks(range(len(pivot_mae.columns)))
        ax1.set_yticklabels(pivot_mae.columns, fontsize=10)
        
        # æ·»åŠ MAEæ•°å€¼æ ‡æ³¨
        for i in range(len(pivot_mae.columns)):
            for j in range(len(pivot_mae.index)):
                if not np.isnan(pivot_mae.iloc[j, i]):
                    ax1.text(j, i, f'{pivot_mae.iloc[j, i]:.1f}', 
                            ha='center', va='center', fontweight='bold')
        
        plt.colorbar(im1, ax=ax1, label='MAE')
        
        # RÂ²å¯¹æ¯”
        pivot_r2 = model_df.pivot(index='experiment', columns='parameter_label', values='r2_score')
        im2 = ax2.imshow(pivot_r2.values.T, cmap='Blues', aspect='auto')
        ax2.set_title('å„å®éªŒRÂ²å¯¹æ¯” (è¶Šé«˜è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax2.set_xlabel('å®éªŒç¼–å·')
        ax2.set_ylabel('ç”Ÿç†å‚æ•°')
        ax2.set_xticks(range(len(pivot_r2.index)))
        ax2.set_xticklabels(pivot_r2.index)
        ax2.set_yticks(range(len(pivot_r2.columns)))
        ax2.set_yticklabels(pivot_r2.columns, fontsize=10)
        
        # æ·»åŠ RÂ²æ•°å€¼æ ‡æ³¨
        for i in range(len(pivot_r2.columns)):
            for j in range(len(pivot_r2.index)):
                if not np.isnan(pivot_r2.iloc[j, i]):
                    ax2.text(j, i, f'{pivot_r2.iloc[j, i]:.2f}', 
                            ha='center', va='center', fontweight='bold')
        
        plt.colorbar(im2, ax=ax2, label='RÂ² Score')
        
        plt.tight_layout()
        comparison_file = f"{self.output_dir}/individual_model_performance_comparison.png"
        plt.savefig(comparison_file, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾: {comparison_file}")

    def save_analysis_results(self, combined_df, correlations, models):
        """ä¿å­˜åˆ†æç»“æœï¼ˆè‹±æ–‡ç‰ˆï¼‰"""
        # 1. ä¿å­˜åŒæ­¥æ•°æ®
        sync_file = f"{self.output_dir}/synchronized_ptt_cardiovascular_data.csv"
        combined_df.to_csv(sync_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜åŒæ­¥æ•°æ®: {sync_file}")
        
        # 2. ä¿å­˜ç›¸å…³æ€§ç»“æœ
        corr_results = []
        for sensor_pair, physio_data in correlations.items():
            for physio_col, stats_data in physio_data.items():
                corr_results.append({
                    'sensor_pair': sensor_pair,
                    'sensor_combination': self._format_sensor_pair_label_en(sensor_pair),
                    'physiological_parameter': physio_col,
                    'parameter_label': self._format_physio_label_en(physio_col),
                    'correlation_coefficient': stats_data['correlation'],
                    'p_value': stats_data['p_value'],
                    'n_samples': stats_data['n_samples'],
                    'statistically_significant': stats_data['significant']
                })
        
        corr_df = pd.DataFrame(corr_results)
        corr_file = f"{self.output_dir}/ptt_cardiovascular_correlations.csv"
        corr_df.to_csv(corr_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜ç›¸å…³æ€§åˆ†æ: {corr_file}")
        
        # 3. ä¿å­˜æ¨¡å‹è¯„ä¼°ç»“æœ
        model_results = []
        for physio_col, model_data in models.items():
            model_results.append({
                'physiological_parameter': physio_col,
                'parameter_label': self._format_physio_label_en(physio_col),
                'r2_score': model_data['r2_score'],
                'mae': model_data['mae'],
                'n_samples': model_data['n_samples']
            })
        
        model_df = pd.DataFrame(model_results)
        model_file = f"{self.output_dir}/ptt_cardiovascular_model_evaluation.csv"
        model_df.to_csv(model_file, index=False)
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹è¯„ä¼°: {model_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ©º PTT-Cardiovascular Parameters Correlation Analysis")
    print("="*60)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = PTTBloodPressureAnalyzer()
    
    print("\nğŸ“‹ è¯·é€‰æ‹©åˆ†ææ–¹å¼:")
    print("1. ç»¼åˆåˆ†æ (åŸå§‹ï¼šæ± åŒ–æ‰€æœ‰å®éªŒæ•°æ®æ‹Ÿåˆ)")
    print("2. å•ç‹¬å®éªŒæ‹Ÿåˆåˆ†æ (æ¯ä¸ªå®éªŒå•ç‹¬å»ºæ¨¡)")
    print("3. å®Œæ•´å¯¹æ¯”åˆ†æ (åŒ…å«1+2)")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3, é»˜è®¤1): ").strip()
        if not choice:
            choice = "1"
    except:
        choice = "1"  # é»˜è®¤é€‰æ‹©
    
    if choice == "1":
        print("\nğŸ”¬ è¿è¡Œç»¼åˆåˆ†æï¼ˆæ± åŒ–æ‹Ÿåˆï¼‰...")
        # è¿è¡Œç»¼åˆåˆ†æ
        results = analyzer.run_comprehensive_analysis()
        
        if results and results['overall']:
            overall_results = results['overall']
            individual_results = results['individual']
            
            print("\nğŸ“‹ Analysis Summary:")
            print(f"   â€¢ Total samples: {len(overall_results['combined_data'])}")
            physio_indicators = len([col for col in overall_results['combined_data'].columns 
                                   if any(indicator in col for indicator in analyzer.physiological_indicators.keys())])
            print(f"   â€¢ PTT combinations: {len(analyzer.ptt_combinations_en)}")
            print(f"   â€¢ Physiological parameters: {physio_indicators}")
            print(f"   â€¢ Regression models: {len(overall_results['models'])}")
            print(f"   â€¢ Individual experiments analyzed: {len(individual_results) if individual_results else 0}")
            
            # æ˜¾ç¤ºæœ€ä½³ç›¸å…³æ€§
            print(f"\nğŸ† Top Significant Correlations (Overall Analysis):")
            all_corrs = []
            for sensor_pair, physio_data in overall_results['correlations'].items():
                for physio_col, stats_data in physio_data.items():
                    if stats_data['significant']:
                        all_corrs.append((abs(stats_data['correlation']), 
                                        analyzer._format_sensor_pair_label_en(sensor_pair),
                                        analyzer._format_physio_label_en(physio_col),
                                        stats_data['correlation'],
                                        stats_data['p_value'],
                                        stats_data['n_samples']))
            
            all_corrs.sort(reverse=True)
            for i, (abs_corr, sensor_label, physio_label, corr, p_val, n_samples) in enumerate(all_corrs[:10]):
                direction = "â†‘" if corr > 0 else "â†“"
                print(f"   {i+1:2d}. {sensor_label} â†â†’ {physio_label}")
                print(f"       r={corr:+.3f} {direction}, p={p_val:.2e}, N={n_samples}")
            
            # æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½
            if overall_results['models']:
                print(f"\nğŸ“ˆ Best Prediction Models (æ± åŒ–æ‹Ÿåˆ):")
                model_performance = [(model_data['r2_score'], physio_col, model_data) 
                                   for physio_col, model_data in overall_results['models'].items()]
                model_performance.sort(reverse=True)
                
                for i, (r2, physio_col, model_data) in enumerate(model_performance[:5]):
                    physio_label = analyzer._format_physio_label_en(physio_col)
                    print(f"   {i+1}. {physio_label}: RÂ²={r2:.3f}, MAE={model_data['mae']:.2f}")
    
    elif choice == "2":
        print("\nğŸ¯ è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆåˆ†æ...")
        # è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆ
        individual_models = analyzer.run_individual_regression_analysis()
        
        if individual_models:
            print(f"\nğŸ“Š å•ç‹¬å®éªŒæ‹Ÿåˆå®Œæˆ!")
            print(f"   â€¢ æˆåŠŸåˆ†æå®éªŒæ•°: {len(individual_models)}")
            print(f"   â€¢ è¯¦ç»†ç»“æœå·²ä¿å­˜: individual_experiment_models.csv")
            print(f"   â€¢ æ€§èƒ½å¯¹æ¯”å›¾: individual_model_performance_comparison.png")
    
    elif choice == "3":
        print("\nğŸ”¬ è¿è¡Œå®Œæ•´å¯¹æ¯”åˆ†æ...")
        # å…ˆè¿è¡Œç»¼åˆåˆ†æ
        results = analyzer.run_comprehensive_analysis()
        
        # å†è¿è¡Œå•ç‹¬å®éªŒæ‹Ÿåˆ
        print("\n" + "="*60)
        individual_models = analyzer.run_individual_regression_analysis()
        
        # å¯¹æ¯”æ€»ç»“
        if results and results['overall'] and individual_models:
            print("\nğŸ“ˆ æ‹Ÿåˆæ–¹å¼å¯¹æ¯”æ€»ç»“:")
            overall_models = results['overall']['models']
            
            print("\nğŸ” æ± åŒ–æ‹Ÿåˆ vs å•ç‹¬æ‹Ÿåˆå¯¹æ¯”:")
            for physio_param in ['systolic_bp_mean', 'diastolic_bp_mean', 'mean_bp_mean']:
                if physio_param in overall_models:
                    overall_mae = overall_models[physio_param]['mae']
                    overall_r2 = overall_models[physio_param]['r2_score']
                    overall_n = overall_models[physio_param]['n_samples']
                    
                    physio_label = analyzer._format_physio_label_en(physio_param)
                    print(f"\nğŸ“Š {physio_label}:")
                    print(f"   æ± åŒ–æ‹Ÿåˆ: RÂ²={overall_r2:.3f}, MAE={overall_mae:.2f}, N={overall_n}")
                    
                    # ç»Ÿè®¡å•ç‹¬å®éªŒçš„å¹³å‡æ€§èƒ½
                    individual_r2s = []
                    individual_maes = []
                    individual_ns = []
                    
                    for exp_key, exp_models in individual_models.items():
                        if physio_param in exp_models:
                            individual_r2s.append(exp_models[physio_param]['r2_score'])
                            individual_maes.append(exp_models[physio_param]['mae'])
                            individual_ns.append(exp_models[physio_param]['n_samples'])
                    
                    if individual_r2s:
                        avg_r2 = np.mean(individual_r2s)
                        avg_mae = np.mean(individual_maes)
                        total_n = sum(individual_ns)
                        print(f"   å•ç‹¬æ‹Ÿåˆ: RÂ²={avg_r2:.3f}Â±{np.std(individual_r2s):.3f}, MAE={avg_mae:.2f}Â±{np.std(individual_maes):.2f}, æ€»N={total_n}")
                        
                        # æ€§èƒ½æ¯”è¾ƒ
                        if overall_r2 > avg_r2:
                            print(f"   âœ… æ± åŒ–æ‹ŸåˆRÂ²æ›´ä¼˜ (+{overall_r2-avg_r2:.3f})")
                        else:
                            print(f"   âš ï¸  å•ç‹¬æ‹ŸåˆRÂ²æ›´ä¼˜ (+{avg_r2-overall_r2:.3f})")
                        
                        if overall_mae < avg_mae:
                            print(f"   âœ… æ± åŒ–æ‹ŸåˆMAEæ›´ä¼˜ (-{avg_mae-overall_mae:.2f})")
                        else:
                            print(f"   âš ï¸  å•ç‹¬æ‹ŸåˆMAEæ›´ä¼˜ (-{overall_mae-avg_mae:.2f})")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œç»¼åˆåˆ†æ")
        choice = "1"
        # é€’å½’è°ƒç”¨åŸå§‹åˆ†æ
        analyzer.run_comprehensive_analysis()
    
    print(f"\nâœ… åˆ†æå®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")

if __name__ == "__main__":
    main() 