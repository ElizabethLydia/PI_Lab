#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§PPG-ABPä¿¡å·åˆ†æè„šæœ¬
å¯ä»¥åˆ†æä¸åŒå®éªŒã€ä¸åŒä¿¡å·æ®µï¼Œå¹¶ä¸”å¯ä»¥è°ƒæ•´å‚æ•°
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import signal
from scipy.stats import pearsonr, spearmanr
from scipy.interpolate import interp1d
from sklearn.metrics import mutual_info_score
import pywt
from scipy.ndimage import grey_opening, grey_closing
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

class AdvancedPPGABPAnalyzer:
    def __init__(self, subject_id="00017"):
        """
        åˆå§‹åŒ–é«˜çº§åˆ†æå™¨
        
        Args:
            subject_id: å—è¯•è€…ID
        """
        self.subject_id = subject_id
        self.base_dir = f'/root/autodl-tmp/blood_pressure_reconstruction/{subject_id}/csv'
        
        # è·å–å¯ç”¨çš„å®éªŒåˆ—è¡¨
        self.available_experiments = self.get_available_experiments()
        
        print(f"ğŸ“‹ å—è¯•è€… {subject_id} å¯ç”¨å®éªŒ: {self.available_experiments}")
    
    def get_available_experiments(self):
        """è·å–å¯ç”¨çš„å®éªŒåˆ—è¡¨"""
        if not os.path.exists(self.base_dir):
            return []
        
        experiments = set()
        files = os.listdir(self.base_dir)
        
        for file in files:
            if file.endswith('_abp.csv'):
                parts = file.split('_')
                if len(parts) >= 2:
                    experiments.add(parts[1])
        
        return sorted(list(experiments))
    
    def analyze_experiment(self, experiment, segment_length=2000, start_idx=None, 
                          butterworth_params=(0.5, 8.0, 100, 4),
                          wavelet_params=('db4', 4),
                          morphological_params=(5,),
                          show_plots=True):
        """
        åˆ†æå•ä¸ªå®éªŒ
        
        Args:
            experiment: å®éªŒç¼–å·
            segment_length: ç»˜å›¾æ®µé•¿åº¦
            start_idx: å¼€å§‹ç´¢å¼•ï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©ï¼‰
            butterworth_params: (lowcut, highcut, fs, order)
            wavelet_params: (wavelet, level)
            morphological_params: (size,)
            show_plots: æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨
        """
        print(f"\n{'='*80}")
        print(f"ğŸ”¬ åˆ†æå®éªŒ {experiment}")
        print(f"{'='*80}")
        
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = PPGABPAnalyzer(self.subject_id, experiment)
        
        # è‡ªå®šä¹‰é¢„å¤„ç†å‚æ•°
        analyzer.butterworth_params = butterworth_params
        analyzer.wavelet_params = wavelet_params
        analyzer.morphological_params = morphological_params
        
        # è¿è¡Œåˆ†æ
        try:
            analyzer.run_complete_analysis(
                segment_length=segment_length,
                start_idx=start_idx
            )
            
            # è¿”å›åˆ†æç»“æœ
            return {
                'experiment': experiment,
                'analyzer': analyzer,
                'correlation_metrics': analyzer.correlation_metrics,
                'processed_signals': analyzer.processed_signals
            }
            
        except Exception as e:
            print(f"âŒ å®éªŒ {experiment} åˆ†æå¤±è´¥: {e}")
            return None
    
    def analyze_multiple_experiments(self, experiments=None, segment_length=2000, 
                                   start_idx=None, show_plots=True):
        """
        åˆ†æå¤šä¸ªå®éªŒ
        
        Args:
            experiments: å®éªŒåˆ—è¡¨ï¼ˆNoneè¡¨ç¤ºåˆ†ææ‰€æœ‰å®éªŒï¼‰
            segment_length: ç»˜å›¾æ®µé•¿åº¦
            start_idx: å¼€å§‹ç´¢å¼•
            show_plots: æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨
        """
        if experiments is None:
            experiments = self.available_experiments
        
        print(f"\nğŸš€ å¼€å§‹åˆ†æå¤šä¸ªå®éªŒ...")
        print(f"ğŸ“‹ ç›®æ ‡å®éªŒ: {experiments}")
        print(f"ğŸ“ ç»˜å›¾æ®µé•¿åº¦: {segment_length}")
        
        results = {}
        
        for exp in experiments:
            if exp in self.available_experiments:
                result = self.analyze_experiment(
                    experiment=exp,
                    segment_length=segment_length,
                    start_idx=start_idx,
                    show_plots=show_plots
                )
                if result:
                    results[exp] = result
            else:
                print(f"âš ï¸  å®éªŒ {exp} ä¸å¯ç”¨ï¼Œè·³è¿‡")
        
        return results
    
    def compare_experiments(self, experiments, segment_length=2000, start_idx=None):
        """
        æ¯”è¾ƒå¤šä¸ªå®éªŒçš„ç›¸å…³æ€§æŒ‡æ ‡
        """
        print(f"\nğŸ“Š æ¯”è¾ƒå¤šä¸ªå®éªŒçš„ç›¸å…³æ€§æŒ‡æ ‡...")
        
        # åˆ†ææ‰€æœ‰å®éªŒ
        results = self.analyze_multiple_experiments(
            experiments=experiments,
            segment_length=segment_length,
            start_idx=start_idx,
            show_plots=False  # ä¸æ˜¾ç¤ºå›¾è¡¨ï¼Œåªè®¡ç®—æŒ‡æ ‡
        )
        
        if not results:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„åˆ†æç»“æœ")
            return None
        
        # åˆ›å»ºæ¯”è¾ƒè¡¨æ ¼
        comparison_data = []
        
        for exp, result in results.items():
            metrics = result['correlation_metrics']
            
            for method_name, method_metrics in metrics.items():
                comparison_data.append({
                    'experiment': exp,
                    'method': method_name,
                    'pearson_r': method_metrics.get('pearson_r', np.nan),
                    'spearman_r': method_metrics.get('spearman_r', np.nan),
                    'mutual_info': method_metrics.get('mutual_info', np.nan),
                    'freq_correlation': method_metrics.get('freq_correlation', np.nan),
                    'coherence_mean': method_metrics.get('coherence_mean', np.nan),
                    'ppg_snr': method_metrics.get('ppg_snr', np.nan),
                    'abp_snr': method_metrics.get('abp_snr', np.nan)
                })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # ä¿å­˜æ¯”è¾ƒç»“æœ
        output_dir = f'/root/autodl-tmp/blood_pressure_reconstruction/{self.subject_id}/analysis_results'
        os.makedirs(output_dir, exist_ok=True)
        
        comparison_file = os.path.join(output_dir, f'{self.subject_id}_experiments_comparison.csv')
        comparison_df.to_csv(comparison_file, index=False, encoding='utf-8')
        print(f"ğŸ’¾ å®éªŒæ¯”è¾ƒç»“æœå·²ä¿å­˜: {comparison_file}")
        
        # æ˜¾ç¤ºæœ€ä½³ç»“æœ
        print(f"\nğŸ† æœ€ä½³ç›¸å…³æ€§ç»“æœ:")
        best_pearson = comparison_df.loc[comparison_df['pearson_r'].idxmax()]
        print(f"  Pearsonç›¸å…³ç³»æ•°æœ€é«˜: å®éªŒ{best_pearson['experiment']} - {best_pearson['method']} (r={best_pearson['pearson_r']:.4f})")
        
        best_spearman = comparison_df.loc[comparison_df['spearman_r'].idxmax()]
        print(f"  Spearmanç›¸å…³ç³»æ•°æœ€é«˜: å®éªŒ{best_spearman['experiment']} - {best_spearman['method']} (r={best_spearman['spearman_r']:.4f})")
        
        best_mutual_info = comparison_df.loc[comparison_df['mutual_info'].idxmax()]
        print(f"  äº’ä¿¡æ¯æœ€é«˜: å®éªŒ{best_mutual_info['experiment']} - {best_mutual_info['method']} (MI={best_mutual_info['mutual_info']:.4f})")
        
        return comparison_df
    
    def plot_experiment_comparison(self, comparison_df):
        """ç»˜åˆ¶å®éªŒæ¯”è¾ƒå›¾"""
        if comparison_df is None or comparison_df.empty:
            print("âŒ æ²¡æœ‰æ¯”è¾ƒæ•°æ®å¯ç»˜åˆ¶")
            return
        
        print(f"\nğŸ“Š ç»˜åˆ¶å®éªŒæ¯”è¾ƒå›¾...")
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. Pearsonç›¸å…³ç³»æ•°æ¯”è¾ƒ
        ax1 = axes[0, 0]
        sns.boxplot(data=comparison_df, x='method', y='pearson_r', ax=ax1)
        ax1.set_title('Pearsonç›¸å…³ç³»æ•°æ¯”è¾ƒ', fontweight='bold')
        ax1.set_xlabel('é¢„å¤„ç†æ–¹æ³•')
        ax1.set_ylabel('Pearsonç›¸å…³ç³»æ•°')
        ax1.tick_params(axis='x', rotation=45)
        
        # 2. Spearmanç›¸å…³ç³»æ•°æ¯”è¾ƒ
        ax2 = axes[0, 1]
        sns.boxplot(data=comparison_df, x='method', y='spearman_r', ax=ax2)
        ax2.set_title('Spearmanç›¸å…³ç³»æ•°æ¯”è¾ƒ', fontweight='bold')
        ax2.set_xlabel('é¢„å¤„ç†æ–¹æ³•')
        ax2.set_ylabel('Spearmanç›¸å…³ç³»æ•°')
        ax2.tick_params(axis='x', rotation=45)
        
        # 3. äº’ä¿¡æ¯æ¯”è¾ƒ
        ax3 = axes[1, 0]
        sns.boxplot(data=comparison_df, x='method', y='mutual_info', ax=ax3)
        ax3.set_title('äº’ä¿¡æ¯æ¯”è¾ƒ', fontweight='bold')
        ax3.set_xlabel('é¢„å¤„ç†æ–¹æ³•')
        ax3.set_ylabel('äº’ä¿¡æ¯')
        ax3.tick_params(axis='x', rotation=45)
        
        # 4. ä¿¡å™ªæ¯”æ¯”è¾ƒ
        ax4 = axes[1, 1]
        sns.boxplot(data=comparison_df, x='method', y='ppg_snr', ax=ax4)
        ax4.set_title('PPGä¿¡å™ªæ¯”æ¯”è¾ƒ', fontweight='bold')
        ax4.set_xlabel('é¢„å¤„ç†æ–¹æ³•')
        ax4.set_ylabel('PPGä¿¡å™ªæ¯” (dB)')
        ax4.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_dir = f'/root/autodl-tmp/blood_pressure_reconstruction/{self.subject_id}/analysis_results'
        os.makedirs(output_dir, exist_ok=True)
        
        plot_file = os.path.join(output_dir, f'{self.subject_id}_experiments_comparison.png')
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        print(f"  ğŸ’¾ å®éªŒæ¯”è¾ƒå›¾å·²ä¿å­˜: {plot_file}")
        
        plt.show()
        
        return fig

class PPGABPAnalyzer:
    def __init__(self, subject_id="00017", experiment="1"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            subject_id: å—è¯•è€…ID
            experiment: å®éªŒç¼–å·
        """
        self.subject_id = subject_id
        self.experiment = experiment
        self.base_dir = f'/root/autodl-tmp/blood_pressure_reconstruction/{subject_id}/csv'
        
        # æ•°æ®æ–‡ä»¶è·¯å¾„
        self.ppg_file = f'{subject_id}_{experiment}_sensor2.csv'
        self.abp_file = f'{subject_id}_{experiment}_abp.csv'
        
        # é»˜è®¤é¢„å¤„ç†å‚æ•°
        self.butterworth_params = (0.5, 8.0, 100, 4)
        self.wavelet_params = ('db4', 4)
        self.morphological_params = (5,)
        
        # åŠ è½½æ•°æ®
        self.ppg_data = None
        self.abp_data = None
        self.load_data()
        
        # é¢„å¤„ç†åçš„æ•°æ®
        self.processed_signals = {}
        
        # ç›¸å…³æ€§æŒ‡æ ‡
        self.correlation_metrics = {}
        
    def load_data(self):
        """åŠ è½½PPGå’ŒABPæ•°æ®"""
        print(f"ğŸ“– åŠ è½½æ•°æ®...")
        print(f"  PPGæ–‡ä»¶: {self.ppg_file}")
        print(f"  ABPæ–‡ä»¶: {self.abp_file}")
        
        try:
            # åŠ è½½PPGæ•°æ®
            ppg_path = os.path.join(self.base_dir, self.ppg_file)
            self.ppg_data = pd.read_csv(ppg_path)
            print(f"  âœ… PPGæ•°æ®åŠ è½½æˆåŠŸ: {len(self.ppg_data)} è¡Œ")
            
            # åŠ è½½ABPæ•°æ®
            abp_path = os.path.join(self.base_dir, self.abp_file)
            self.abp_data = pd.read_csv(abp_path)
            print(f"  âœ… ABPæ•°æ®åŠ è½½æˆåŠŸ: {len(self.abp_data)} è¡Œ")
            
            # æ£€æŸ¥æ•°æ®é•¿åº¦
            print(f"  ğŸ“Š æ•°æ®é•¿åº¦å¯¹æ¯”:")
            print(f"    PPG: {len(self.ppg_data)} è¡Œ")
            print(f"    ABP: {len(self.abp_data)} è¡Œ")
            
            # æ—¶é—´èŒƒå›´
            ppg_time_range = self.ppg_data['timestamp'].max() - self.ppg_data['timestamp'].min()
            abp_time_range = self.abp_data['timestamp'].max() - self.abp_data['timestamp'].min()
            print(f"  â±ï¸  æ—¶é—´èŒƒå›´:")
            print(f"    PPG: {ppg_time_range:.2f} ç§’")
            print(f"    ABP: {abp_time_range:.2f} ç§’")
            
        except Exception as e:
            print(f"  âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def align_signals(self):
        """å¯¹é½PPGå’ŒABPä¿¡å·åˆ°ç›¸åŒçš„æ—¶é—´æˆ³"""
        print(f"\nğŸ”„ å¯¹é½ä¿¡å·...")
        
        # ä½¿ç”¨PPGæ—¶é—´æˆ³ä½œä¸ºå‚è€ƒ
        ref_timestamps = self.ppg_data['timestamp'].values
        ppg_ir = self.ppg_data['ir'].values
        ppg_red = self.ppg_data['red'].values
        ppg_green = self.ppg_data['green'].values
        
        # æ’å€¼ABPæ•°æ®åˆ°PPGæ—¶é—´æˆ³
        abp_interpolated = np.interp(
            ref_timestamps, 
            self.abp_data['timestamp'].values, 
            self.abp_data['abp'].values
        )
        
        # åˆ›å»ºå¯¹é½åçš„æ•°æ®
        self.aligned_data = pd.DataFrame({
            'timestamp': ref_timestamps,
            'ppg_ir': ppg_ir,
            'ppg_red': ppg_red,
            'ppg_green': ppg_green,
            'abp': abp_interpolated
        })
        
        # æ·»åŠ åŠ é€Ÿåº¦æ•°æ®
        if 'ax' in self.ppg_data.columns:
            self.aligned_data['ax'] = np.interp(
                ref_timestamps,
                self.ppg_data['timestamp'].values,
                self.ppg_data['ax'].values
            )
            self.aligned_data['ay'] = np.interp(
                ref_timestamps,
                self.ppg_data['timestamp'].values,
                self.ppg_data['ay'].values
            )
            self.aligned_data['az'] = np.interp(
                ref_timestamps,
                self.ppg_data['timestamp'].values,
                self.ppg_data['az'].values
            )
        
        print(f"  âœ… ä¿¡å·å¯¹é½å®Œæˆ: {len(self.aligned_data)} è¡Œ")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        abp_nan_count = self.aligned_data['abp'].isna().sum()
        if abp_nan_count > 0:
            print(f"  âš ï¸  ABPæ•°æ®ä¸­æœ‰ {abp_nan_count} ä¸ªNaNå€¼")
        
        return self.aligned_data
    
    def butterworth_filter(self, signal_data):
        """Butterworthå¸¦é€šæ»¤æ³¢å™¨"""
        lowcut, highcut, fs, order = self.butterworth_params
        nyquist = fs / 2
        low = lowcut / nyquist
        high = highcut / nyquist
        b, a = signal.butter(order, [low, high], btype='band')
        filtered = signal.filtfilt(b, a, signal_data)
        return filtered
    
    def wavelet_denoising(self, signal_data):
        """å°æ³¢å»å™ª"""
        try:
            wavelet, level = self.wavelet_params
            # å°æ³¢åˆ†è§£
            coeffs = pywt.wavedec(signal_data, wavelet, level=level)
            
            # é˜ˆå€¼å¤„ç†
            threshold = np.std(coeffs[-1]) * np.sqrt(2 * np.log(len(signal_data)))
            coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]
            
            # å°æ³¢é‡æ„
            denoised = pywt.waverec(coeffs, wavelet)
            
            # ç¡®ä¿é•¿åº¦ä¸€è‡´
            if len(denoised) > len(signal_data):
                denoised = denoised[:len(signal_data)]
            elif len(denoised) < len(signal_data):
                denoised = np.pad(denoised, (0, len(signal_data) - len(denoised)), 'edge')
            
            return denoised
        except Exception as e:
            print(f"    å°æ³¢å»å™ªå¤±è´¥: {e}")
            return signal_data
    
    def morphological_filter(self, signal_data):
        """å½¢æ€å­¦æ»¤æ³¢"""
        try:
            size = self.morphological_params[0]
            # å¼€è¿ç®—ï¼ˆå…ˆè…èš€åè†¨èƒ€ï¼‰
            opened = grey_opening(signal_data, size=size)
            # é—­è¿ç®—ï¼ˆå…ˆè†¨èƒ€åè…èš€ï¼‰
            closed = grey_closing(opened, size=size)
            return closed
        except Exception as e:
            print(f"    å½¢æ€å­¦æ»¤æ³¢å¤±è´¥: {e}")
            return signal_data
    
    def remove_motion_artifacts(self, ppg_signal, acc_data):
        """ä½¿ç”¨åŠ é€Ÿåº¦æ•°æ®å»é™¤è¿åŠ¨ä¼ªå½±"""
        try:
            if acc_data is None or len(acc_data) == 0:
                return ppg_signal
            
            # è®¡ç®—åŠ é€Ÿåº¦å¹…åº¦
            acc_magnitude = np.sqrt(acc_data['ax']**2 + acc_data['ay']**2 + acc_data['az']**2)
            
            # è®¡ç®—åŠ é€Ÿåº¦é˜ˆå€¼ï¼ˆåŠ¨æ€é˜ˆå€¼ï¼‰
            acc_threshold = np.mean(acc_magnitude) + 2 * np.std(acc_magnitude)
            
            # åˆ›å»ºè¿åŠ¨æ©ç 
            motion_mask = acc_magnitude > acc_threshold
            
            # å¯¹è¿åŠ¨æ®µè¿›è¡Œæ’å€¼
            ppg_cleaned = ppg_signal.copy()
            if np.any(motion_mask):
                # æ‰¾åˆ°éè¿åŠ¨æ®µçš„ç´¢å¼•
                non_motion_indices = np.where(~motion_mask)[0]
                motion_indices = np.where(motion_mask)[0]
                
                if len(non_motion_indices) > 0:
                    # ä½¿ç”¨éè¿åŠ¨æ®µçš„å€¼æ’å€¼è¿åŠ¨æ®µ
                    ppg_cleaned[motion_indices] = np.interp(
                        motion_indices, 
                        non_motion_indices, 
                        ppg_signal[non_motion_indices]
                    )
            
            return ppg_cleaned
        except Exception as e:
            print(f"    è¿åŠ¨ä¼ªå½±å»é™¤å¤±è´¥: {e}")
            return ppg_signal
    
    def apply_preprocessing_methods(self):
        """åº”ç”¨å¤šç§é¢„å¤„ç†æ–¹æ³•"""
        print(f"\nğŸ”§ åº”ç”¨é¢„å¤„ç†æ–¹æ³•...")
        
        # è·å–å¯¹é½åçš„æ•°æ®
        if not hasattr(self, 'aligned_data'):
            self.align_signals()
        
        # æå–ä¿¡å·
        ppg_ir = self.aligned_data['ppg_ir'].values
        abp = self.aligned_data['abp'].values
        
        # 1. åŸå§‹ä¿¡å·
        self.processed_signals['åŸå§‹ä¿¡å·'] = {
            'ppg': ppg_ir,
            'abp': abp
        }
        
        # 2. Butterworthæ»¤æ³¢
        print(f"  ğŸ”§ Butterworthæ»¤æ³¢...")
        ppg_butter = self.butterworth_filter(ppg_ir)
        self.processed_signals['Butterworthæ»¤æ³¢'] = {
            'ppg': ppg_butter,
            'abp': abp
        }
        
        # 3. å°æ³¢å»å™ª
        print(f"  ğŸ”§ å°æ³¢å»å™ª...")
        ppg_wavelet = self.wavelet_denoising(ppg_ir)
        self.processed_signals['å°æ³¢å»å™ª'] = {
            'ppg': ppg_wavelet,
            'abp': abp
        }
        
        # 4. å½¢æ€å­¦æ»¤æ³¢
        print(f"  ğŸ”§ å½¢æ€å­¦æ»¤æ³¢...")
        ppg_morph = self.morphological_filter(ppg_ir)
        self.processed_signals['å½¢æ€å­¦æ»¤æ³¢'] = {
            'ppg': ppg_morph,
            'abp': abp
        }
        
        # 5. ç»„åˆæ»¤æ³¢ï¼ˆButterworth + å°æ³¢ï¼‰
        print(f"  ğŸ”§ ç»„åˆæ»¤æ³¢...")
        ppg_combined = self.butterworth_filter(ppg_wavelet)
        self.processed_signals['ç»„åˆæ»¤æ³¢'] = {
            'ppg': ppg_combined,
            'abp': abp
        }
        
        # 6. è¿åŠ¨ä¼ªå½±å»é™¤
        if 'ax' in self.aligned_data.columns:
            print(f"  ğŸ”§ è¿åŠ¨ä¼ªå½±å»é™¤...")
            acc_data = self.aligned_data[['ax', 'ay', 'az']]
            ppg_motion_removed = self.remove_motion_artifacts(ppg_ir, acc_data)
            self.processed_signals['è¿åŠ¨ä¼ªå½±å»é™¤'] = {
                'ppg': ppg_motion_removed,
                'abp': abp
            }
        
        print(f"  âœ… é¢„å¤„ç†å®Œæˆï¼Œå…± {len(self.processed_signals)} ç§æ–¹æ³•")
        
        return self.processed_signals
    
    def calculate_correlation_metrics(self):
        """è®¡ç®—å„ç§ç›¸å…³æ€§æŒ‡æ ‡"""
        print(f"\nğŸ“Š è®¡ç®—ç›¸å…³æ€§æŒ‡æ ‡...")
        
        for method_name, signals in self.processed_signals.items():
            ppg = signals['ppg']
            abp = signals['abp']
            
            # å»é™¤NaNå€¼
            valid_mask = ~(np.isnan(ppg) | np.isnan(abp))
            if np.sum(valid_mask) < 10:  # è‡³å°‘éœ€è¦10ä¸ªæœ‰æ•ˆç‚¹
                continue
            
            ppg_valid = ppg[valid_mask]
            abp_valid = abp[valid_mask]
            
            metrics = {}
            
            try:
                # 1. Pearsonç›¸å…³ç³»æ•°
                pearson_r, pearson_p = pearsonr(ppg_valid, abp_valid)
                metrics['pearson_r'] = pearson_r
                metrics['pearson_p'] = pearson_p
                
                # 2. Spearmanç›¸å…³ç³»æ•°
                spearman_r, spearman_p = spearmanr(ppg_valid, abp_valid)
                metrics['spearman_r'] = spearman_r
                metrics['spearman_p'] = spearman_p
                
                # 3. äº’ä¿¡æ¯
                # å°†è¿ç»­å€¼åˆ†ç®±ä»¥è®¡ç®—äº’ä¿¡æ¯
                ppg_binned = pd.cut(ppg_valid, bins=20, labels=False)
                abp_binned = pd.cut(abp_valid, bins=20, labels=False)
                mutual_info = mutual_info_score(ppg_binned, abp_binned)
                metrics['mutual_info'] = mutual_info
                
                # 4. é¢‘ç‡åŸŸç›¸å…³æ€§
                ppg_fft = np.abs(np.fft.fft(ppg_valid))
                abp_fft = np.abs(np.fft.fft(abp_valid))
                freq_corr, _ = pearsonr(ppg_fft, abp_fft)
                metrics['freq_correlation'] = freq_corr
                
                # 5. ç›¸å¹²æ€§
                if len(ppg_valid) > 100:
                    f, coh = signal.coherence(ppg_valid, abp_valid, fs=100)
                    metrics['coherence_mean'] = np.mean(coh)
                    metrics['coherence_max'] = np.max(coh)
                else:
                    metrics['coherence_mean'] = np.nan
                    metrics['coherence_max'] = np.nan
                
                # 6. ä¿¡å·è´¨é‡æŒ‡æ ‡
                ppg_snr = self.calculate_snr(ppg_valid)
                abp_snr = self.calculate_snr(abp_valid)
                metrics['ppg_snr'] = ppg_snr
                metrics['abp_snr'] = abp_snr
                
                self.correlation_metrics[method_name] = metrics
                
            except Exception as e:
                print(f"    âŒ {method_name} ç›¸å…³æ€§è®¡ç®—å¤±è´¥: {e}")
                continue
        
        print(f"  âœ… ç›¸å…³æ€§è®¡ç®—å®Œæˆï¼Œå…± {len(self.correlation_metrics)} ç§æ–¹æ³•")
        return self.correlation_metrics
    
    def calculate_snr(self, signal_data):
        """è®¡ç®—ä¿¡å™ªæ¯”"""
        try:
            # ä½¿ç”¨FFTè®¡ç®—ä¿¡å™ªæ¯”
            fft = np.fft.fft(signal_data)
            power = np.abs(fft)**2
            
            # å‡è®¾ä½é¢‘éƒ¨åˆ†æ˜¯ä¿¡å·ï¼Œé«˜é¢‘éƒ¨åˆ†æ˜¯å™ªå£°
            mid_freq = len(power) // 2
            signal_power = np.mean(power[:mid_freq])
            noise_power = np.mean(power[mid_freq:])
            
            if noise_power > 0:
                snr = 10 * np.log10(signal_power / noise_power)
                return snr
            else:
                return np.nan
        except:
            return np.nan
    
    def plot_signals_comparison(self, segment_length=1000, start_idx=None):
        """ç»˜åˆ¶ä¿¡å·å¯¹æ¯”å›¾"""
        print(f"\nğŸ“Š ç»˜åˆ¶ä¿¡å·å¯¹æ¯”å›¾...")
        
        if not self.processed_signals:
            self.apply_preprocessing_methods()
        
        if not self.correlation_metrics:
            self.calculate_correlation_metrics()
        
        # ç¡®å®šç»˜å›¾æ®µ
        total_length = len(self.aligned_data)
        if start_idx is None:
            start_idx = total_length // 4  # ä»1/4å¤„å¼€å§‹
        
        end_idx = min(start_idx + segment_length, total_length)
        
        print(f"  ğŸ“ ç»˜å›¾æ®µ: {start_idx} - {end_idx} (å…± {end_idx - start_idx} ä¸ªç‚¹)")
        
        # åˆ›å»ºå­å›¾
        n_methods = len(self.processed_signals)
        fig, axes = plt.subplots(n_methods, 2, figsize=(20, 4*n_methods))
        
        if n_methods == 1:
            axes = axes.reshape(1, -1)
        
        # æ—¶é—´è½´
        time_segment = self.aligned_data['timestamp'].iloc[start_idx:end_idx]
        time_relative = time_segment - time_segment.iloc[0]
        
        # ç»˜åˆ¶æ¯ç§é¢„å¤„ç†æ–¹æ³•çš„ç»“æœ
        for i, (method_name, signals) in enumerate(self.processed_signals.items()):
            ppg = signals['ppg'][start_idx:end_idx]
            abp = signals['abp'][start_idx:end_idx]
            
            # è·å–ç›¸å…³æ€§æŒ‡æ ‡
            metrics = self.correlation_metrics.get(method_name, {})
            
            # PPGä¿¡å·
            ax1 = axes[i, 0]
            ax1.plot(time_relative, ppg, 'b-', linewidth=1, alpha=0.8, label='PPG (IR)')
            ax1.set_title(f'{method_name} - PPGä¿¡å·', fontsize=12, fontweight='bold')
            ax1.set_xlabel('æ—¶é—´ (ç§’)')
            ax1.set_ylabel('PPGå€¼')
            ax1.grid(True, alpha=0.3)
            ax1.legend()
            
            # æ·»åŠ ç›¸å…³æ€§ä¿¡æ¯
            if metrics:
                corr_text = f"Pearson r: {metrics.get('pearson_r', 'N/A'):.3f}\n"
                corr_text += f"Spearman r: {metrics.get('spearman_r', 'N/A'):.3f}\n"
                corr_text += f"äº’ä¿¡æ¯: {metrics.get('mutual_info', 'N/A'):.3f}"
                ax1.text(0.02, 0.98, corr_text, transform=ax1.transAxes, 
                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            
            # ABPä¿¡å·
            ax2 = axes[i, 1]
            ax2.plot(time_relative, abp, 'r-', linewidth=1, alpha=0.8, label='ABP')
            ax2.set_title(f'{method_name} - ABPä¿¡å·', fontsize=12, fontweight='bold')
            ax2.set_xlabel('æ—¶é—´ (ç§’)')
            ax2.set_ylabel('è¡€å‹ (mmHg)')
            ax2.grid(True, alpha=0.3)
            ax2.legend()
            
            # æ·»åŠ ä¿¡å·è´¨é‡ä¿¡æ¯
            if metrics:
                quality_text = f"PPG SNR: {metrics.get('ppg_snr', 'N/A'):.1f} dB\n"
                quality_text += f"ABP SNR: {metrics.get('abp_snr', 'N/A'):.1f} dB\n"
                quality_text += f"é¢‘ç‡ç›¸å…³æ€§: {metrics.get('freq_correlation', 'N/A'):.3f}"
                ax2.text(0.02, 0.98, quality_text, transform=ax2.transAxes, 
                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_dir = f'/root/autodl-tmp/blood_pressure_reconstruction/{self.subject_id}/analysis_results'
        os.makedirs(output_dir, exist_ok=True)
        
        plot_file = os.path.join(output_dir, f'{self.subject_id}_{self.experiment}_signals_comparison.png')
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        print(f"  ğŸ’¾ ä¿¡å·å¯¹æ¯”å›¾å·²ä¿å­˜: {plot_file}")
        
        plt.show()
        
        return fig
    
    def plot_correlation_heatmap(self):
        """ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾"""
        print(f"\nğŸ“Š ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾...")
        
        if not self.correlation_metrics:
            self.calculate_correlation_metrics()
        
        # å‡†å¤‡æ•°æ®
        methods = list(self.correlation_metrics.keys())
        metrics_names = ['pearson_r', 'spearman_r', 'mutual_info', 'freq_correlation', 'coherence_mean']
        
        # åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = np.zeros((len(methods), len(metrics_names)))
        
        for i, method in enumerate(methods):
            for j, metric in enumerate(metrics_names):
                corr_matrix[i, j] = self.correlation_metrics[method].get(metric, np.nan)
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ä½¿ç”¨seabornç»˜åˆ¶çƒ­åŠ›å›¾
        sns.heatmap(corr_matrix, 
                   xticklabels=metrics_names, 
                   yticklabels=methods,
                   annot=True, 
                   fmt='.3f', 
                   cmap='RdYlBu_r',
                   center=0,
                   ax=ax)
        
        ax.set_title(f'å—è¯•è€…{self.subject_id} å®éªŒ{self.experiment} - ç›¸å…³æ€§æŒ‡æ ‡çƒ­åŠ›å›¾', 
                    fontsize=14, fontweight='bold')
        ax.set_xlabel('ç›¸å…³æ€§æŒ‡æ ‡', fontsize=12)
        ax.set_ylabel('é¢„å¤„ç†æ–¹æ³•', fontsize=12)
        
        # æ—‹è½¬xè½´æ ‡ç­¾
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_dir = f'/root/autodl-tmp/blood_pressure_reconstruction/{self.subject_id}/analysis_results'
        os.makedirs(output_dir, exist_ok=True)
        
        heatmap_file = os.path.join(output_dir, f'{self.subject_id}_{self.experiment}_correlation_heatmap.png')
        plt.savefig(heatmap_file, dpi=300, bbox_inches='tight')
        print(f"  ğŸ’¾ ç›¸å…³æ€§çƒ­åŠ›å›¾å·²ä¿å­˜: {heatmap_file}")
        
        plt.show()
        
        return fig
    
    def generate_summary_report(self):
        """ç”Ÿæˆåˆ†ææ€»ç»“æŠ¥å‘Š"""
        print(f"\nğŸ“ ç”Ÿæˆåˆ†ææ€»ç»“æŠ¥å‘Š...")
        
        if not self.correlation_metrics:
            self.calculate_correlation_metrics()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = f'/root/autodl-tmp/blood_pressure_reconstruction/{self.subject_id}/analysis_results'
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_file = os.path.join(output_dir, f'{self.subject_id}_{self.experiment}_analysis_report.txt')
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"PPG-ABPä¿¡å·åˆ†ææŠ¥å‘Š\n")
            f.write("="*50 + "\n\n")
            f.write(f"å—è¯•è€…ID: {self.subject_id}\n")
            f.write(f"å®éªŒç¼–å·: {self.experiment}\n")
            f.write(f"åˆ†ææ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("é¢„å¤„ç†å‚æ•°:\n")
            f.write("-"*20 + "\n")
            f.write(f"Butterworthæ»¤æ³¢: ä½æˆªæ­¢={self.butterworth_params[0]}Hz, é«˜æˆªæ­¢={self.butterworth_params[1]}Hz, é‡‡æ ·ç‡={self.butterworth_params[2]}Hz, é˜¶æ•°={self.butterworth_params[3]}\n")
            f.write(f"å°æ³¢å»å™ª: å°æ³¢={self.wavelet_params[0]}, åˆ†è§£å±‚æ•°={self.wavelet_params[1]}\n")
            f.write(f"å½¢æ€å­¦æ»¤æ³¢: ç»“æ„å…ƒç´ å¤§å°={self.morphological_params[0]}\n\n")
            
            f.write("æ•°æ®æ¦‚è§ˆ:\n")
            f.write("-"*20 + "\n")
            f.write(f"PPGæ•°æ®é•¿åº¦: {len(self.aligned_data)} è¡Œ\n")
            f.write(f"æ—¶é—´èŒƒå›´: {self.aligned_data['timestamp'].max() - self.aligned_data['timestamp'].min():.2f} ç§’\n")
            f.write(f"é‡‡æ ·é¢‘ç‡: çº¦ {len(self.aligned_data) / (self.aligned_data['timestamp'].max() - self.aligned_data['timestamp'].min()):.1f} Hz\n\n")
            
            f.write("ç›¸å…³æ€§åˆ†æç»“æœ:\n")
            f.write("-"*30 + "\n")
            
            # æŒ‰Pearsonç›¸å…³ç³»æ•°æ’åº
            sorted_methods = sorted(
                self.correlation_metrics.items(),
                key=lambda x: x[1].get('pearson_r', -1),
                reverse=True
            )
            
            for method_name, metrics in sorted_methods:
                f.write(f"\n{method_name}:\n")
                f.write(f"  Pearsonç›¸å…³ç³»æ•°: {metrics.get('pearson_r', 'N/A'):.4f}\n")
                f.write(f"  Spearmanç›¸å…³ç³»æ•°: {metrics.get('spearman_r', 'N/A'):.4f}\n")
                f.write(f"  äº’ä¿¡æ¯: {metrics.get('mutual_info', 'N/A'):.4f}\n")
                f.write(f"  é¢‘ç‡ç›¸å…³æ€§: {metrics.get('freq_correlation', 'N/A'):.4f}\n")
                f.write(f"  å¹³å‡ç›¸å¹²æ€§: {metrics.get('coherence_mean', 'N/A'):.4f}\n")
                f.write(f"  PPGä¿¡å™ªæ¯”: {metrics.get('ppg_snr', 'N/A'):.1f} dB\n")
                f.write(f"  ABPä¿¡å™ªæ¯”: {metrics.get('abp_snr', 'N/A'):.4f} dB\n")
            
            f.write(f"\næœ€ä½³é¢„å¤„ç†æ–¹æ³•:\n")
            f.write("-"*25 + "\n")
            best_method = sorted_methods[0][0]
            best_pearson = sorted_methods[0][1].get('pearson_r', 0)
            f.write(f"æ–¹æ³•: {best_method}\n")
            f.write(f"Pearsonç›¸å…³ç³»æ•°: {best_pearson:.4f}\n")
            
            if best_pearson > 0.9:
                f.write("è¯„ä»·: ç›¸å…³æ€§æå¼º (r > 0.9)\n")
            elif best_pearson > 0.7:
                f.write("è¯„ä»·: ç›¸å…³æ€§å¼º (r > 0.7)\n")
            elif best_pearson > 0.5:
                f.write("è¯„ä»·: ç›¸å…³æ€§ä¸­ç­‰ (r > 0.5)\n")
            else:
                f.write("è¯„ä»·: ç›¸å…³æ€§è¾ƒå¼± (r < 0.5)\n")
            
            f.write(f"\nè¾“å‡ºæ–‡ä»¶:\n")
            f.write("-"*15 + "\n")
            f.write(f"ä¿¡å·å¯¹æ¯”å›¾: {self.subject_id}_{self.experiment}_signals_comparison.png\n")
            f.write(f"ç›¸å…³æ€§çƒ­åŠ›å›¾: {self.subject_id}_{self.experiment}_correlation_heatmap.png\n")
            f.write(f"åˆ†ææŠ¥å‘Š: {self.subject_id}_{self.experiment}_analysis_report.txt\n")
        
        print(f"  ğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report_file
    
    def run_complete_analysis(self, segment_length=1000, start_idx=None):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print(f"\nğŸš€ å¼€å§‹å®Œæ•´åˆ†ææµç¨‹...")
        print(f"{'='*60}")
        
        try:
            # 1. åº”ç”¨é¢„å¤„ç†æ–¹æ³•
            self.apply_preprocessing_methods()
            
            # 2. è®¡ç®—ç›¸å…³æ€§æŒ‡æ ‡
            self.calculate_correlation_metrics()
            
            # 3. ç»˜åˆ¶ä¿¡å·å¯¹æ¯”å›¾
            self.plot_signals_comparison(segment_length, start_idx)
            
            # 4. ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾
            self.plot_correlation_heatmap()
            
            # 5. ç”Ÿæˆåˆ†ææŠ¥å‘Š
            self.generate_summary_report()
            
            print(f"\nğŸ‰ å®Œæ•´åˆ†ææµç¨‹å®Œæˆï¼")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: /root/autodl-tmp/blood_pressure_reconstruction/{self.subject_id}/analysis_results/")
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é«˜çº§PPG-ABPä¿¡å·åˆ†æç³»ç»Ÿ")
    print("="*60)
    
    # åˆ›å»ºé«˜çº§åˆ†æå™¨
    analyzer = AdvancedPPGABPAnalyzer(subject_id="00017")
    
    # ç¤ºä¾‹1: åˆ†æå•ä¸ªå®éªŒï¼Œä½¿ç”¨è‡ªå®šä¹‰å‚æ•°
    print(f"\nğŸ”¬ ç¤ºä¾‹1: åˆ†æå®éªŒ1ï¼Œä½¿ç”¨è‡ªå®šä¹‰å‚æ•°")
    custom_analyzer = PPGABPAnalyzer(subject_id="00017", experiment="1")
    
    # è‡ªå®šä¹‰é¢„å¤„ç†å‚æ•°
    custom_analyzer.butterworth_params = (0.3, 10.0, 100, 6)  # æ›´å®½çš„é¢‘å¸¦ï¼Œæ›´é«˜é˜¶æ•°
    custom_analyzer.wavelet_params = ('db6', 6)  # ä¸åŒçš„å°æ³¢å’Œåˆ†è§£å±‚æ•°
    custom_analyzer.morphological_params = (7,)  # æ›´å¤§çš„ç»“æ„å…ƒç´ 
    
    # è¿è¡Œåˆ†æ
    custom_analyzer.run_complete_analysis(segment_length=1500, start_idx=20000)
    
    # ç¤ºä¾‹2: æ¯”è¾ƒå¤šä¸ªå®éªŒ
    print(f"\nğŸ”¬ ç¤ºä¾‹2: æ¯”è¾ƒå¤šä¸ªå®éªŒçš„ç›¸å…³æ€§")
    comparison_df = analyzer.compare_experiments(
        experiments=['1', '2', '3'],  # æ¯”è¾ƒå‰3ä¸ªå®éªŒ
        segment_length=1000,
        start_idx=None
    )
    
    # ç»˜åˆ¶æ¯”è¾ƒå›¾
    if comparison_df is not None:
        analyzer.plot_experiment_comparison(comparison_df)

if __name__ == "__main__":
    main()
