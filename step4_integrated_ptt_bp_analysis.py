#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 4: Integrated PTT-BP Analysis
Uses results from step3 for further analysis: bar charts, integrated views, etc.
åŸºäºæä¾›çš„ç›®å½•ç»“æ„ï¼ˆæ¯ä¸ªå—è¯•è€…å¦‚ /root/autodl-tmp/00003 æœ‰ ptt_bp_analysis/ ç­‰å­ç›®å½•ï¼‰ï¼Œ
è„šæœ¬ä»æ¯ä¸ªå—è¯•è€…çš„ ptt_bp_analysis/ åŠ è½½ step3 æ–‡ä»¶ï¼Œè¿›è¡Œè·¨å—è¯•è€…åˆ†æã€‚
è¾“å‡ºä¿å­˜åˆ° /root/autodl-tmp/integrated_analysis ï¼ˆå…¨å±€ç›®å½•ï¼‰ã€‚
"""

import os
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.ioff()

class IntegratedPTTBloodPressureAnalyzer:
    def __init__(self, root_path="/root/autodl-tmp/", output_dir="integrated_analysis"):
        self.root_path = root_path
        self.output_dir = os.path.join(root_path, output_dir)
        self.step3_dir = "ptt_bp_analysis"  # step3 è¾“å‡ºç›®å½•ï¼ˆæ¯ä¸ªå—è¯•è€…ä¸‹ï¼‰
        os.makedirs(self.output_dir, exist_ok=True)
        
        self.physiological_indicators = {
            'systolic_bp': 'Systolic BP (mmHg)',
            'diastolic_bp': 'Diastolic BP (mmHg)', 
            'mean_bp': 'Mean Arterial Pressure (mmHg)',
            'bp': 'Continuous BP (mmHg)',
            'cardiac_output': 'Cardiac Output (L/min)',
            'cardiac_index': 'Cardiac Index (L/min/mÂ²)',
            'hr': 'Heart Rate (bpm)',
            'systemic_vascular_resistance': 'Systemic Vascular Resistance (dynÂ·s/cmâµ)',
            'rsp': 'Respiration Rate (breaths/min)'
        }
        
        self.ptt_combinations_en = {
            'sensor2-sensor3': 'Noseâ†’Finger',
            'sensor2-sensor4': 'Noseâ†’Wrist', 
            'sensor2-sensor5': 'Noseâ†’Ear',
            'sensor3-sensor4': 'Fingerâ†’Wrist',
            'sensor3-sensor5': 'Fingerâ†’Ear',
            'sensor4-sensor5': 'Wristâ†’Ear'
        }
        
        print("ğŸ”¬ Integrated PTT-Cardiovascular Parameters Correlation Analyzer")
        print(f"ğŸ“ Results will be saved to: {self.output_dir}")
        print(f"ğŸ“‚ Loading from each subject's {self.step3_dir}/")
    
    def load_subjects(self):
        """åŠ è½½æ‰€æœ‰å—è¯•è€…ï¼ˆç›®å½•ä»¥ '00' å¼€å¤´ï¼‰"""
        return sorted([d for d in os.listdir(self.root_path) 
                       if os.path.isdir(os.path.join(self.root_path, d)) and d.startswith('00')])
    
    def load_step3_correlations(self, subject, exp_id=None):
        """ä»å—è¯•è€…çš„ ptt_bp_analysis/ åŠ è½½ correlations CSV"""
        print(f"ğŸ“‚ åŠ è½½ {subject} çš„ correlations CSV")
        subject_dir = os.path.join(self.root_path, subject, self.step3_dir)
        if exp_id is not None:
            corr_file = os.path.join(subject_dir, f'ptt_cardiovascular_correlations_exp_{exp_id}.csv')
        else:
            corr_file = os.path.join(subject_dir, 'ptt_cardiovascular_correlations.csv')
        if not os.path.exists(corr_file):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {corr_file}")
            return None
        try:
            df = pd.read_csv(corr_file)
            if df.empty:
                print(f"âš ï¸ ç©ºæ–‡ä»¶: {corr_file}")
                return None
            df['subject'] = subject
            return df
        except pd.errors.EmptyDataError:
            print(f"âš ï¸ ç©ºæ•°æ®é”™è¯¯: {corr_file}")
            return None
        except Exception as e:
            print(f"âŒ åŠ è½½é”™è¯¯ {subject} exp_{exp_id}: {e}")
            return None
    
    def load_step3_sync_data(self, subject, exp_id=None):
        """ä»å—è¯•è€…çš„ ptt_bp_analysis/ åŠ è½½ sync æ•°æ® CSV (always load overall file)"""
        print(f"ğŸ“‚ åŠ è½½ {subject} çš„ sync æ•°æ®")
        subject_dir = os.path.join(self.root_path, subject, self.step3_dir)
        sync_file = os.path.join(subject_dir, 'synchronized_ptt_cardiovascular_data.csv')
        if not os.path.exists(sync_file):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {sync_file}")
            return None
        try:
            df = pd.read_csv(sync_file)
            if df.empty:
                print(f"âš ï¸ ç©ºæ–‡ä»¶: {sync_file}")
                return None
            df['subject'] = subject
            return df
        except pd.errors.EmptyDataError:
            print(f"âš ï¸ ç©ºæ•°æ®é”™è¯¯: {sync_file}")
            return None
        except Exception as e:
            print(f"âŒ åŠ è½½é”™è¯¯ {subject}: {e}")
            return None
    
    def create_correlation_bar_chart(self, corr_df, title_suffix, subjects, exp_id=None):
        """åˆ›å»ºç›¸å…³æ€§æŸ±çŠ¶å›¾ï¼ˆä¸¤ç§ç‰ˆæœ¬ï¼šmulti-pair ä¸€å¼ å›¾ + per pair å•ç‹¬å›¾ï¼‰"""
        valid_sensors = list(self.ptt_combinations_en.values())
        for physio, physio_label in self.physiological_indicators.items():
            physio_col = f'{physio}_mean'
            data = []
            for subject in subjects:
                subj_df = corr_df[corr_df['subject'] == subject]
                for _, row in subj_df.iterrows():
                    sensor_label = row['sensor_combination']
                    if sensor_label in valid_sensors and row['physiological_parameter'] == physio_col:
                        data.append({
                            'subject': subject,
                            'sensor_pair': sensor_label,
                            'correlation': row['correlation_coefficient'],
                            'p_value': row.get('p_value', 1.0),  # Assume p_value in data
                            'significant': row.get('p_value', 1.0) < 0.05
                        })
            if not data:
                continue
            df = pd.DataFrame(data)
            n_subjects = len(df['subject'].unique())
            if n_subjects == 0:
                continue
            
            subdir = os.path.join(self.output_dir, f'exp_{exp_id}' if exp_id else 'overall')
            os.makedirs(subdir, exist_ok=True)
            
            # ç‰ˆæœ¬1: ä¸€å¼ å›¾æ‰€æœ‰6ä¸ª pair
            fig_width = max(12, n_subjects * 0.5)
            plt.figure(figsize=(fig_width, 8))
            ax = sns.barplot(data=df, x='subject', y='correlation', hue='sensor_pair', palette='tab10')
            lines = [(0.4, 'green'), (-0.4, 'green'), (0.5, 'blue'), (-0.5, 'blue'), (0.7, 'red'), (-0.7, 'red')]
            for val, color in lines:
                plt.axhline(val, color=color, linestyle='--')
            # Add significance asterisks
            for i, bar in enumerate(ax.patches):
                if i < len(df) and df.iloc[i]['significant']:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01 if bar.get_height() > 0 else bar.get_height() - 0.05,
                            '*', ha='center', va='bottom' if bar.get_height() > 0 else 'top')
            plt.title(f'Correlation Bar Chart for {physio_label} (All Pairs) {title_suffix}')
            plt.ylim(-1, 1)
            plt.xlabel('Subject')
            plt.ylabel('Pearson Correlation')
            plt.xticks(rotation=90, ha='right')
            plt.legend(title='Sensor Pair', bbox_to_anchor=(1.05, 1), loc='upper left')
            filename_multi = f'correlation_bar_{physio}_multi{("_exp" + str(exp_id) if exp_id else "")}.png'
            plt.savefig(os.path.join(subdir, filename_multi), bbox_inches='tight')
            plt.close()
            print(f"ğŸ’¾ ä¿å­˜ multi-pair æŸ±çŠ¶å›¾: {os.path.join(subdir, filename_multi)}")
            
            # ç‰ˆæœ¬2: æ¯ä¸ª pair å•ç‹¬ä¸€å¼ å›¾
            for pair_label in valid_sensors:
                pair_data = [d for d in data if d['sensor_pair'] == pair_label]
                if not pair_data:
                    continue
                pair_df = pd.DataFrame(pair_data)
                fig_width = max(12, len(pair_df) * 0.5)
                plt.figure(figsize=(fig_width, 8))
                ax = sns.barplot(data=pair_df, x='subject', y='correlation', color='skyblue')
                for val, color in lines:
                    plt.axhline(val, color=color, linestyle='--')
                # Add significance asterisks
                for i, bar in enumerate(ax.patches):
                    if pair_df.iloc[i]['significant']:
                        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01 if bar.get_height() > 0 else bar.get_height() - 0.05,
                                '*', ha='center', va='bottom' if bar.get_height() > 0 else 'top')
                plt.title(f'Correlation Bar Chart for {physio_label} - {pair_label} {title_suffix}')
                plt.ylim(-1, 1)
                plt.xlabel('Subject')
                plt.ylabel('Pearson Correlation')
                plt.xticks(rotation=90, ha='right')
                safe_pair = pair_label.replace('â†’', '-').replace(' ', '_')
                filename = f'correlation_bar_{physio}_{safe_pair}{("_exp" + str(exp_id) if exp_id else "")}.png'
                plt.savefig(os.path.join(subdir, filename), bbox_inches='tight')
                plt.close()
                print(f"ğŸ’¾ ä¿å­˜ per-pair æŸ±çŠ¶å›¾: {os.path.join(subdir, filename)}")
    
    def create_r_distribution_plot(self, corr_df, title_suffix, subjects, exp_id=None):
        """ç»˜åˆ¶ r çš„åˆ†å¸ƒå›¾ (violin plot with gradient)"""
        valid_sensors = list(self.ptt_combinations_en.values())
        for physio, physio_label in self.physiological_indicators.items():
            data = []
            for subject in subjects:
                subj_df = corr_df[corr_df['subject'] == subject]
                for _, row in subj_df.iterrows():
                    sensor_label = row['sensor_combination']
                    if sensor_label in valid_sensors:
                        data.append({
                            'sensor_pair': sensor_label,
                            'correlation': row['correlation_coefficient']
                        })
            if not data:
                continue
            df = pd.DataFrame(data)
            subdir = os.path.join(self.output_dir, f'exp_{exp_id}' if exp_id else 'overall')
            os.makedirs(subdir, exist_ok=True)
            plt.figure(figsize=(12, 8))
            sns.violinplot(data=df, x='sensor_pair', y='correlation', palette='viridis', inner='box')
            plt.title(f'Distribution of Correlations for {physio_label} {title_suffix}')
            plt.ylim(-1, 1)
            plt.xlabel('Sensor Pair')
            plt.ylabel('Pearson Correlation')
            plt.xticks(rotation=45, ha='right')
            filename = f'r_distribution_{physio}{("_exp" + str(exp_id) if exp_id else "")}.png'
            plt.savefig(os.path.join(subdir, filename), bbox_inches='tight')
            plt.close()
            print(f"ğŸ’¾ ä¿å­˜ r åˆ†å¸ƒå›¾: {os.path.join(subdir, filename)}")
    
    def remove_outliers_iqr(self, data_series):
        """ä½¿ç”¨IQRæ–¹æ³•å»é™¤æå€¼ (from step3)"""
        q1 = data_series.quantile(0.25)
        q3 = data_series.quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        return data_series[(data_series >= lower_bound) & (data_series <= upper_bound)]

    def run_individual_experiment_analysis(self, subjects):
        print("\n=== å•å®éªŒåˆ†æ ===")
        for exp_id in range(1, 12):
            exp_corrs = pd.DataFrame()
            for subject in subjects:
                df = self.load_step3_correlations(subject, exp_id)
                if df is not None:
                    exp_corrs = pd.concat([exp_corrs, df])
            if not exp_corrs.empty:
                print(f"ğŸ“Š ç”Ÿæˆå®éªŒ {exp_id} çš„æŸ±çŠ¶å›¾")
                subdir = os.path.join(self.output_dir, f'exp_{exp_id}')
                os.makedirs(subdir, exist_ok=True)
                if 'subject' in exp_corrs.columns:
                    cols = ['subject'] + [col for col in exp_corrs.columns if col != 'subject']
                    exp_corrs = exp_corrs[cols]
                csv_path = os.path.join(subdir, f'exp_{exp_id}_correlations.csv')
                exp_corrs.to_csv(csv_path, index=False)
                print(f"ğŸ’¾ ä¿å­˜å®éªŒ {exp_id} çš„ correlations CSV: {csv_path}")
                self.create_correlation_bar_chart(exp_corrs, f'(Exp {exp_id})', subjects, exp_id)
                self.create_r_distribution_plot(exp_corrs, f'(Exp {exp_id})', subjects, exp_id)
    
    def run_subject_overall_analysis(self, subjects):
        print("\n=== æ¯ä¸ªå—è¯•è€…æ•´ä½“åˆ†æ ===")
        overall_corrs = pd.DataFrame()
        for subject in subjects:
            df = self.load_step3_correlations(subject)
            if df is not None:
                overall_corrs = pd.concat([overall_corrs, df])
        if not overall_corrs.empty:
            print("ğŸ“Š ç”Ÿæˆæ¯ä¸ªå—è¯•è€…æ•´ä½“æŸ±çŠ¶å›¾")
            subdir = os.path.join(self.output_dir, 'overall')
            os.makedirs(subdir, exist_ok=True)
            if 'subject' in overall_corrs.columns:
                cols = ['subject'] + [col for col in overall_corrs.columns if col != 'subject']
                overall_corrs = overall_corrs[cols]
            csv_path = os.path.join(subdir, 'overall_correlations.csv')
            overall_corrs.to_csv(csv_path, index=False)
            print(f"ğŸ’¾ ä¿å­˜æ•´ä½“ correlations CSV: {csv_path}")
            self.create_correlation_bar_chart(overall_corrs, '(Overall per Subject)', subjects)
            self.create_r_distribution_plot(overall_corrs, '(Overall per Subject)', subjects)
    
    def run_integrated_analysis(self, subjects):
        """èåˆåˆ†æï¼šè·¨å—è¯•è€…æ•´åˆ"""
        print("\n=== èåˆåˆ†æ ===")
        integrated_dir = os.path.join(self.output_dir, 'integrated_experiments')
        os.makedirs(integrated_dir, exist_ok=True)
        
        all_sync_df = pd.DataFrame()
        for subject in subjects:
            df = self.load_step3_sync_data(subject)
            if df is not None:
                all_sync_df = pd.concat([all_sync_df, df], ignore_index=True)
        
        if all_sync_df.empty:
            print("âš ï¸ æ— å¯ç”¨ sync æ•°æ®")
            return
        
        # Reorder with subject first
        if 'subject' in all_sync_df.columns:
            cols = ['subject'] + [col for col in all_sync_df.columns if col != 'subject']
            all_sync_df = all_sync_df[cols]
        
        # Per exp_id (assuming exp_id column exists)
        if 'exp_id' in all_sync_df.columns:
            for exp_id in sorted(all_sync_df['exp_id'].unique()):
                exp_sync = all_sync_df[all_sync_df['exp_id'] == exp_id].reset_index(drop=True)
                if not exp_sync.empty:
                    csv_path = os.path.join(integrated_dir, f'integrated_exp_{exp_id}.csv')
                    exp_sync.to_csv(csv_path, index=False)
                    print(f"ğŸ’¾ ä¿å­˜æ•´åˆ CSV: {csv_path}")
                    
                    # Clean outliers per group (sensor_pair)
                    cleaned_exp = pd.DataFrame()
                    for pair in exp_sync['sensor_pair'].unique():
                        pair_df = exp_sync[exp_sync['sensor_pair'] == pair]
                        for col in [c for c in pair_df.columns if c.endswith('_mean') or c == 'ptt_ms']:
                            cleaned_series = self.remove_outliers_iqr(pair_df[col])
                            mask = pair_df[col].isin(cleaned_series)
                            pair_df = pair_df[mask]
                        cleaned_exp = pd.concat([cleaned_exp, pair_df])
                    cleaned_path = os.path.join(integrated_dir, f'integrated_exp_{exp_id}_cleaned.csv')
                    cleaned_exp.to_csv(cleaned_path, index=False)
                    print(f"ğŸ’¾ ä¿å­˜ cleaned æ•´åˆ CSV: {cleaned_path}")
                    
                    # Use cleaned for plots
                    exp_sync = cleaned_exp
                    
                    # ç»˜åˆ¶æ•£ç‚¹å›¾ + çº¿æ€§æ‹Ÿåˆ
                    for physio, label in self.physiological_indicators.items():
                        col = f'{physio}_mean'
                        if col in exp_sync.columns:
                            for pair in exp_sync['sensor_pair'].unique():
                                pair_df = exp_sync[exp_sync['sensor_pair'] == pair].reset_index(drop=True)
                                if len(pair_df) < 10:
                                    continue
                                plt.figure(figsize=(10, 8))
                                sns.scatterplot(data=pair_df, x='ptt_ms', y=col, hue='subject', palette='tab20', alpha=0.6)
                                
                                mask = ~(pair_df['ptt_ms'].isna() | pair_df[col].isna())
                                if mask.sum() >= 10:
                                    X = pair_df.loc[mask, 'ptt_ms'].values.reshape(-1, 1)
                                    y = pair_df.loc[mask, col].values
                                    model = LinearRegression().fit(X, y)
                                    pred = model.predict(X)
                                    r, _ = stats.pearsonr(pair_df.loc[mask, 'ptt_ms'], y)
                                    r2 = model.score(X, y)
                                    mae = mean_absolute_error(y, pred)
                                    std = np.std(y - pred)
                                    x_sort = np.sort(X, axis=0)
                                    plt.plot(x_sort, model.predict(x_sort), color='red', linewidth=2, label='Overall Fit')
                                    
                                    # æ·»åŠ æ ‡æ³¨
                                    stats_text = f'r = {r:.2f}\nRÂ² = {r2:.2f}\nMAE = {mae:.2f}\nSTD = {std:.2f}'
                                    plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes,
                                             bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray', boxstyle='round,pad=0.5'),
                                             verticalalignment='top')
                                
                                plt.title(f'{label} vs PTT ({self.ptt_combinations_en.get(pair, pair)}) - Integrated Exp {exp_id} (Cleaned)')
                                plt.xlabel('PTT (ms)')
                                plt.ylabel(label)
                                plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                                filename = f'scatter_fit_{physio}_{pair}_exp{exp_id}_cleaned.png'
                                plt.savefig(os.path.join(integrated_dir, filename), bbox_inches='tight')
                                plt.close()
                                print(f"ğŸ’¾ ä¿å­˜æ•£ç‚¹æ‹Ÿåˆå›¾ (cleaned): {os.path.join(integrated_dir, filename)}")
        else:
            print("âš ï¸ sync æ•°æ®ç¼ºå°‘ 'exp_id' åˆ—ï¼Œæ— æ³• per-exp æ‹†åˆ†")
        
        # ç»¼åˆæ‰€æœ‰å®éªŒ
        comprehensive_path = os.path.join(self.output_dir, 'comprehensive_integrated.csv')
        all_sync_df.to_csv(comprehensive_path, index=False)
        print(f"ğŸ’¾ ä¿å­˜ç»¼åˆ CSV: {comprehensive_path}")
        
        # Clean comprehensive
        cleaned_comp = pd.DataFrame()
        for pair in all_sync_df['sensor_pair'].unique():
            pair_df = all_sync_df[all_sync_df['sensor_pair'] == pair]
            for col in [c for c in pair_df.columns if c.endswith('_mean') or c == 'ptt_ms']:
                cleaned_series = self.remove_outliers_iqr(pair_df[col])
                mask = pair_df[col].isin(cleaned_series)
                pair_df = pair_df[mask]
            cleaned_comp = pd.concat([cleaned_comp, pair_df])
        cleaned_comp_path = os.path.join(self.output_dir, 'comprehensive_integrated_cleaned.csv')
        cleaned_comp.to_csv(cleaned_comp_path, index=False)
        print(f"ğŸ’¾ ä¿å­˜ cleaned ç»¼åˆ CSV: {cleaned_comp_path}")
        
        # Use cleaned for comprehensive plots
        all_sync_df = cleaned_comp
        
        # ç»¼åˆæ•£ç‚¹ + æ‹Ÿåˆ
        for physio, label in self.physiological_indicators.items():
            col = f'{physio}_mean'
            if col in all_sync_df.columns:
                for pair in all_sync_df['sensor_pair'].unique():
                    pair_df = all_sync_df[all_sync_df['sensor_pair'] == pair].reset_index(drop=True)
                    if len(pair_df) < 10:
                        continue
                    plt.figure(figsize=(10, 8))
                    sns.scatterplot(data=pair_df, x='ptt_ms', y=col, hue='subject', palette='tab20', alpha=0.6)
                    
                    mask = ~(pair_df['ptt_ms'].isna() | pair_df[col].isna())
                    if mask.sum() >= 10:
                        X = pair_df.loc[mask, 'ptt_ms'].values.reshape(-1, 1)
                        y = pair_df.loc[mask, col].values
                        model = LinearRegression().fit(X, y)
                        pred = model.predict(X)
                        r, _ = stats.pearsonr(pair_df.loc[mask, 'ptt_ms'], y)
                        r2 = model.score(X, y)
                        mae = mean_absolute_error(y, pred)
                        std = np.std(y - pred)
                        x_sort = np.sort(X, axis=0)
                        plt.plot(x_sort, model.predict(x_sort), color='red', linewidth=2, label='Overall Fit')
                        
                        # æ·»åŠ æ ‡æ³¨
                        stats_text = f'r = {r:.2f}\nRÂ² = {r2:.2f}\nMAE = {mae:.2f}\nSTD = {std:.2f}'
                        plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes,
                                 bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray', boxstyle='round,pad=0.5'),
                                 verticalalignment='top')
                    
                    plt.title(f'{label} vs PTT ({self.ptt_combinations_en.get(pair, pair)}) - Comprehensive (Cleaned)')
                    plt.xlabel('PTT (ms)')
                    plt.ylabel(label)
                    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                    filename = f'scatter_fit_{physio}_{pair}_comprehensive_cleaned.png'
                    plt.savefig(os.path.join(self.output_dir, filename), bbox_inches='tight')
                    plt.close()
                    print(f"ğŸ’¾ ä¿å­˜ç»¼åˆæ•£ç‚¹æ‹Ÿåˆå›¾ (cleaned): {os.path.join(self.output_dir, filename)}")

def main():
    analyzer = IntegratedPTTBloodPressureAnalyzer()
    subjects = analyzer.load_subjects()
    print(f"ğŸ“‹ å‘ç° {len(subjects)} ä¸ªå—è¯•è€…")
    
    print("\nğŸ“‹ è¯·é€‰æ‹©åˆ†ææ–¹å¼:")
    print("1. ç»¼åˆåˆ†æ (æ‰€æœ‰)")
    print("2. å•å®éªŒåˆ†æ (æ¯ä¸ªå®éªŒçš„æŸ±çŠ¶å›¾)")
    print("3. èåˆåˆ†æ (è·¨å—è¯•è€…æ•´åˆ + æ•£ç‚¹æ‹Ÿåˆ)")
    print("4. æ¯ä¸ªå—è¯•è€…æ•´ä½“åˆ†æ (æ‰€æœ‰å®éªŒçš„æŸ±çŠ¶å›¾)")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3/4, é»˜è®¤1): ").strip()
    if not choice:
        choice = "1"
    
    if choice == "1":
        analyzer.run_individual_experiment_analysis(subjects)
        analyzer.run_subject_overall_analysis(subjects)
        analyzer.run_integrated_analysis(subjects)
    elif choice == "2":
        analyzer.run_individual_experiment_analysis(subjects)
    elif choice == "3":
        analyzer.run_integrated_analysis(subjects)
    elif choice == "4":
        analyzer.run_subject_overall_analysis(subjects)
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œç»¼åˆåˆ†æ")
        analyzer.run_individual_experiment_analysis(subjects)
        analyzer.run_subject_overall_analysis(subjects)
        analyzer.run_integrated_analysis(subjects)
    
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")

if __name__ == "__main__":
    main()